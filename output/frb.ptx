// PTX CompilerJob of kernel #frb(CuDeviceVector{Int4x8, 1}, CuDeviceVector{Int32, 1}, CuDeviceVector{Float16x2, 1}, CuDeviceVector{Int32, 1}) for sm_86, minthreads=768, blocks_per_sm=1, always_inline=false

//
// Generated by LLVM NVPTX Back-End
//

.version 7.1
.target sm_86
.address_size 64

	// .globl	_Z14julia_frb_459213CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS1_Li1ELi1EE // -- Begin function _Z14julia_frb_459213CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS1_Li1ELi1EE
.extern .func julia__convert_9980
(
	.param .b64 julia__convert_9980_param_0,
	.param .b64 julia__convert_9980_param_1
)
;
.extern .func gpu_report_exception
(
	.param .b64 gpu_report_exception_param_0
)
;
.extern .func gpu_signal_exception
(
	.param .align 8 .b8 gpu_signal_exception_param_0[8]
)
;
.extern .shared .align 32 .b8 shmem[];
.global .align 1 .b8 exception1[10] = {101, 120, 99, 101, 112, 116, 105, 111, 110, 0};
                                        // @_Z14julia_frb_459213CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS1_Li1ELi1EE
.visible .entry _Z14julia_frb_459213CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS1_Li1ELi1EE(
	.param .align 8 .b8 _Z14julia_frb_459213CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS1_Li1ELi1EE_param_0[8],
	.param .align 8 .b8 _Z14julia_frb_459213CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS1_Li1ELi1EE_param_1[32],
	.param .align 8 .b8 _Z14julia_frb_459213CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS1_Li1ELi1EE_param_2[32],
	.param .align 8 .b8 _Z14julia_frb_459213CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS1_Li1ELi1EE_param_3[32],
	.param .align 8 .b8 _Z14julia_frb_459213CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS1_Li1ELi1EE_param_4[32]
)
.reqntid 768, 1, 1
.minnctapersm 1
{
	.local .align 4 .b8 	__local_depot0[480];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<6>;
	.reg .b16 	%rs<119>;
	.reg .b32 	%r<2015>;
	.reg .b64 	%rd<263>;

// %bb.0:                               // %conversion
	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	// begin inline asm
	mov.u32 %r79, %dynamic_smem_size;
	// end inline asm
	setp.gt.u32 	%p1, %r79, 76895;
	@%p1 bra 	LBB0_2;
	bra.uni 	LBB0_1;
LBB0_2:                                 // %L11
	ld.param.u64 	%rd58, [_Z14julia_frb_459213CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS1_Li1ELi1EE_param_4];
	ld.param.u64 	%rd54, [_Z14julia_frb_459213CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS1_Li1ELi1EE_param_2];
	add.u64 	%rd62, %SP, 0;
	add.u64 	%rd63, %SP, 4;
	add.u64 	%rd64, %SP, 8;
	add.u64 	%rd65, %SP, 12;
	add.u64 	%rd66, %SP, 16;
	add.u64 	%rd67, %SP, 20;
	add.u64 	%rd68, %SP, 24;
	add.u64 	%rd69, %SP, 28;
	add.u64 	%rd70, %SP, 32;
	add.u64 	%rd71, %SP, 36;
	add.u64 	%rd72, %SP, 40;
	add.u64 	%rd73, %SP, 44;
	add.u64 	%rd74, %SP, 48;
	add.u64 	%rd75, %SP, 52;
	add.u64 	%rd76, %SP, 56;
	add.u64 	%rd77, %SP, 60;
	add.u64 	%rd78, %SP, 64;
	add.u64 	%rd79, %SP, 68;
	add.u64 	%rd80, %SP, 72;
	add.u64 	%rd81, %SP, 76;
	add.u64 	%rd82, %SP, 80;
	add.u64 	%rd83, %SP, 84;
	add.u64 	%rd84, %SP, 88;
	add.u64 	%rd85, %SP, 92;
	add.u64 	%rd86, %SP, 96;
	add.u64 	%rd87, %SP, 112;
	add.u64 	%rd88, %SP, 128;
	add.u64 	%rd89, %SP, 144;
	add.u64 	%rd90, %SP, 160;
	add.u64 	%rd91, %SP, 176;
	add.u64 	%rd92, %SP, 192;
	add.u64 	%rd93, %SP, 208;
	add.u64 	%rd94, %SP, 224;
	add.u64 	%rd95, %SP, 240;
	add.u64 	%rd96, %SP, 256;
	add.u64 	%rd97, %SP, 272;
	add.u64 	%rd98, %SP, 288;
	add.u64 	%rd99, %SP, 304;
	add.u64 	%rd100, %SP, 320;
	add.u64 	%rd101, %SP, 336;
	add.u64 	%rd102, %SP, 352;
	add.u64 	%rd103, %SP, 368;
	add.u64 	%rd104, %SP, 384;
	add.u64 	%rd105, %SP, 400;
	add.u64 	%rd106, %SP, 416;
	add.u64 	%rd107, %SP, 432;
	add.u64 	%rd108, %SP, 448;
	add.u64 	%rd109, %SP, 464;
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ctaid.x;
	mul.lo.s32 	%r86, %r2, 768;
	or.b32  	%r87, %r86, %r1;
	mov.u32 	%r3, %tid.y;
	shl.b32 	%r4, %r3, 5;
	add.s32 	%r88, %r4, %r87;
	mul.wide.u32 	%rd112, %r88, 4;
	add.s64 	%rd51, %rd58, %rd112;
	mov.u32 	%r89, 1;
	st.global.u32 	[%rd51], %r89;
	cvt.u16.u32 	%rs6, %r1;
	and.b16  	%rs7, %rs6, 255;
	mul.lo.s16 	%rs8, %rs7, 171;
	shr.u16 	%rs9, %rs8, 12;
	mul.lo.s16 	%rs10, %rs9, 24;
	sub.s16 	%rs1, %rs6, %rs10;
	cvt.u32.u16 	%r90, %rs1;
	and.b32  	%r91, %r90, 255;
	mad.lo.s32 	%r92, %r91, 24, %r3;
	and.b32  	%r93, %r92, 511;
	mul.wide.u32 	%rd113, %r93, 4;
	add.s64 	%rd114, %rd54, %rd113;
	mov.u32 	%r85, 0;
	setp.gt.u32 	%p2, %r1, 23;
	and.b32  	%r8, %r1, 3;
	@%p2 bra 	LBB0_9;
	bra.uni 	LBB0_3;
LBB0_9:                                 // %guard_pass17682
	// begin inline asm
	cvt.rn.f16x2.f32 %r1988, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1989, %r85, %r85;
	// end inline asm
	shr.u32 	%r102, %r1, 2;
	cvt.u16.u32 	%rs17, %r102;
	mul.lo.s16 	%rs18, %rs17, 171;
	shr.u16 	%rs19, %rs18, 10;
	mul.lo.s16 	%rs20, %rs19, 6;
	sub.s16 	%rs21, %rs17, %rs20;
	cvt.u32.u16 	%r103, %rs21;
	and.b32  	%r1987, %r103, 255;
	bra.uni 	LBB0_4;
LBB0_3:                                 // %L230
	ld.param.u64 	%rd2, [_Z14julia_frb_459213CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS1_Li1ELi1EE_param_3];
	mul.lo.s32 	%r94, %r8, 144;
	add.s32 	%r95, %r94, %r3;
	mul.lo.s32 	%r96, %r2, 576;
	add.s32 	%r97, %r95, %r96;
	shr.u32 	%r98, %r1, 2;
	cvt.u16.u32 	%rs11, %r98;
	mul.lo.s16 	%rs12, %rs11, 171;
	shr.u16 	%rs13, %rs12, 10;
	mul.lo.s16 	%rs14, %rs13, 6;
	sub.s16 	%rs15, %rs11, %rs14;
	cvt.u32.u16 	%r99, %rs15;
	and.b32  	%r1987, %r99, 255;
	and.b16  	%rs16, %rs15, 255;
	mul.wide.u16 	%r100, %rs16, 24;
	add.s32 	%r101, %r97, %r100;
	mul.wide.u32 	%rd115, %r101, 4;
	add.s64 	%rd116, %rd2, %rd115;
	ld.global.u32 	%r1988, [%rd116];
	cvt.u64.u32 	%rd117, %r100;
	cvt.u64.u32 	%rd118, %r96;
	cvt.u64.u32 	%rd119, %r94;
	cvt.u64.u32 	%rd120, %r3;
	add.s64 	%rd121, %rd120, %rd119;
	add.s64 	%rd122, %rd121, %rd118;
	add.s64 	%rd123, %rd122, %rd117;
	shl.b64 	%rd124, %rd123, 2;
	add.s64 	%rd125, %rd2, %rd124;
	ld.global.u32 	%r1989, [%rd125+589824];
LBB0_4:                                 // %L492
	ld.param.u64 	%rd1, [_Z14julia_frb_459213CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS1_Li1ELi1EE_param_1];
	cvta.to.local.u64 	%rd3, %rd62;
	cvta.to.local.u64 	%rd4, %rd63;
	cvta.to.local.u64 	%rd5, %rd64;
	cvta.to.local.u64 	%rd6, %rd65;
	cvta.to.local.u64 	%rd7, %rd66;
	cvta.to.local.u64 	%rd8, %rd67;
	cvta.to.local.u64 	%rd9, %rd68;
	cvta.to.local.u64 	%rd10, %rd69;
	cvta.to.local.u64 	%rd11, %rd70;
	cvta.to.local.u64 	%rd12, %rd71;
	cvta.to.local.u64 	%rd13, %rd72;
	cvta.to.local.u64 	%rd14, %rd73;
	cvta.to.local.u64 	%rd15, %rd74;
	cvta.to.local.u64 	%rd16, %rd75;
	cvta.to.local.u64 	%rd17, %rd76;
	cvta.to.local.u64 	%rd18, %rd77;
	cvta.to.local.u64 	%rd19, %rd78;
	cvta.to.local.u64 	%rd20, %rd79;
	cvta.to.local.u64 	%rd21, %rd80;
	cvta.to.local.u64 	%rd22, %rd81;
	cvta.to.local.u64 	%rd23, %rd82;
	cvta.to.local.u64 	%rd24, %rd83;
	cvta.to.local.u64 	%rd25, %rd84;
	cvta.to.local.u64 	%rd26, %rd85;
	cvta.to.local.u64 	%rd27, %rd86;
	cvta.to.local.u64 	%rd28, %rd87;
	cvta.to.local.u64 	%rd29, %rd88;
	cvta.to.local.u64 	%rd30, %rd89;
	cvta.to.local.u64 	%rd31, %rd90;
	cvta.to.local.u64 	%rd32, %rd91;
	cvta.to.local.u64 	%rd33, %rd92;
	cvta.to.local.u64 	%rd34, %rd93;
	cvta.to.local.u64 	%rd35, %rd94;
	cvta.to.local.u64 	%rd36, %rd95;
	cvta.to.local.u64 	%rd37, %rd96;
	cvta.to.local.u64 	%rd38, %rd97;
	cvta.to.local.u64 	%rd39, %rd98;
	cvta.to.local.u64 	%rd40, %rd99;
	cvta.to.local.u64 	%rd41, %rd100;
	cvta.to.local.u64 	%rd42, %rd101;
	cvta.to.local.u64 	%rd43, %rd102;
	cvta.to.local.u64 	%rd44, %rd103;
	cvta.to.local.u64 	%rd45, %rd104;
	cvta.to.local.u64 	%rd46, %rd105;
	cvta.to.local.u64 	%rd47, %rd106;
	cvta.to.local.u64 	%rd48, %rd107;
	cvta.to.local.u64 	%rd49, %rd108;
	cvta.to.local.u64 	%rd50, %rd109;
	ld.global.u32 	%r5, [%rd114];
	shl.b32 	%r105, %r1, 2;
	and.b32  	%r15, %r105, 60;
	shl.b32 	%r16, %r2, 7;
	shl.b32 	%r106, %r1, 11;
	and.b32  	%r17, %r106, 32768;
	or.b32  	%r18, %r105, 64;
	shr.u32 	%r19, %r1, 4;
	shl.b32 	%r107, %r1, 1;
	and.b32  	%r108, %r107, 30;
	or.b32  	%r109, %r19, %r108;
	mul.lo.s32 	%r20, %r109, 257;
	or.b32  	%r110, %r107, %r19;
	or.b32  	%r111, %r110, 32;
	mul.lo.s32 	%r21, %r111, 257;
	and.b32  	%r22, %r4, 224;
	add.s32 	%r114, %r3, 504;
	bfe.u32 	%r115, %r114, 3, 6;
	mul.lo.s32 	%r24, %r115, 257;
	mul.lo.s32 	%r25, %r3, 33;
	mul.lo.s32 	%r26, %r8, 4806;
	mul.lo.s32 	%r27, %r1987, 801;
	cvt.u64.u32 	%rd126, %r27;
	cvt.u64.u32 	%rd127, %r26;
	cvt.u64.u32 	%rd128, %r25;
	add.s64 	%rd129, %rd128, %rd127;
	add.s64 	%rd130, %rd129, %rd126;
	shl.b64 	%rd131, %rd130, 2;
	mov.u64 	%rd132, shmem;
	add.s64 	%rd52, %rd132, %rd131;
	and.b16  	%rs2, %rs1, 255;
	cvt.u16.u32 	%rs3, %r3;
	mov.u16 	%rs118, 16;
	setp.eq.s32 	%p3, %r19, 1;
	setp.lt.u32 	%p4, %r1, 24;
	mov.u32 	%r1990, %r85;
	bra.uni 	LBB0_5;
LBB0_6:                                 // %L47582
                                        //   in Loop: Header=BB0_5 Depth=1
	st.local.u32 	[%rd3], %r2014;
	st.local.u32 	[%rd4], %r2013;
	st.local.u32 	[%rd5], %r2012;
	st.local.u32 	[%rd6], %r2011;
	st.local.u32 	[%rd7], %r2010;
	st.local.u32 	[%rd8], %r2009;
	st.local.u32 	[%rd9], %r2008;
	st.local.u32 	[%rd10], %r2007;
	st.local.u32 	[%rd11], %r2006;
	st.local.u32 	[%rd12], %r2005;
	st.local.u32 	[%rd13], %r2004;
	st.local.u32 	[%rd14], %r2003;
	st.local.u32 	[%rd15], %r2002;
	st.local.u32 	[%rd16], %r2001;
	st.local.u32 	[%rd17], %r2000;
	st.local.u32 	[%rd18], %r1999;
	st.local.u32 	[%rd19], %r1998;
	st.local.u32 	[%rd20], %r1997;
	st.local.u32 	[%rd21], %r1996;
	st.local.u32 	[%rd22], %r1995;
	st.local.u32 	[%rd23], %r1994;
	st.local.u32 	[%rd24], %r1993;
	st.local.u32 	[%rd25], %r1992;
	st.local.u32 	[%rd26], %r1991;
	bar.sync 	0;
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd86;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd85;
	call.uni 
	julia__convert_9980, 
	(
	param0, 
	param1
	);
	} // callseq 2
	{ // callseq 3, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd87;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd84;
	call.uni 
	julia__convert_9980, 
	(
	param0, 
	param1
	);
	} // callseq 3
	{ // callseq 4, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd88;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd83;
	call.uni 
	julia__convert_9980, 
	(
	param0, 
	param1
	);
	} // callseq 4
	{ // callseq 5, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd89;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd82;
	call.uni 
	julia__convert_9980, 
	(
	param0, 
	param1
	);
	} // callseq 5
	{ // callseq 6, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd90;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd81;
	call.uni 
	julia__convert_9980, 
	(
	param0, 
	param1
	);
	} // callseq 6
	{ // callseq 7, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd91;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	call.uni 
	julia__convert_9980, 
	(
	param0, 
	param1
	);
	} // callseq 7
	{ // callseq 8, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd92;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd79;
	call.uni 
	julia__convert_9980, 
	(
	param0, 
	param1
	);
	} // callseq 8
	{ // callseq 9, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd93;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd78;
	call.uni 
	julia__convert_9980, 
	(
	param0, 
	param1
	);
	} // callseq 9
	{ // callseq 10, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd94;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd77;
	call.uni 
	julia__convert_9980, 
	(
	param0, 
	param1
	);
	} // callseq 10
	{ // callseq 11, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd95;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd76;
	call.uni 
	julia__convert_9980, 
	(
	param0, 
	param1
	);
	} // callseq 11
	{ // callseq 12, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd96;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd75;
	call.uni 
	julia__convert_9980, 
	(
	param0, 
	param1
	);
	} // callseq 12
	{ // callseq 13, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd97;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd74;
	call.uni 
	julia__convert_9980, 
	(
	param0, 
	param1
	);
	} // callseq 13
	{ // callseq 14, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd98;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd73;
	call.uni 
	julia__convert_9980, 
	(
	param0, 
	param1
	);
	} // callseq 14
	{ // callseq 15, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd99;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd72;
	call.uni 
	julia__convert_9980, 
	(
	param0, 
	param1
	);
	} // callseq 15
	{ // callseq 16, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd100;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd71;
	call.uni 
	julia__convert_9980, 
	(
	param0, 
	param1
	);
	} // callseq 16
	{ // callseq 17, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd101;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd70;
	call.uni 
	julia__convert_9980, 
	(
	param0, 
	param1
	);
	} // callseq 17
	{ // callseq 18, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd102;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd69;
	call.uni 
	julia__convert_9980, 
	(
	param0, 
	param1
	);
	} // callseq 18
	{ // callseq 19, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd103;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd68;
	call.uni 
	julia__convert_9980, 
	(
	param0, 
	param1
	);
	} // callseq 19
	{ // callseq 20, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd104;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd67;
	call.uni 
	julia__convert_9980, 
	(
	param0, 
	param1
	);
	} // callseq 20
	{ // callseq 21, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd105;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd66;
	call.uni 
	julia__convert_9980, 
	(
	param0, 
	param1
	);
	} // callseq 21
	{ // callseq 22, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd106;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd65;
	call.uni 
	julia__convert_9980, 
	(
	param0, 
	param1
	);
	} // callseq 22
	{ // callseq 23, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd107;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd64;
	call.uni 
	julia__convert_9980, 
	(
	param0, 
	param1
	);
	} // callseq 23
	{ // callseq 24, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd108;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd63;
	call.uni 
	julia__convert_9980, 
	(
	param0, 
	param1
	);
	} // callseq 24
	{ // callseq 25, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd109;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd62;
	call.uni 
	julia__convert_9980, 
	(
	param0, 
	param1
	);
	} // callseq 25
	ld.local.u32 	%r450, [%rd27];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r450;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r448, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r453, [%rd27+4];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r453;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r451, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r456, [%rd28];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r456;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r454, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r459, [%rd28+4];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r459;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r457, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r462, [%rd29];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r462;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r460, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r465, [%rd29+4];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r465;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r463, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r468, [%rd30];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r468;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r466, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r471, [%rd30+4];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r471;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r469, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r474, [%rd31];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r474;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r472, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r477, [%rd31+4];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r477;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r475, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r480, [%rd32];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r480;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r478, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r483, [%rd32+4];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r483;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r481, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r486, [%rd33];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r486;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r484, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r489, [%rd33+4];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r489;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r487, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r492, [%rd34];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r492;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r490, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r495, [%rd34+4];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r495;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r493, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r498, [%rd35];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r498;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r496, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r501, [%rd35+4];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r501;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r499, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r504, [%rd36];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r504;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r502, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r507, [%rd36+4];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r507;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r505, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r510, [%rd37];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r510;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r508, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r513, [%rd37+4];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r513;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r511, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r516, [%rd38];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r516;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r514, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r519, [%rd38+4];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r519;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r517, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r522, [%rd39];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r522;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r520, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r525, [%rd39+4];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r525;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r523, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r528, [%rd40];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r528;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r526, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r531, [%rd40+4];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r531;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r529, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r534, [%rd41];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r534;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r532, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r537, [%rd41+4];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r537;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r535, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r540, [%rd42];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r540;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r538, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r543, [%rd42+4];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r543;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r541, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r546, [%rd43];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r546;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r544, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r549, [%rd43+4];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r549;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r547, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r552, [%rd44];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r552;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r550, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r555, [%rd44+4];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r555;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r553, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r558, [%rd45];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r558;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r556, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r561, [%rd45+4];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r561;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r559, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r564, [%rd46];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r564;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r562, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r567, [%rd46+4];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r567;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r565, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r570, [%rd47];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r570;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r568, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r573, [%rd47+4];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r573;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r571, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r576, [%rd48];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r576;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r574, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r579, [%rd48+4];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r579;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r577, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r582, [%rd49];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r582;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r580, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r585, [%rd49+4];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r585;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r583, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r588, [%rd50];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r588;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r586, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r591, [%rd50+4];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r591;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r589, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r594, [%rd27+8];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r594;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r592, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r597, [%rd27+12];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r597;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r595, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r600, [%rd28+8];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r600;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r598, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r603, [%rd28+12];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r603;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r601, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r606, [%rd29+8];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r606;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r604, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r609, [%rd29+12];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r609;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r607, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r612, [%rd30+8];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r612;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r610, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r615, [%rd30+12];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r615;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r613, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r618, [%rd31+8];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r618;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r616, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r621, [%rd31+12];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r621;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r619, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r624, [%rd32+8];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r624;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r622, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r627, [%rd32+12];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r627;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r625, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r630, [%rd33+8];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r630;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r628, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r633, [%rd33+12];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r633;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r631, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r636, [%rd34+8];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r636;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r634, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r639, [%rd34+12];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r639;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r637, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r642, [%rd35+8];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r642;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r640, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r645, [%rd35+12];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r645;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r643, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r648, [%rd36+8];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r648;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r646, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r651, [%rd36+12];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r651;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r649, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r654, [%rd37+8];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r654;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r652, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r657, [%rd37+12];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r657;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r655, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r660, [%rd38+8];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r660;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r658, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r663, [%rd38+12];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r663;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r661, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r666, [%rd39+8];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r666;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r664, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r669, [%rd39+12];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r669;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r667, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r672, [%rd40+8];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r672;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r670, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r675, [%rd40+12];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r675;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r673, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r678, [%rd41+8];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r678;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r676, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r681, [%rd41+12];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r681;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r679, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r684, [%rd42+8];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r684;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r682, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r687, [%rd42+12];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r687;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r685, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r690, [%rd43+8];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r690;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r688, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r693, [%rd43+12];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r693;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r691, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r696, [%rd44+8];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r696;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r694, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r699, [%rd44+12];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r699;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r697, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r702, [%rd45+8];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r702;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r700, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r705, [%rd45+12];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r705;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r703, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r708, [%rd46+8];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r708;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r706, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r711, [%rd46+12];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r711;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r709, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r714, [%rd47+8];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r714;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r712, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r717, [%rd47+12];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r717;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r715, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r720, [%rd48+8];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r720;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r718, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r723, [%rd48+12];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r723;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r721, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r726, [%rd49+8];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r726;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r724, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r729, [%rd49+12];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r729;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r727, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r732, [%rd50+8];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1988;
    mov.b32 {%r2re, %r2im}, %r732;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r730, {%r0re, %r0im};
}

	// end inline asm
	ld.local.u32 	%r735, [%rd50+12];
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r1989;
    mov.b32 {%r2re, %r2im}, %r735;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r733, {%r0re, %r0im};
}

	// end inline asm
	mov.u16 	%rs114, 15360;
	mov.u16 	%rs115, 16384;
	// begin inline asm
	mov.b32 %r1316, {%rs114, %rs115};
	// end inline asm
	// begin inline asm
	mov.b32 %r1317, {%rs114, %rs115};
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r738, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r741, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r744, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r747, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r750, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r753, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r756, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r759, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r762, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r765, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r768, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r771, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r774, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r777, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r780, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r783, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r786, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r789, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r792, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r795, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r798, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r801, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r804, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r807, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r810, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r813, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r816, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r819, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r822, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r825, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r828, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r831, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r834, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r837, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r840, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r843, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r846, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r849, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r852, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r855, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r858, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r861, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r864, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r867, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r870, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r873, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r876, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r879, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r882, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r885, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r888, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r891, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r894, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r897, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r900, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r903, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r906, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r909, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r912, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r915, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r918, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r921, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r924, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r927, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r930, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r933, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r936, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r939, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r942, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r945, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r948, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r951, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r954, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r957, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r960, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r963, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r966, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r969, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r972, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r975, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r978, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r981, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r984, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r987, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r990, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r993, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r996, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r999, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1002, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1005, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1008, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1011, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1014, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1017, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1020, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1023, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1026, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1029, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1032, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1035, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1038, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1041, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1044, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1047, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1050, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1053, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1056, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1059, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1062, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1065, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1068, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1071, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1074, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1077, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1080, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1083, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1086, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1089, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1092, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1095, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1098, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1101, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1104, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1107, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1110, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1113, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1116, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1119, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1122, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1125, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1128, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1131, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1134, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1137, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1140, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1143, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1146, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1149, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1152, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1155, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1158, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1161, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1164, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1167, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1170, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1173, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1176, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1179, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1182, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1185, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1188, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1191, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1194, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1197, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1200, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1203, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1206, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1209, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1212, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1215, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1218, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1221, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1224, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1227, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1230, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1233, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1236, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1239, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1242, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1245, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1248, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1251, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1254, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1257, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1260, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1263, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1266, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1269, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1272, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1275, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1278, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1281, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1284, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1287, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1290, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1293, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1296, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1299, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1302, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1305, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1308, %r85, %r85;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r1311, %r85, %r85;
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1314, %r1315}, {%r1316, %r1317}, {%r448}, {%r738, %r741};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1321, %r1322}, {%r1316, %r1317}, {%r451}, {%r744, %r747};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1328, %r1329}, {%r1316, %r1317}, {%r454}, {%r750, %r753};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1335, %r1336}, {%r1316, %r1317}, {%r457}, {%r756, %r759};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1342, %r1343}, {%r1316, %r1317}, {%r460}, {%r762, %r765};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1349, %r1350}, {%r1316, %r1317}, {%r463}, {%r768, %r771};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1356, %r1357}, {%r1316, %r1317}, {%r466}, {%r774, %r777};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1363, %r1364}, {%r1316, %r1317}, {%r469}, {%r780, %r783};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1370, %r1371}, {%r1316, %r1317}, {%r472}, {%r786, %r789};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1377, %r1378}, {%r1316, %r1317}, {%r475}, {%r792, %r795};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1384, %r1385}, {%r1316, %r1317}, {%r478}, {%r798, %r801};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1391, %r1392}, {%r1316, %r1317}, {%r481}, {%r804, %r807};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1398, %r1399}, {%r1316, %r1317}, {%r484}, {%r810, %r813};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1405, %r1406}, {%r1316, %r1317}, {%r487}, {%r816, %r819};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1412, %r1413}, {%r1316, %r1317}, {%r490}, {%r822, %r825};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1419, %r1420}, {%r1316, %r1317}, {%r493}, {%r828, %r831};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1426, %r1427}, {%r1316, %r1317}, {%r496}, {%r834, %r837};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1433, %r1434}, {%r1316, %r1317}, {%r499}, {%r840, %r843};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1440, %r1441}, {%r1316, %r1317}, {%r502}, {%r846, %r849};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1447, %r1448}, {%r1316, %r1317}, {%r505}, {%r852, %r855};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1454, %r1455}, {%r1316, %r1317}, {%r508}, {%r858, %r861};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1461, %r1462}, {%r1316, %r1317}, {%r511}, {%r864, %r867};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1468, %r1469}, {%r1316, %r1317}, {%r514}, {%r870, %r873};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1475, %r1476}, {%r1316, %r1317}, {%r517}, {%r876, %r879};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1482, %r1483}, {%r1316, %r1317}, {%r520}, {%r882, %r885};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1489, %r1490}, {%r1316, %r1317}, {%r523}, {%r888, %r891};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1496, %r1497}, {%r1316, %r1317}, {%r526}, {%r894, %r897};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1503, %r1504}, {%r1316, %r1317}, {%r529}, {%r900, %r903};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1510, %r1511}, {%r1316, %r1317}, {%r532}, {%r906, %r909};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1517, %r1518}, {%r1316, %r1317}, {%r535}, {%r912, %r915};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1524, %r1525}, {%r1316, %r1317}, {%r538}, {%r918, %r921};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1531, %r1532}, {%r1316, %r1317}, {%r541}, {%r924, %r927};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1538, %r1539}, {%r1316, %r1317}, {%r544}, {%r930, %r933};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1545, %r1546}, {%r1316, %r1317}, {%r547}, {%r936, %r939};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1552, %r1553}, {%r1316, %r1317}, {%r550}, {%r942, %r945};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1559, %r1560}, {%r1316, %r1317}, {%r553}, {%r948, %r951};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1566, %r1567}, {%r1316, %r1317}, {%r556}, {%r954, %r957};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1573, %r1574}, {%r1316, %r1317}, {%r559}, {%r960, %r963};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1580, %r1581}, {%r1316, %r1317}, {%r562}, {%r966, %r969};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1587, %r1588}, {%r1316, %r1317}, {%r565}, {%r972, %r975};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1594, %r1595}, {%r1316, %r1317}, {%r568}, {%r978, %r981};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1601, %r1602}, {%r1316, %r1317}, {%r571}, {%r984, %r987};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1608, %r1609}, {%r1316, %r1317}, {%r574}, {%r990, %r993};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1615, %r1616}, {%r1316, %r1317}, {%r577}, {%r996, %r999};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1622, %r1623}, {%r1316, %r1317}, {%r580}, {%r1002, %r1005};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1629, %r1630}, {%r1316, %r1317}, {%r583}, {%r1008, %r1011};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1636, %r1637}, {%r1316, %r1317}, {%r586}, {%r1014, %r1017};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1643, %r1644}, {%r1316, %r1317}, {%r589}, {%r1020, %r1023};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1650, %r1651}, {%r1316, %r1317}, {%r592}, {%r1026, %r1029};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1657, %r1658}, {%r1316, %r1317}, {%r595}, {%r1032, %r1035};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1664, %r1665}, {%r1316, %r1317}, {%r598}, {%r1038, %r1041};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1671, %r1672}, {%r1316, %r1317}, {%r601}, {%r1044, %r1047};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1678, %r1679}, {%r1316, %r1317}, {%r604}, {%r1050, %r1053};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1685, %r1686}, {%r1316, %r1317}, {%r607}, {%r1056, %r1059};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1692, %r1693}, {%r1316, %r1317}, {%r610}, {%r1062, %r1065};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1699, %r1700}, {%r1316, %r1317}, {%r613}, {%r1068, %r1071};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1706, %r1707}, {%r1316, %r1317}, {%r616}, {%r1074, %r1077};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1713, %r1714}, {%r1316, %r1317}, {%r619}, {%r1080, %r1083};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1720, %r1721}, {%r1316, %r1317}, {%r622}, {%r1086, %r1089};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1727, %r1728}, {%r1316, %r1317}, {%r625}, {%r1092, %r1095};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1734, %r1735}, {%r1316, %r1317}, {%r628}, {%r1098, %r1101};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1741, %r1742}, {%r1316, %r1317}, {%r631}, {%r1104, %r1107};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1748, %r1749}, {%r1316, %r1317}, {%r634}, {%r1110, %r1113};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1755, %r1756}, {%r1316, %r1317}, {%r637}, {%r1116, %r1119};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1762, %r1763}, {%r1316, %r1317}, {%r640}, {%r1122, %r1125};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1769, %r1770}, {%r1316, %r1317}, {%r643}, {%r1128, %r1131};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1776, %r1777}, {%r1316, %r1317}, {%r646}, {%r1134, %r1137};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1783, %r1784}, {%r1316, %r1317}, {%r649}, {%r1140, %r1143};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1790, %r1791}, {%r1316, %r1317}, {%r652}, {%r1146, %r1149};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1797, %r1798}, {%r1316, %r1317}, {%r655}, {%r1152, %r1155};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1804, %r1805}, {%r1316, %r1317}, {%r658}, {%r1158, %r1161};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1811, %r1812}, {%r1316, %r1317}, {%r661}, {%r1164, %r1167};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1818, %r1819}, {%r1316, %r1317}, {%r664}, {%r1170, %r1173};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1825, %r1826}, {%r1316, %r1317}, {%r667}, {%r1176, %r1179};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1832, %r1833}, {%r1316, %r1317}, {%r670}, {%r1182, %r1185};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1839, %r1840}, {%r1316, %r1317}, {%r673}, {%r1188, %r1191};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1846, %r1847}, {%r1316, %r1317}, {%r676}, {%r1194, %r1197};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1853, %r1854}, {%r1316, %r1317}, {%r679}, {%r1200, %r1203};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1860, %r1861}, {%r1316, %r1317}, {%r682}, {%r1206, %r1209};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1867, %r1868}, {%r1316, %r1317}, {%r685}, {%r1212, %r1215};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1874, %r1875}, {%r1316, %r1317}, {%r688}, {%r1218, %r1221};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1881, %r1882}, {%r1316, %r1317}, {%r691}, {%r1224, %r1227};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1888, %r1889}, {%r1316, %r1317}, {%r694}, {%r1230, %r1233};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1895, %r1896}, {%r1316, %r1317}, {%r697}, {%r1236, %r1239};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1902, %r1903}, {%r1316, %r1317}, {%r700}, {%r1242, %r1245};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1909, %r1910}, {%r1316, %r1317}, {%r703}, {%r1248, %r1251};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1916, %r1917}, {%r1316, %r1317}, {%r706}, {%r1254, %r1257};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1923, %r1924}, {%r1316, %r1317}, {%r709}, {%r1260, %r1263};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1930, %r1931}, {%r1316, %r1317}, {%r712}, {%r1266, %r1269};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1937, %r1938}, {%r1316, %r1317}, {%r715}, {%r1272, %r1275};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1944, %r1945}, {%r1316, %r1317}, {%r718}, {%r1278, %r1281};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1951, %r1952}, {%r1316, %r1317}, {%r721}, {%r1284, %r1287};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1958, %r1959}, {%r1316, %r1317}, {%r724}, {%r1290, %r1293};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1965, %r1966}, {%r1316, %r1317}, {%r727}, {%r1296, %r1299};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1972, %r1973}, {%r1316, %r1317}, {%r730}, {%r1302, %r1305};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1979, %r1980}, {%r1316, %r1317}, {%r733}, {%r1308, %r1311};
	// end inline asm
	add.s32 	%r1990, %r1990, 48;
	add.s16 	%rs118, %rs118, 48;
	setp.ne.s32 	%p5, %r1990, 2064;
	@%p5 bra 	LBB0_5;
	bra.uni 	LBB0_7;
LBB0_5:                                 // %L495
                                        // =>This Inner Loop Header: Depth=1
	add.s16 	%rs23, %rs3, %rs118;
	add.s16 	%rs24, %rs23, -16;
	mul.hi.s16 	%rs25, %rs24, 16257;
	shr.u16 	%rs26, %rs25, 15;
	shr.s16 	%rs27, %rs25, 9;
	add.s16 	%rs28, %rs27, %rs26;
	mul.lo.s16 	%rs29, %rs28, 2064;
	sub.s16 	%rs30, %rs24, %rs29;
	cvt.u32.u16 	%r309, %rs30;
	shl.b32 	%r310, %r309, 16;
	or.b32  	%r311, %r15, %r310;
	or.b32  	%r312, %r311, %r16;
	or.b32  	%r313, %r312, %r17;
	mul.wide.s32 	%rd133, %r313, 4;
	add.s64 	%rd134, %rd1, %rd133;
	ld.global.v4.u32 	{%r314, %r315, %r316, %r317}, [%rd134];
	or.b32  	%r318, %r18, %r310;
	or.b32  	%r319, %r318, %r16;
	or.b32  	%r320, %r319, %r17;
	mul.wide.s32 	%rd135, %r320, 4;
	add.s64 	%rd136, %rd1, %rd135;
	ld.global.v4.u32 	{%r321, %r322, %r323, %r324}, [%rd136];
	add.s16 	%rs31, %rs23, 8;
	mul.hi.s16 	%rs32, %rs31, 16257;
	shr.u16 	%rs33, %rs32, 15;
	shr.s16 	%rs34, %rs32, 9;
	add.s16 	%rs35, %rs34, %rs33;
	mul.lo.s16 	%rs36, %rs35, 2064;
	sub.s16 	%rs37, %rs31, %rs36;
	cvt.u32.u16 	%r325, %rs37;
	shl.b32 	%r326, %r325, 16;
	or.b32  	%r327, %r15, %r326;
	or.b32  	%r328, %r327, %r16;
	or.b32  	%r329, %r328, %r17;
	mul.wide.s32 	%rd137, %r329, 4;
	add.s64 	%rd138, %rd1, %rd137;
	ld.global.v4.u32 	{%r330, %r331, %r332, %r333}, [%rd138];
	or.b32  	%r334, %r18, %r326;
	or.b32  	%r335, %r334, %r16;
	or.b32  	%r336, %r335, %r17;
	mul.wide.s32 	%rd139, %r336, 4;
	add.s64 	%rd140, %rd1, %rd139;
	ld.global.v4.u32 	{%r337, %r338, %r339, %r340}, [%rd140];
	selp.b32 	%r341, %r314, %r316, %p3;
	shfl.sync.bfly.b32	%r342, %r341, 16, 31, -1;
	selp.b32 	%r118, %r342, %r314, %p3;
	selp.b32 	%r123, %r316, %r342, %p3;
	selp.b32 	%r343, %r315, %r317, %p3;
	shfl.sync.bfly.b32	%r344, %r343, 16, 31, -1;
	selp.b32 	%r126, %r344, %r315, %p3;
	selp.b32 	%r131, %r317, %r344, %p3;
	selp.b32 	%r345, %r321, %r323, %p3;
	shfl.sync.bfly.b32	%r346, %r345, 16, 31, -1;
	selp.b32 	%r134, %r346, %r321, %p3;
	selp.b32 	%r139, %r323, %r346, %p3;
	selp.b32 	%r347, %r322, %r324, %p3;
	shfl.sync.bfly.b32	%r348, %r347, 16, 31, -1;
	selp.b32 	%r142, %r348, %r322, %p3;
	selp.b32 	%r147, %r324, %r348, %p3;
	selp.b32 	%r349, %r330, %r332, %p3;
	shfl.sync.bfly.b32	%r350, %r349, 16, 31, -1;
	selp.b32 	%r150, %r350, %r330, %p3;
	selp.b32 	%r155, %r332, %r350, %p3;
	selp.b32 	%r351, %r331, %r333, %p3;
	shfl.sync.bfly.b32	%r352, %r351, 16, 31, -1;
	selp.b32 	%r158, %r352, %r331, %p3;
	selp.b32 	%r163, %r333, %r352, %p3;
	selp.b32 	%r353, %r337, %r339, %p3;
	shfl.sync.bfly.b32	%r354, %r353, 16, 31, -1;
	selp.b32 	%r166, %r354, %r337, %p3;
	selp.b32 	%r171, %r339, %r354, %p3;
	selp.b32 	%r355, %r338, %r340, %p3;
	shfl.sync.bfly.b32	%r356, %r355, 16, 31, -1;
	selp.b32 	%r174, %r356, %r338, %p3;
	selp.b32 	%r179, %r340, %r356, %p3;
	shl.b32 	%r119, %r123, 4;
	mov.u32 	%r117, 252645135;
	// begin inline asm
	lop3.b32 %r181, %r117, %r118, %r119, 202;
	// end inline asm
	shr.u32 	%r122, %r118, 4;
	// begin inline asm
	lop3.b32 %r197, %r117, %r122, %r123, 202;
	// end inline asm
	shl.b32 	%r127, %r131, 4;
	// begin inline asm
	lop3.b32 %r189, %r117, %r126, %r127, 202;
	// end inline asm
	shr.u32 	%r130, %r126, 4;
	// begin inline asm
	lop3.b32 %r205, %r117, %r130, %r131, 202;
	// end inline asm
	shl.b32 	%r135, %r139, 4;
	// begin inline asm
	lop3.b32 %r213, %r117, %r134, %r135, 202;
	// end inline asm
	shr.u32 	%r138, %r134, 4;
	// begin inline asm
	lop3.b32 %r229, %r117, %r138, %r139, 202;
	// end inline asm
	shl.b32 	%r143, %r147, 4;
	// begin inline asm
	lop3.b32 %r221, %r117, %r142, %r143, 202;
	// end inline asm
	shr.u32 	%r146, %r142, 4;
	// begin inline asm
	lop3.b32 %r237, %r117, %r146, %r147, 202;
	// end inline asm
	shl.b32 	%r151, %r155, 4;
	// begin inline asm
	lop3.b32 %r182, %r117, %r150, %r151, 202;
	// end inline asm
	shr.u32 	%r154, %r150, 4;
	// begin inline asm
	lop3.b32 %r198, %r117, %r154, %r155, 202;
	// end inline asm
	shl.b32 	%r159, %r163, 4;
	// begin inline asm
	lop3.b32 %r190, %r117, %r158, %r159, 202;
	// end inline asm
	shr.u32 	%r162, %r158, 4;
	// begin inline asm
	lop3.b32 %r206, %r117, %r162, %r163, 202;
	// end inline asm
	shl.b32 	%r167, %r171, 4;
	// begin inline asm
	lop3.b32 %r214, %r117, %r166, %r167, 202;
	// end inline asm
	shr.u32 	%r170, %r166, 4;
	// begin inline asm
	lop3.b32 %r230, %r117, %r170, %r171, 202;
	// end inline asm
	shl.b32 	%r175, %r179, 4;
	// begin inline asm
	lop3.b32 %r222, %r117, %r174, %r175, 202;
	// end inline asm
	shr.u32 	%r178, %r174, 4;
	// begin inline asm
	lop3.b32 %r238, %r117, %r178, %r179, 202;
	// end inline asm
	mov.u32 	%r183, 25152;
	// begin inline asm
	prmt.b32 %r245, %r181, %r182, %r183;
	// end inline asm
	mov.u32 	%r187, 29521;
	// begin inline asm
	prmt.b32 %r277, %r181, %r182, %r187;
	// end inline asm
	// begin inline asm
	prmt.b32 %r253, %r189, %r190, %r183;
	// end inline asm
	// begin inline asm
	prmt.b32 %r285, %r189, %r190, %r187;
	// end inline asm
	// begin inline asm
	prmt.b32 %r246, %r197, %r198, %r183;
	// end inline asm
	// begin inline asm
	prmt.b32 %r278, %r197, %r198, %r187;
	// end inline asm
	// begin inline asm
	prmt.b32 %r254, %r205, %r206, %r183;
	// end inline asm
	// begin inline asm
	prmt.b32 %r286, %r205, %r206, %r187;
	// end inline asm
	// begin inline asm
	prmt.b32 %r261, %r213, %r214, %r183;
	// end inline asm
	// begin inline asm
	prmt.b32 %r293, %r213, %r214, %r187;
	// end inline asm
	// begin inline asm
	prmt.b32 %r269, %r221, %r222, %r183;
	// end inline asm
	// begin inline asm
	prmt.b32 %r301, %r221, %r222, %r187;
	// end inline asm
	// begin inline asm
	prmt.b32 %r262, %r229, %r230, %r183;
	// end inline asm
	// begin inline asm
	prmt.b32 %r294, %r229, %r230, %r187;
	// end inline asm
	// begin inline asm
	prmt.b32 %r270, %r237, %r238, %r183;
	// end inline asm
	// begin inline asm
	prmt.b32 %r302, %r237, %r238, %r187;
	// end inline asm
	mov.u32 	%r247, 21520;
	// begin inline asm
	prmt.b32 %r244, %r245, %r246, %r247;
	// end inline asm
	mov.u32 	%r251, 30258;
	// begin inline asm
	prmt.b32 %r248, %r245, %r246, %r251;
	// end inline asm
	// begin inline asm
	prmt.b32 %r252, %r253, %r254, %r247;
	// end inline asm
	// begin inline asm
	prmt.b32 %r256, %r253, %r254, %r251;
	// end inline asm
	// begin inline asm
	prmt.b32 %r260, %r261, %r262, %r247;
	// end inline asm
	// begin inline asm
	prmt.b32 %r264, %r261, %r262, %r251;
	// end inline asm
	// begin inline asm
	prmt.b32 %r268, %r269, %r270, %r247;
	// end inline asm
	// begin inline asm
	prmt.b32 %r272, %r269, %r270, %r251;
	// end inline asm
	// begin inline asm
	prmt.b32 %r276, %r277, %r278, %r247;
	// end inline asm
	// begin inline asm
	prmt.b32 %r280, %r277, %r278, %r251;
	// end inline asm
	// begin inline asm
	prmt.b32 %r284, %r285, %r286, %r247;
	// end inline asm
	// begin inline asm
	prmt.b32 %r288, %r285, %r286, %r251;
	// end inline asm
	// begin inline asm
	prmt.b32 %r292, %r293, %r294, %r247;
	// end inline asm
	// begin inline asm
	prmt.b32 %r296, %r293, %r294, %r251;
	// end inline asm
	// begin inline asm
	prmt.b32 %r300, %r301, %r302, %r247;
	// end inline asm
	// begin inline asm
	prmt.b32 %r304, %r301, %r302, %r251;
	// end inline asm
	mul.hi.s16 	%rs38, %rs24, 10923;
	shr.u16 	%rs39, %rs38, 15;
	shr.s16 	%rs40, %rs38, 2;
	add.s16 	%rs41, %rs40, %rs39;
	mul.lo.s16 	%rs42, %rs41, 24;
	sub.s16 	%rs43, %rs24, %rs42;
	cvt.s32.s16 	%r357, %rs43;
	add.s32 	%r358, %r20, %r357;
	mul.wide.s32 	%rd141, %r358, 4;
	add.s64 	%rd143, %rd132, %rd141;
	st.shared.u32 	[%rd143], %r244;
	st.shared.u32 	[%rd143+512], %r252;
	st.shared.u32 	[%rd143+256], %r248;
	st.shared.u32 	[%rd143+768], %r256;
	add.s32 	%r359, %r21, %r357;
	mul.wide.s32 	%rd144, %r359, 4;
	add.s64 	%rd145, %rd132, %rd144;
	st.shared.u32 	[%rd145], %r260;
	st.shared.u32 	[%rd145+512], %r268;
	st.shared.u32 	[%rd145+256], %r264;
	st.shared.u32 	[%rd145+768], %r272;
	st.shared.u32 	[%rd143+128], %r276;
	st.shared.u32 	[%rd143+640], %r284;
	st.shared.u32 	[%rd143+384], %r280;
	st.shared.u32 	[%rd143+896], %r288;
	st.shared.u32 	[%rd145+128], %r292;
	st.shared.u32 	[%rd145+640], %r300;
	st.shared.u32 	[%rd145+384], %r296;
	st.shared.u32 	[%rd145+896], %r304;
	bar.sync 	0;
	add.s16 	%rs44, %rs2, %rs118;
	add.s16 	%rs45, %rs44, -16;
	mul.hi.s16 	%rs46, %rs45, 10923;
	shr.u16 	%rs47, %rs46, 15;
	shr.s16 	%rs48, %rs46, 2;
	add.s16 	%rs49, %rs48, %rs47;
	mul.lo.s16 	%rs50, %rs49, 24;
	sub.s16 	%rs51, %rs45, %rs50;
	cvt.s32.s16 	%r360, %rs51;
	add.s32 	%r361, %r22, %r360;
	add.s32 	%r362, %r361, %r24;
	mul.wide.s32 	%rd146, %r362, 4;
	add.s64 	%rd147, %rd132, %rd146;
	ld.shared.u32 	%r363, [%rd147];
	bar.sync 	0;
	shfl.sync.idx.b32	%r364, %r5, 0, 31, -1;
	shfl.sync.idx.b32	%r365, %r5, 1, 31, -1;
	shfl.sync.idx.b32	%r366, %r5, 2, 31, -1;
	shfl.sync.idx.b32	%r367, %r5, 3, 31, -1;
	shfl.sync.idx.b32	%r368, %r5, 4, 31, -1;
	shfl.sync.idx.b32	%r369, %r5, 5, 31, -1;
	shfl.sync.idx.b32	%r370, %r5, 6, 31, -1;
	shfl.sync.idx.b32	%r371, %r5, 7, 31, -1;
	shfl.sync.idx.b32	%r372, %r5, 8, 31, -1;
	shfl.sync.idx.b32	%r373, %r5, 9, 31, -1;
	shfl.sync.idx.b32	%r374, %r5, 10, 31, -1;
	shfl.sync.idx.b32	%r375, %r5, 11, 31, -1;
	shfl.sync.idx.b32	%r376, %r5, 12, 31, -1;
	shfl.sync.idx.b32	%r377, %r5, 13, 31, -1;
	shfl.sync.idx.b32	%r378, %r5, 14, 31, -1;
	shfl.sync.idx.b32	%r379, %r5, 15, 31, -1;
	shfl.sync.idx.b32	%r380, %r5, 16, 31, -1;
	shfl.sync.idx.b32	%r381, %r5, 17, 31, -1;
	shfl.sync.idx.b32	%r382, %r5, 18, 31, -1;
	shfl.sync.idx.b32	%r383, %r5, 19, 31, -1;
	shfl.sync.idx.b32	%r384, %r5, 20, 31, -1;
	shfl.sync.idx.b32	%r385, %r5, 21, 31, -1;
	shfl.sync.idx.b32	%r386, %r5, 22, 31, -1;
	shfl.sync.idx.b32	%r387, %r5, 23, 31, -1;
	add.s32 	%r388, %r364, %r360;
	mul.wide.s32 	%rd148, %r388, 4;
	add.s64 	%rd149, %rd132, %rd148;
	st.shared.u32 	[%rd149], %r363;
	add.s32 	%r389, %r365, %r360;
	mul.wide.s32 	%rd150, %r389, 4;
	add.s64 	%rd151, %rd132, %rd150;
	st.shared.u32 	[%rd151], %r363;
	add.s32 	%r390, %r366, %r360;
	mul.wide.s32 	%rd152, %r390, 4;
	add.s64 	%rd153, %rd132, %rd152;
	st.shared.u32 	[%rd153], %r363;
	add.s32 	%r391, %r367, %r360;
	mul.wide.s32 	%rd154, %r391, 4;
	add.s64 	%rd155, %rd132, %rd154;
	st.shared.u32 	[%rd155], %r363;
	add.s32 	%r392, %r368, %r360;
	mul.wide.s32 	%rd156, %r392, 4;
	add.s64 	%rd157, %rd132, %rd156;
	st.shared.u32 	[%rd157], %r363;
	add.s32 	%r393, %r369, %r360;
	mul.wide.s32 	%rd158, %r393, 4;
	add.s64 	%rd159, %rd132, %rd158;
	st.shared.u32 	[%rd159], %r363;
	add.s32 	%r394, %r370, %r360;
	mul.wide.s32 	%rd160, %r394, 4;
	add.s64 	%rd161, %rd132, %rd160;
	st.shared.u32 	[%rd161], %r363;
	add.s32 	%r395, %r371, %r360;
	mul.wide.s32 	%rd162, %r395, 4;
	add.s64 	%rd163, %rd132, %rd162;
	st.shared.u32 	[%rd163], %r363;
	add.s32 	%r396, %r372, %r360;
	mul.wide.s32 	%rd164, %r396, 4;
	add.s64 	%rd165, %rd132, %rd164;
	st.shared.u32 	[%rd165], %r363;
	add.s32 	%r397, %r373, %r360;
	mul.wide.s32 	%rd166, %r397, 4;
	add.s64 	%rd167, %rd132, %rd166;
	st.shared.u32 	[%rd167], %r363;
	add.s32 	%r398, %r374, %r360;
	mul.wide.s32 	%rd168, %r398, 4;
	add.s64 	%rd169, %rd132, %rd168;
	st.shared.u32 	[%rd169], %r363;
	add.s32 	%r399, %r375, %r360;
	mul.wide.s32 	%rd170, %r399, 4;
	add.s64 	%rd171, %rd132, %rd170;
	st.shared.u32 	[%rd171], %r363;
	add.s32 	%r400, %r376, %r360;
	mul.wide.s32 	%rd172, %r400, 4;
	add.s64 	%rd173, %rd132, %rd172;
	st.shared.u32 	[%rd173], %r363;
	add.s32 	%r401, %r377, %r360;
	mul.wide.s32 	%rd174, %r401, 4;
	add.s64 	%rd175, %rd132, %rd174;
	st.shared.u32 	[%rd175], %r363;
	add.s32 	%r402, %r378, %r360;
	mul.wide.s32 	%rd176, %r402, 4;
	add.s64 	%rd177, %rd132, %rd176;
	st.shared.u32 	[%rd177], %r363;
	add.s32 	%r403, %r379, %r360;
	mul.wide.s32 	%rd178, %r403, 4;
	add.s64 	%rd179, %rd132, %rd178;
	st.shared.u32 	[%rd179], %r363;
	add.s32 	%r404, %r380, %r360;
	mul.wide.s32 	%rd180, %r404, 4;
	add.s64 	%rd181, %rd132, %rd180;
	st.shared.u32 	[%rd181], %r363;
	add.s32 	%r405, %r381, %r360;
	mul.wide.s32 	%rd182, %r405, 4;
	add.s64 	%rd183, %rd132, %rd182;
	st.shared.u32 	[%rd183], %r363;
	add.s32 	%r406, %r382, %r360;
	mul.wide.s32 	%rd184, %r406, 4;
	add.s64 	%rd185, %rd132, %rd184;
	st.shared.u32 	[%rd185], %r363;
	add.s32 	%r407, %r383, %r360;
	mul.wide.s32 	%rd186, %r407, 4;
	add.s64 	%rd187, %rd132, %rd186;
	st.shared.u32 	[%rd187], %r363;
	add.s32 	%r408, %r384, %r360;
	mul.wide.s32 	%rd188, %r408, 4;
	add.s64 	%rd189, %rd132, %rd188;
	st.shared.u32 	[%rd189], %r363;
	add.s32 	%r409, %r385, %r360;
	mul.wide.s32 	%rd190, %r409, 4;
	add.s64 	%rd191, %rd132, %rd190;
	st.shared.u32 	[%rd191], %r363;
	add.s32 	%r410, %r386, %r360;
	mul.wide.s32 	%rd192, %r410, 4;
	add.s64 	%rd193, %rd132, %rd192;
	st.shared.u32 	[%rd193], %r85;
	add.s32 	%r411, %r387, %r360;
	mul.wide.s32 	%rd194, %r411, 4;
	add.s64 	%rd195, %rd132, %rd194;
	st.shared.u32 	[%rd195], %r85;
	bar.sync 	0;
	mov.u32 	%r1991, %r85;
	mov.u32 	%r1992, %r85;
	mov.u32 	%r1993, %r85;
	mov.u32 	%r1994, %r85;
	mov.u32 	%r1995, %r85;
	mov.u32 	%r1996, %r85;
	mov.u32 	%r1997, %r85;
	mov.u32 	%r1998, %r85;
	mov.u32 	%r1999, %r85;
	mov.u32 	%r2000, %r85;
	mov.u32 	%r2001, %r85;
	mov.u32 	%r2002, %r85;
	mov.u32 	%r2003, %r85;
	mov.u32 	%r2004, %r85;
	mov.u32 	%r2005, %r85;
	mov.u32 	%r2006, %r85;
	mov.u32 	%r2007, %r85;
	mov.u32 	%r2008, %r85;
	mov.u32 	%r2009, %r85;
	mov.u32 	%r2010, %r85;
	mov.u32 	%r2011, %r85;
	mov.u32 	%r2012, %r85;
	mov.u32 	%r2013, %r85;
	mov.u32 	%r2014, %r85;
	@%p4 bra 	LBB0_8;
	bra.uni 	LBB0_6;
LBB0_8:                                 // %oksrem15777
                                        //   in Loop: Header=BB0_5 Depth=1
	add.s16 	%rs52, %rs118, -16;
	mul.hi.s16 	%rs53, %rs52, 10923;
	shr.u16 	%rs54, %rs53, 15;
	shr.s16 	%rs55, %rs53, 2;
	add.s16 	%rs56, %rs55, %rs54;
	mul.lo.s16 	%rs57, %rs56, 24;
	sub.s16 	%rs58, %rs52, %rs57;
	cvt.s32.s16 	%r412, %rs58;
	add.s32 	%r413, %r25, %r412;
	add.s32 	%r414, %r413, %r26;
	add.s32 	%r415, %r414, %r27;
	mul.wide.s32 	%rd196, %r415, 4;
	add.s64 	%rd198, %rd132, %rd196;
	ld.shared.u32 	%r1991, [%rd198];
	ld.shared.u32 	%r1992, [%rd52+4];
	ld.shared.u32 	%r1993, [%rd52+8];
	ld.shared.u32 	%r1994, [%rd52+12];
	ld.shared.u32 	%r1995, [%rd52+16];
	ld.shared.u32 	%r1996, [%rd52+20];
	ld.shared.u32 	%r1997, [%rd52+24];
	ld.shared.u32 	%r1998, [%rd52+28];
	ld.shared.u32 	%r1999, [%rd52+32];
	ld.shared.u32 	%r2000, [%rd52+36];
	ld.shared.u32 	%r2001, [%rd52+40];
	ld.shared.u32 	%r2002, [%rd52+44];
	ld.shared.u32 	%r2003, [%rd52+48];
	ld.shared.u32 	%r2004, [%rd52+52];
	ld.shared.u32 	%r2005, [%rd52+56];
	ld.shared.u32 	%r2006, [%rd52+60];
	mul.hi.s16 	%rs59, %rs118, 10923;
	shr.u16 	%rs60, %rs59, 15;
	shr.s16 	%rs61, %rs59, 2;
	add.s16 	%rs62, %rs61, %rs60;
	mul.lo.s16 	%rs63, %rs62, 24;
	sub.s16 	%rs64, %rs118, %rs63;
	cvt.s32.s16 	%r416, %rs64;
	add.s32 	%r417, %r25, %r416;
	add.s32 	%r418, %r417, %r26;
	add.s32 	%r419, %r418, %r27;
	mul.wide.s32 	%rd199, %r419, 4;
	add.s64 	%rd200, %rd132, %rd199;
	ld.shared.u32 	%r2007, [%rd200];
	add.s16 	%rs65, %rs118, 1;
	mul.hi.s16 	%rs66, %rs65, 10923;
	shr.u16 	%rs67, %rs66, 15;
	shr.s16 	%rs68, %rs66, 2;
	add.s16 	%rs69, %rs68, %rs67;
	mul.lo.s16 	%rs70, %rs69, 24;
	sub.s16 	%rs71, %rs65, %rs70;
	cvt.s32.s16 	%r420, %rs71;
	add.s32 	%r421, %r25, %r420;
	add.s32 	%r422, %r421, %r26;
	add.s32 	%r423, %r422, %r27;
	mul.wide.s32 	%rd201, %r423, 4;
	add.s64 	%rd202, %rd132, %rd201;
	ld.shared.u32 	%r2008, [%rd202];
	add.s16 	%rs72, %rs118, 2;
	mul.hi.s16 	%rs73, %rs72, 10923;
	shr.u16 	%rs74, %rs73, 15;
	shr.s16 	%rs75, %rs73, 2;
	add.s16 	%rs76, %rs75, %rs74;
	mul.lo.s16 	%rs77, %rs76, 24;
	sub.s16 	%rs78, %rs72, %rs77;
	cvt.s32.s16 	%r424, %rs78;
	add.s32 	%r425, %r25, %r424;
	add.s32 	%r426, %r425, %r26;
	add.s32 	%r427, %r426, %r27;
	mul.wide.s32 	%rd203, %r427, 4;
	add.s64 	%rd204, %rd132, %rd203;
	ld.shared.u32 	%r2009, [%rd204];
	add.s16 	%rs79, %rs118, 3;
	mul.hi.s16 	%rs80, %rs79, 10923;
	shr.u16 	%rs81, %rs80, 15;
	shr.s16 	%rs82, %rs80, 2;
	add.s16 	%rs83, %rs82, %rs81;
	mul.lo.s16 	%rs84, %rs83, 24;
	sub.s16 	%rs85, %rs79, %rs84;
	cvt.s32.s16 	%r428, %rs85;
	add.s32 	%r429, %r25, %r428;
	add.s32 	%r430, %r429, %r26;
	add.s32 	%r431, %r430, %r27;
	mul.wide.s32 	%rd205, %r431, 4;
	add.s64 	%rd206, %rd132, %rd205;
	ld.shared.u32 	%r2010, [%rd206];
	add.s16 	%rs86, %rs118, 4;
	mul.hi.s16 	%rs87, %rs86, 10923;
	shr.u16 	%rs88, %rs87, 15;
	shr.s16 	%rs89, %rs87, 2;
	add.s16 	%rs90, %rs89, %rs88;
	mul.lo.s16 	%rs91, %rs90, 24;
	sub.s16 	%rs92, %rs86, %rs91;
	cvt.s32.s16 	%r432, %rs92;
	add.s32 	%r433, %r25, %r432;
	add.s32 	%r434, %r433, %r26;
	add.s32 	%r435, %r434, %r27;
	mul.wide.s32 	%rd207, %r435, 4;
	add.s64 	%rd208, %rd132, %rd207;
	ld.shared.u32 	%r2011, [%rd208];
	add.s16 	%rs93, %rs118, 5;
	mul.hi.s16 	%rs94, %rs93, 10923;
	shr.u16 	%rs95, %rs94, 15;
	shr.s16 	%rs96, %rs94, 2;
	add.s16 	%rs97, %rs96, %rs95;
	mul.lo.s16 	%rs98, %rs97, 24;
	sub.s16 	%rs99, %rs93, %rs98;
	cvt.s32.s16 	%r436, %rs99;
	add.s32 	%r437, %r25, %r436;
	add.s32 	%r438, %r437, %r26;
	add.s32 	%r439, %r438, %r27;
	mul.wide.s32 	%rd209, %r439, 4;
	add.s64 	%rd210, %rd132, %rd209;
	ld.shared.u32 	%r2012, [%rd210];
	add.s16 	%rs100, %rs118, 6;
	mul.hi.s16 	%rs101, %rs100, 10923;
	shr.u16 	%rs102, %rs101, 15;
	shr.s16 	%rs103, %rs101, 2;
	add.s16 	%rs104, %rs103, %rs102;
	mul.lo.s16 	%rs105, %rs104, 24;
	sub.s16 	%rs106, %rs100, %rs105;
	cvt.s32.s16 	%r440, %rs106;
	add.s32 	%r441, %r25, %r440;
	add.s32 	%r442, %r441, %r26;
	add.s32 	%r443, %r442, %r27;
	mul.wide.s32 	%rd211, %r443, 4;
	add.s64 	%rd212, %rd132, %rd211;
	ld.shared.u32 	%r2013, [%rd212];
	add.s16 	%rs107, %rs118, 7;
	mul.hi.s16 	%rs108, %rs107, 10923;
	shr.u16 	%rs109, %rs108, 15;
	shr.s16 	%rs110, %rs108, 2;
	add.s16 	%rs111, %rs110, %rs109;
	mul.lo.s16 	%rs112, %rs111, 24;
	sub.s16 	%rs113, %rs107, %rs112;
	cvt.s32.s16 	%r444, %rs113;
	add.s32 	%r445, %r25, %r444;
	add.s32 	%r446, %r445, %r26;
	add.s32 	%r447, %r446, %r27;
	mul.wide.s32 	%rd213, %r447, 4;
	add.s64 	%rd214, %rd132, %rd213;
	ld.shared.u32 	%r2014, [%rd214];
	bra.uni 	LBB0_6;
LBB0_7:                                 // %L49474
	mov.u32 	%r1986, 0;
	st.global.u32 	[%rd51], %r1986;
	ret;
LBB0_1:                                 // %L9
	ld.param.u64 	%rd53, [_Z14julia_frb_459213CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS1_Li1ELi1EE_param_0];
	mov.u64 	%rd110, exception1;
	cvta.global.u64 	%rd111, %rd110;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd111;
	call.uni 
	gpu_report_exception, 
	(
	param0
	);
	} // callseq 0
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .align 8 .b8 param0[8];
	st.param.b64 	[param0+0], %rd53;
	call.uni 
	gpu_signal_exception, 
	(
	param0
	);
	} // callseq 1
	// begin inline asm
	exit;
	// end inline asm
                                        // -- End function
}
