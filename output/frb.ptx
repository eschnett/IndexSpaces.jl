// PTX CompilerJob of kernel #frb(CuDeviceVector{Int4x8, 1}, CuDeviceVector{Int32, 1}, CuDeviceVector{Float16x2, 1}, CuDeviceVector{Float16x2, 1}, CuDeviceVector{Int32, 1}) for sm_86, minthreads=768, blocks_per_sm=1, always_inline=false

//
// Generated by LLVM NVPTX Back-End
//

.version 7.1
.target sm_86
.address_size 64

	// .globl	_Z14julia_frb_550613CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE // -- Begin function _Z14julia_frb_550613CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE
.func gpu_report_exception
(
	.param .b64 gpu_report_exception_param_0
)
.noreturn
{
	trap;
}
.func gpu_signal_exception
(
	.param .align 8 .b8 gpu_signal_exception_param_0[8]
)
.noreturn
{
	trap;
}
.extern .shared .align 32 .b8 shmem[];
.global .align 1 .b8 exception1[10] = {101, 120, 99, 101, 112, 116, 105, 111, 110, 0};
                                        // @_Z14julia_frb_550613CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE
.visible .entry _Z14julia_frb_550613CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE(
	.param .align 8 .b8 _Z14julia_frb_550613CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_0[8],
	.param .align 8 .b8 _Z14julia_frb_550613CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_1[32],
	.param .align 8 .b8 _Z14julia_frb_550613CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_2[32],
	.param .align 8 .b8 _Z14julia_frb_550613CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_3[32],
	.param .align 8 .b8 _Z14julia_frb_550613CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_4[32],
	.param .align 8 .b8 _Z14julia_frb_550613CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_5[32]
)
.reqntid 768, 1, 1
.minnctapersm 1
{
	.reg .pred 	%p<58>;
	.reg .b16 	%rs<424>;
	.reg .f32 	%f<172>;
	.reg .b32 	%r<2497>;
	.reg .b64 	%rd<192>;

// %bb.0:                               // %conversion
	// begin inline asm
	mov.u32 %r197, %dynamic_smem_size;
	// end inline asm
	setp.gt.u32 	%p1, %r197, 76895;
	@%p1 bra 	LBB0_2;
	bra.uni 	LBB0_1;
LBB0_2:                                 // %L11
	ld.param.u64 	%rd13, [_Z14julia_frb_550613CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_5];
	ld.param.u64 	%rd9, [_Z14julia_frb_550613CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_2];
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %tid.y;
	shl.b32 	%r3, %r2, 5;
	or.b32  	%r222, %r3, %r1;
	mov.u32 	%r4, %ctaid.x;
	mad.lo.s32 	%r223, %r4, 768, %r222;
	mul.wide.u32 	%rd19, %r223, 4;
	add.s64 	%rd4, %rd13, %rd19;
	mov.u32 	%r224, 1;
	st.global.u32 	[%rd4], %r224;
	and.b32  	%r5, %r1, 3;
	shr.u32 	%r6, %r1, 2;
	mul.lo.s32 	%r225, %r6, %r5;
	cvt.rn.f32.s32 	%f1, %r225;
	mul.f32 	%f2, %f1, 0f3E800000;
	add.f32 	%f3, %f2, %f2;
	mov.b32 	%r226, %f3;
	and.b32  	%r227, %r226, -2147483648;
	or.b32  	%r228, %r227, 1056964608;
	mov.b32 	%f4, %r228;
	add.f32 	%f5, %f3, %f4;
	cvt.rzi.f32.f32 	%f6, %f5;
	abs.f32 	%f7, %f3;
	setp.gt.f32 	%p2, %f7, 0f4B000000;
	selp.f32 	%f8, %f3, %f6, %p2;
	cvt.rzi.f32.f32 	%f9, %f3;
	setp.lt.f32 	%p3, %f7, 0f3F000000;
	selp.f32 	%f10, %f9, %f8, %p3;
	cvt.rzi.s32.f32 	%r229, %f10;
	fma.rn.f32 	%f11, %f10, 0fBF000000, %f2;
	mul.f32 	%f12, %f11, 0f34222169;
	fma.rn.f32 	%f13, %f11, 0f40490FDA, %f12;
	mul.f32 	%f14, %f13, %f13;
	fma.rn.f32 	%f15, %f14, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f16, %f15, %f14, 0f3D2AAABB;
	fma.rn.f32 	%f17, %f16, %f14, 0fBEFFFFFF;
	fma.rn.f32 	%f18, %f17, %f14, 0f3F800000;
	fma.rn.f32 	%f19, %f14, %f13, 0f00000000;
	fma.rn.f32 	%f20, %f14, 0fB94D4153, 0f3C0885E4;
	fma.rn.f32 	%f21, %f20, %f14, 0fBE2AAAA8;
	fma.rn.f32 	%f22, %f21, %f19, %f13;
	and.b32  	%r230, %r229, 1;
	setp.eq.b32 	%p4, %r230, 1;
	selp.f32 	%f23, %f18, %f22, %p4;
	selp.f32 	%f24, %f22, %f18, %p4;
	and.b32  	%r231, %r229, 2;
	setp.eq.s32 	%p5, %r231, 0;
	neg.f32 	%f25, %f23;
	selp.f32 	%f26, %f23, %f25, %p5;
	add.s32 	%r232, %r229, 1;
	and.b32  	%r233, %r232, 2;
	setp.eq.s32 	%p6, %r233, 0;
	mov.f32 	%f27, 0f00000000;
	sub.f32 	%f28, %f27, %f24;
	selp.f32 	%f29, %f24, %f28, %p6;
	cvt.rzi.f32.f32 	%f30, %f2;
	setp.eq.f32 	%p7, %f30, %f2;
	mul.f32 	%f31, %f2, 0f00000000;
	selp.f32 	%f32, %f31, %f26, %p7;
	abs.f32 	%f33, %f2;
	setp.gt.f32 	%p8, %f33, 0f4B800000;
	add.f32 	%f34, %f32, 0f3F800000;
	selp.f32 	%f35, %f34, %f29, %p8;
	mov.b32 	%r200, %f35;
	mov.b32 	%r203, %f32;
	xor.b32  	%r199, %r203, -2147483648;
	shl.b32 	%r9, %r1, 1;
	and.b32  	%r234, %r9, 6;
	mul.lo.s32 	%r235, %r6, %r234;
	cvt.rn.f32.s32 	%f36, %r235;
	div.rn.f32 	%f37, %f36, 0f41C00000;
	add.f32 	%f38, %f37, %f37;
	mov.b32 	%r236, %f38;
	and.b32  	%r237, %r236, -2147483648;
	or.b32  	%r238, %r237, 1056964608;
	mov.b32 	%f39, %r238;
	add.f32 	%f40, %f38, %f39;
	cvt.rzi.f32.f32 	%f41, %f40;
	abs.f32 	%f42, %f38;
	setp.gt.f32 	%p9, %f42, 0f4B000000;
	selp.f32 	%f43, %f38, %f41, %p9;
	cvt.rzi.f32.f32 	%f44, %f38;
	setp.lt.f32 	%p10, %f42, 0f3F000000;
	selp.f32 	%f45, %f44, %f43, %p10;
	cvt.rzi.s32.f32 	%r239, %f45;
	fma.rn.f32 	%f46, %f45, 0fBF000000, %f37;
	mul.f32 	%f47, %f46, 0f34222169;
	fma.rn.f32 	%f48, %f46, 0f40490FDA, %f47;
	mul.f32 	%f49, %f48, %f48;
	fma.rn.f32 	%f50, %f49, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f51, %f50, %f49, 0f3D2AAABB;
	fma.rn.f32 	%f52, %f51, %f49, 0fBEFFFFFF;
	fma.rn.f32 	%f53, %f52, %f49, 0f3F800000;
	fma.rn.f32 	%f54, %f49, %f48, 0f00000000;
	fma.rn.f32 	%f55, %f49, 0fB94D4153, 0f3C0885E4;
	fma.rn.f32 	%f56, %f55, %f49, 0fBE2AAAA8;
	fma.rn.f32 	%f57, %f56, %f54, %f48;
	and.b32  	%r240, %r239, 1;
	setp.eq.b32 	%p11, %r240, 1;
	selp.f32 	%f58, %f53, %f57, %p11;
	selp.f32 	%f59, %f57, %f53, %p11;
	and.b32  	%r241, %r239, 2;
	setp.eq.s32 	%p12, %r241, 0;
	neg.f32 	%f60, %f58;
	selp.f32 	%f61, %f58, %f60, %p12;
	add.s32 	%r242, %r239, 1;
	and.b32  	%r243, %r242, 2;
	setp.eq.s32 	%p13, %r243, 0;
	sub.f32 	%f62, %f27, %f59;
	selp.f32 	%f63, %f59, %f62, %p13;
	cvt.rzi.f32.f32 	%f64, %f37;
	setp.eq.f32 	%p14, %f64, %f37;
	mul.f32 	%f65, %f37, 0f00000000;
	selp.f32 	%f66, %f65, %f61, %p14;
	abs.f32 	%f67, %f37;
	setp.gt.f32 	%p15, %f67, 0f4B800000;
	add.f32 	%f68, %f66, 0f3F800000;
	selp.f32 	%f69, %f68, %f63, %p15;
	add.s32 	%r244, %r235, %r6;
	cvt.rn.f32.s32 	%f70, %r244;
	div.rn.f32 	%f71, %f70, 0f41C00000;
	add.f32 	%f72, %f71, %f71;
	mov.b32 	%r245, %f72;
	and.b32  	%r246, %r245, -2147483648;
	or.b32  	%r247, %r246, 1056964608;
	mov.b32 	%f73, %r247;
	add.f32 	%f74, %f72, %f73;
	cvt.rzi.f32.f32 	%f75, %f74;
	abs.f32 	%f76, %f72;
	setp.gt.f32 	%p16, %f76, 0f4B000000;
	selp.f32 	%f77, %f72, %f75, %p16;
	cvt.rzi.f32.f32 	%f78, %f72;
	setp.lt.f32 	%p17, %f76, 0f3F000000;
	selp.f32 	%f79, %f78, %f77, %p17;
	cvt.rzi.s32.f32 	%r248, %f79;
	fma.rn.f32 	%f80, %f79, 0fBF000000, %f71;
	mul.f32 	%f81, %f80, 0f34222169;
	fma.rn.f32 	%f82, %f80, 0f40490FDA, %f81;
	mul.f32 	%f83, %f82, %f82;
	fma.rn.f32 	%f84, %f83, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f85, %f84, %f83, 0f3D2AAABB;
	fma.rn.f32 	%f86, %f85, %f83, 0fBEFFFFFF;
	fma.rn.f32 	%f87, %f86, %f83, 0f3F800000;
	fma.rn.f32 	%f88, %f83, %f82, 0f00000000;
	fma.rn.f32 	%f89, %f83, 0fB94D4153, 0f3C0885E4;
	fma.rn.f32 	%f90, %f89, %f83, 0fBE2AAAA8;
	fma.rn.f32 	%f91, %f90, %f88, %f82;
	and.b32  	%r249, %r248, 1;
	setp.eq.b32 	%p18, %r249, 1;
	selp.f32 	%f92, %f87, %f91, %p18;
	selp.f32 	%f93, %f91, %f87, %p18;
	and.b32  	%r250, %r248, 2;
	setp.eq.s32 	%p19, %r250, 0;
	neg.f32 	%f94, %f92;
	selp.f32 	%f95, %f92, %f94, %p19;
	add.s32 	%r251, %r248, 1;
	and.b32  	%r252, %r251, 2;
	setp.eq.s32 	%p20, %r252, 0;
	sub.f32 	%f96, %f27, %f93;
	selp.f32 	%f97, %f93, %f96, %p20;
	cvt.rzi.f32.f32 	%f98, %f71;
	setp.eq.f32 	%p21, %f98, %f71;
	mul.f32 	%f99, %f71, 0f00000000;
	selp.f32 	%f100, %f99, %f95, %p21;
	abs.f32 	%f101, %f71;
	setp.gt.f32 	%p22, %f101, 0f4B800000;
	add.f32 	%f102, %f100, 0f3F800000;
	selp.f32 	%f103, %f102, %f97, %p22;
	mov.b32 	%r205, %f69;
	mov.b32 	%r206, %f103;
	mov.b32 	%r208, %f66;
	mov.b32 	%r209, %f100;
	shl.b32 	%r253, %r1, 4;
	and.b32  	%r254, %r253, 48;
	mul.lo.s32 	%r255, %r6, %r254;
	cvt.rn.f32.s32 	%f104, %r255;
	div.rn.f32 	%f105, %f104, 0f41C00000;
	add.f32 	%f106, %f105, %f105;
	mov.b32 	%r256, %f106;
	and.b32  	%r257, %r256, -2147483648;
	or.b32  	%r258, %r257, 1056964608;
	mov.b32 	%f107, %r258;
	add.f32 	%f108, %f106, %f107;
	cvt.rzi.f32.f32 	%f109, %f108;
	abs.f32 	%f110, %f106;
	setp.gt.f32 	%p23, %f110, 0f4B000000;
	selp.f32 	%f111, %f106, %f109, %p23;
	cvt.rzi.f32.f32 	%f112, %f106;
	setp.lt.f32 	%p24, %f110, 0f3F000000;
	selp.f32 	%f113, %f112, %f111, %p24;
	cvt.rzi.s32.f32 	%r259, %f113;
	fma.rn.f32 	%f114, %f113, 0fBF000000, %f105;
	mul.f32 	%f115, %f114, 0f34222169;
	fma.rn.f32 	%f116, %f114, 0f40490FDA, %f115;
	mul.f32 	%f117, %f116, %f116;
	fma.rn.f32 	%f118, %f117, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f119, %f118, %f117, 0f3D2AAABB;
	fma.rn.f32 	%f120, %f119, %f117, 0fBEFFFFFF;
	fma.rn.f32 	%f121, %f120, %f117, 0f3F800000;
	fma.rn.f32 	%f122, %f117, %f116, 0f00000000;
	fma.rn.f32 	%f123, %f117, 0fB94D4153, 0f3C0885E4;
	fma.rn.f32 	%f124, %f123, %f117, 0fBE2AAAA8;
	fma.rn.f32 	%f125, %f124, %f122, %f116;
	and.b32  	%r260, %r259, 1;
	setp.eq.b32 	%p25, %r260, 1;
	selp.f32 	%f126, %f121, %f125, %p25;
	selp.f32 	%f127, %f125, %f121, %p25;
	and.b32  	%r261, %r259, 2;
	setp.eq.s32 	%p26, %r261, 0;
	neg.f32 	%f128, %f126;
	selp.f32 	%f129, %f126, %f128, %p26;
	add.s32 	%r262, %r259, 1;
	and.b32  	%r263, %r262, 2;
	setp.eq.s32 	%p27, %r263, 0;
	sub.f32 	%f130, %f27, %f127;
	selp.f32 	%f131, %f127, %f130, %p27;
	cvt.rzi.f32.f32 	%f132, %f105;
	setp.eq.f32 	%p28, %f132, %f105;
	mul.f32 	%f133, %f105, 0f00000000;
	selp.f32 	%f134, %f133, %f129, %p28;
	abs.f32 	%f135, %f105;
	setp.gt.f32 	%p29, %f135, 0f4B800000;
	add.f32 	%f136, %f134, 0f3F800000;
	selp.f32 	%f137, %f136, %f131, %p29;
	shl.b32 	%r264, %r6, 3;
	add.s32 	%r265, %r255, %r264;
	cvt.rn.f32.s32 	%f138, %r265;
	div.rn.f32 	%f139, %f138, 0f41C00000;
	add.f32 	%f140, %f139, %f139;
	mov.b32 	%r266, %f140;
	and.b32  	%r267, %r266, -2147483648;
	or.b32  	%r268, %r267, 1056964608;
	mov.b32 	%f141, %r268;
	add.f32 	%f142, %f140, %f141;
	cvt.rzi.f32.f32 	%f143, %f142;
	abs.f32 	%f144, %f140;
	setp.gt.f32 	%p30, %f144, 0f4B000000;
	selp.f32 	%f145, %f140, %f143, %p30;
	cvt.rzi.f32.f32 	%f146, %f140;
	setp.lt.f32 	%p31, %f144, 0f3F000000;
	selp.f32 	%f147, %f146, %f145, %p31;
	cvt.rzi.s32.f32 	%r269, %f147;
	fma.rn.f32 	%f148, %f147, 0fBF000000, %f139;
	mul.f32 	%f149, %f148, 0f34222169;
	fma.rn.f32 	%f150, %f148, 0f40490FDA, %f149;
	mul.f32 	%f151, %f150, %f150;
	fma.rn.f32 	%f152, %f151, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f153, %f152, %f151, 0f3D2AAABB;
	fma.rn.f32 	%f154, %f153, %f151, 0fBEFFFFFF;
	fma.rn.f32 	%f155, %f154, %f151, 0f3F800000;
	fma.rn.f32 	%f156, %f151, %f150, 0f00000000;
	fma.rn.f32 	%f157, %f151, 0fB94D4153, 0f3C0885E4;
	fma.rn.f32 	%f158, %f157, %f151, 0fBE2AAAA8;
	fma.rn.f32 	%f159, %f158, %f156, %f150;
	and.b32  	%r270, %r269, 1;
	setp.eq.b32 	%p32, %r270, 1;
	selp.f32 	%f160, %f155, %f159, %p32;
	selp.f32 	%f161, %f159, %f155, %p32;
	and.b32  	%r271, %r269, 2;
	setp.eq.s32 	%p33, %r271, 0;
	neg.f32 	%f162, %f160;
	selp.f32 	%f163, %f160, %f162, %p33;
	add.s32 	%r272, %r269, 1;
	and.b32  	%r273, %r272, 2;
	setp.eq.s32 	%p34, %r273, 0;
	sub.f32 	%f164, %f27, %f161;
	selp.f32 	%f165, %f161, %f164, %p34;
	cvt.rzi.f32.f32 	%f166, %f139;
	setp.eq.f32 	%p35, %f166, %f139;
	mul.f32 	%f167, %f139, 0f00000000;
	selp.f32 	%f168, %f167, %f163, %p35;
	abs.f32 	%f169, %f139;
	setp.gt.f32 	%p36, %f169, 0f4B800000;
	add.f32 	%f170, %f168, 0f3F800000;
	selp.f32 	%f171, %f170, %f165, %p36;
	mov.b32 	%r211, %f137;
	mov.b32 	%r212, %f171;
	mov.b32 	%r217, %f134;
	xor.b32  	%r214, %r217, -2147483648;
	mov.b32 	%r218, %f168;
	xor.b32  	%r215, %r218, -2147483648;
	cvt.u16.u32 	%rs1, %r1;
	and.b16  	%rs2, %rs1, 255;
	mul.lo.s16 	%rs3, %rs2, 171;
	shr.u16 	%rs4, %rs3, 12;
	mul.lo.s16 	%rs5, %rs4, 24;
	sub.s16 	%rs6, %rs1, %rs5;
	cvt.u32.u16 	%r274, %rs6;
	and.b32  	%r16, %r274, 255;
	mad.lo.s32 	%r275, %r16, 24, %r2;
	and.b32  	%r276, %r275, 511;
	mul.wide.u32 	%rd20, %r276, 4;
	add.s64 	%rd21, %rd9, %rd20;
	setp.lt.u32 	%p37, %r1, 24;
	cvt.u16.u32 	%rs7, %r6;
	mul.lo.s16 	%rs8, %rs7, 171;
	shr.u16 	%rs9, %rs8, 10;
	mul.lo.s16 	%rs10, %rs9, 6;
	sub.s16 	%rs11, %rs7, %rs10;
	cvt.u32.u16 	%r277, %rs11;
	and.b32  	%r18, %r277, 255;
	@%p37 bra 	LBB0_4;
// %bb.3:                               // %L11.L833_crit_edge
	cvt.u16.u32 	%rs18, %r2;
	and.b16  	%rs19, %rs18, 255;
	mul.lo.s16 	%rs20, %rs19, 171;
	shr.u16 	%rs21, %rs20, 10;
	cvt.u32.u16 	%r2439, %rs21;
	mul.lo.s16 	%rs22, %rs21, -6;
	add.s16 	%rs23, %rs22, %rs18;
	cvt.u32.u16 	%r289, %rs23;
	and.b32  	%r2438, %r289, 255;
	mul.wide.u16 	%r2437, %rs21, 6;
	mov.u32 	%r2440, 0;
	mov.u32 	%r2441, %r2440;
	bra.uni 	LBB0_5;
LBB0_4:                                 // %L513
	ld.param.u64 	%rd2, [_Z14julia_frb_550613CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_3];
	mul.lo.s32 	%r278, %r18, 24;
	cvt.u16.u32 	%rs12, %r2;
	and.b16  	%rs13, %rs12, 255;
	mul.lo.s16 	%rs14, %rs13, 171;
	shr.u16 	%rs15, %rs14, 10;
	mul.lo.s16 	%rs16, %rs15, -6;
	add.s16 	%rs17, %rs16, %rs12;
	cvt.u32.u16 	%r280, %rs17;
	and.b32  	%r2438, %r280, 255;
	or.b32  	%r281, %r278, %r2438;
	cvt.u32.u16 	%r2439, %rs15;
	mul.wide.u16 	%r2437, %rs15, 6;
	add.s32 	%r282, %r281, %r2437;
	mul.lo.s32 	%r283, %r5, 144;
	add.s32 	%r284, %r282, %r283;
	mul.lo.s32 	%r285, %r4, 576;
	add.s32 	%r286, %r284, %r285;
	mul.wide.u32 	%rd22, %r286, 4;
	add.s64 	%rd23, %rd2, %rd22;
	ld.global.u32 	%r2440, [%rd23];
	cvt.u64.u32 	%rd24, %r285;
	cvt.u64.u32 	%rd25, %r283;
	cvt.u64.u32 	%rd26, %r2437;
	cvt.u64.u32 	%rd27, %r281;
	add.s64 	%rd28, %rd27, %rd26;
	add.s64 	%rd29, %rd28, %rd25;
	add.s64 	%rd30, %rd29, %rd24;
	shl.b64 	%rd31, %rd30, 2;
	add.s64 	%rd32, %rd2, %rd31;
	ld.global.u32 	%r2441, [%rd32+589824];
LBB0_5:                                 // %L833
	ld.param.u64 	%rd1, [_Z14julia_frb_550613CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_1];
	ld.param.u64 	%rd3, [_Z14julia_frb_550613CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_4];
	// begin inline asm
	cvt.rn.f16x2.f32 %r198, %r200, %r199;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r201, %r203, %r200;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r204, %r206, %r205;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r207, %r209, %r208;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r210, %r212, %r211;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r213, %r215, %r214;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r216, %r218, %r217;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r219, %r212, %r211;
	// end inline asm
	ld.global.u32 	%r17, [%rd21];
	mov.u32 	%r2436, 0;
	shl.b32 	%r291, %r1, 2;
	shl.b32 	%r292, %r1, 11;
	or.b32  	%r293, %r291, %r292;
	and.b32  	%r294, %r292, 32768;
	and.b32  	%r295, %r293, 32828;
	shl.b32 	%r296, %r4, 7;
	or.b32  	%r32, %r295, %r296;
	or.b32  	%r297, %r294, %r291;
	or.b32  	%r298, %r297, %r296;
	or.b32  	%r33, %r298, 64;
	shr.u32 	%r34, %r1, 4;
	and.b32  	%r299, %r9, 30;
	or.b32  	%r300, %r34, %r299;
	mul.lo.s32 	%r35, %r300, 257;
	or.b32  	%r301, %r9, %r34;
	or.b32  	%r302, %r301, 32;
	mul.lo.s32 	%r36, %r302, 257;
	and.b32  	%r37, %r3, 224;
	add.s32 	%r305, %r2, 504;
	bfe.u32 	%r306, %r305, 3, 6;
	mul.lo.s32 	%r39, %r306, 257;
	mul.lo.s32 	%r40, %r18, 801;
	mul.lo.s32 	%r41, %r2439, 198;
	mul.lo.s32 	%r42, %r2438, 33;
	mul.lo.s32 	%r43, %r5, 4806;
	bfe.u32 	%r307, %r1, 3, 1;
	mul.lo.s32 	%r308, %r307, 514;
	add.s32 	%r309, %r2437, %r308;
	add.s32 	%r310, %r309, %r2438;
	and.b32  	%r311, %r6, 1;
	mul.lo.s32 	%r312, %r311, 1028;
	add.s32 	%r313, %r310, %r312;
	bfe.u32 	%r314, %r1, 1, 1;
	mul.lo.s32 	%r315, %r314, 2056;
	add.s32 	%r316, %r313, %r315;
	and.b32  	%r317, %r1, 1;
	mul.lo.s32 	%r318, %r317, 4112;
	add.s32 	%r319, %r316, %r318;
	mul.lo.s32 	%r320, %r34, 257;
	add.s32 	%r44, %r319, %r320;
	mul.wide.u32 	%rd33, %r44, 4;
	mov.u64 	%rd34, shmem;
	add.s64 	%rd5, %rd34, %rd33;
	cvt.u64.u32 	%rd35, %r320;
	cvt.u64.u32 	%rd36, %r318;
	cvt.u64.u32 	%rd37, %r315;
	cvt.u64.u32 	%rd38, %r312;
	cvt.u64.u32 	%rd39, %r2438;
	cvt.u64.u32 	%rd40, %r2437;
	cvt.u64.u32 	%rd41, %r308;
	add.s64 	%rd42, %rd41, %rd40;
	add.s64 	%rd43, %rd42, %rd39;
	add.s64 	%rd44, %rd43, %rd38;
	add.s64 	%rd45, %rd44, %rd37;
	add.s64 	%rd46, %rd45, %rd36;
	add.s64 	%rd47, %rd46, %rd35;
	shl.b64 	%rd48, %rd47, 2;
	add.s64 	%rd6, %rd34, %rd48;
	bfe.u32 	%r321, %r2, 3, 1;
	mul.lo.s32 	%r45, %r321, 514;
	bfe.u32 	%r322, %r2, 2, 1;
	mul.lo.s32 	%r46, %r322, 1028;
	bfe.u32 	%r323, %r2, 1, 1;
	mul.lo.s32 	%r47, %r323, 2056;
	and.b32  	%r324, %r2, 1;
	mul.lo.s32 	%r48, %r324, 4112;
	shr.u32 	%r325, %r2, 4;
	mul.lo.s32 	%r49, %r325, 257;
	cvt.u16.u32 	%rs24, %r2;
	shl.b16 	%rs25, %rs24, 1;
	and.b16  	%rs26, %rs25, 254;
	mul.lo.s16 	%rs27, %rs26, 171;
	shr.u16 	%rs28, %rs27, 13;
	mul.lo.s16 	%rs29, %rs28, 48;
	sub.s16 	%rs30, %rs25, %rs29;
	and.b16  	%rs31, %rs30, 254;
	mul.wide.u16 	%r50, %rs31, 24;
	mul.lo.s32 	%r51, %r4, 1152;
	or.b16  	%rs32, %rs25, 1;
	and.b16  	%rs33, %rs32, 255;
	mul.lo.s16 	%rs34, %rs33, 171;
	shr.u16 	%rs35, %rs34, 13;
	mul.lo.s16 	%rs36, %rs35, 48;
	sub.s16 	%rs37, %rs32, %rs36;
	and.b16  	%rs38, %rs37, 255;
	mul.wide.u16 	%r52, %rs38, 24;
	cvt.u64.u32 	%rd49, %r43;
	cvt.u64.u32 	%rd50, %r42;
	cvt.u64.u32 	%rd51, %r41;
	cvt.u64.u32 	%rd52, %r40;
	add.s64 	%rd53, %rd52, %rd51;
	add.s64 	%rd54, %rd53, %rd50;
	add.s64 	%rd55, %rd54, %rd49;
	shl.b64 	%rd56, %rd55, 2;
	add.s64 	%rd7, %rd34, %rd56;
	setp.eq.s32 	%p38, %r34, 1;
	mov.u32 	%r2442, %r2436;
	mov.u32 	%r2480, %r2436;
	mov.u32 	%r2492, %r2436;
	mov.u32 	%r2482, %r2436;
	mov.u32 	%r2483, %r2436;
	mov.u32 	%r2484, %r2436;
	mov.u32 	%r2485, %r2436;
	bra.uni 	LBB0_6;
LBB0_17:                                // %L57642
                                        //   in Loop: Header=BB0_6 Depth=1
	add.s32 	%r172, %r2442, 48;
	setp.ne.s32 	%p57, %r2442, 2016;
	mov.u32 	%r2442, %r172;
	@%p57 bra 	LBB0_6;
	bra.uni 	LBB0_18;
LBB0_6:                                 // %L836
                                        // =>This Loop Header: Depth=1
                                        //     Child Loop BB0_8 Depth 2
                                        //       Child Loop BB0_9 Depth 3
	mul.hi.u32 	%r519, %r2442, -1431655765;
	shr.u32 	%r520, %r519, 5;
	mul.lo.s32 	%r60, %r520, 48;
	add.s32 	%r521, %r2, %r60;
	cvt.u16.u32 	%rs39, %r521;
	mul.hi.s16 	%rs40, %rs39, 16257;
	shr.u16 	%rs41, %rs40, 15;
	shr.s16 	%rs42, %rs40, 9;
	add.s16 	%rs43, %rs42, %rs41;
	mul.lo.s16 	%rs44, %rs43, 2064;
	sub.s16 	%rs45, %rs39, %rs44;
	cvt.u32.u16 	%r522, %rs45;
	shl.b32 	%r523, %r522, 16;
	or.b32  	%r524, %r32, %r523;
	mul.wide.s32 	%rd57, %r524, 4;
	add.s64 	%rd58, %rd1, %rd57;
	ld.global.v4.u32 	{%r525, %r526, %r527, %r528}, [%rd58];
	or.b32  	%r529, %r33, %r523;
	mul.wide.s32 	%rd59, %r529, 4;
	add.s64 	%rd60, %rd1, %rd59;
	ld.global.v4.u32 	{%r530, %r531, %r532, %r533}, [%rd60];
	add.s16 	%rs46, %rs39, 24;
	mul.hi.s16 	%rs47, %rs46, 16257;
	shr.u16 	%rs48, %rs47, 15;
	shr.s16 	%rs49, %rs47, 9;
	add.s16 	%rs50, %rs49, %rs48;
	mul.lo.s16 	%rs51, %rs50, 2064;
	sub.s16 	%rs52, %rs46, %rs51;
	cvt.u32.u16 	%r534, %rs52;
	shl.b32 	%r535, %r534, 16;
	or.b32  	%r536, %r32, %r535;
	mul.wide.s32 	%rd61, %r536, 4;
	add.s64 	%rd62, %rd1, %rd61;
	ld.global.v4.u32 	{%r537, %r538, %r539, %r540}, [%rd62];
	or.b32  	%r541, %r33, %r535;
	mul.wide.s32 	%rd63, %r541, 4;
	add.s64 	%rd64, %rd1, %rd63;
	ld.global.v4.u32 	{%r542, %r543, %r544, %r545}, [%rd64];
	selp.b32 	%r546, %r525, %r527, %p38;
	shfl.sync.bfly.b32	%r547, %r546, 16, 31, -1;
	selp.b32 	%r328, %r547, %r525, %p38;
	selp.b32 	%r333, %r527, %r547, %p38;
	selp.b32 	%r548, %r526, %r528, %p38;
	shfl.sync.bfly.b32	%r549, %r548, 16, 31, -1;
	selp.b32 	%r336, %r549, %r526, %p38;
	selp.b32 	%r341, %r528, %r549, %p38;
	selp.b32 	%r550, %r530, %r532, %p38;
	shfl.sync.bfly.b32	%r551, %r550, 16, 31, -1;
	selp.b32 	%r344, %r551, %r530, %p38;
	selp.b32 	%r349, %r532, %r551, %p38;
	selp.b32 	%r552, %r531, %r533, %p38;
	shfl.sync.bfly.b32	%r553, %r552, 16, 31, -1;
	selp.b32 	%r352, %r553, %r531, %p38;
	selp.b32 	%r357, %r533, %r553, %p38;
	selp.b32 	%r554, %r537, %r539, %p38;
	shfl.sync.bfly.b32	%r555, %r554, 16, 31, -1;
	selp.b32 	%r360, %r555, %r537, %p38;
	selp.b32 	%r365, %r539, %r555, %p38;
	selp.b32 	%r556, %r538, %r540, %p38;
	shfl.sync.bfly.b32	%r557, %r556, 16, 31, -1;
	selp.b32 	%r368, %r557, %r538, %p38;
	selp.b32 	%r373, %r540, %r557, %p38;
	selp.b32 	%r558, %r542, %r544, %p38;
	shfl.sync.bfly.b32	%r559, %r558, 16, 31, -1;
	selp.b32 	%r376, %r559, %r542, %p38;
	selp.b32 	%r381, %r544, %r559, %p38;
	selp.b32 	%r560, %r543, %r545, %p38;
	shfl.sync.bfly.b32	%r561, %r560, 16, 31, -1;
	selp.b32 	%r384, %r561, %r543, %p38;
	selp.b32 	%r389, %r545, %r561, %p38;
	shl.b32 	%r329, %r333, 4;
	mov.u32 	%r327, 252645135;
	// begin inline asm
	lop3.b32 %r391, %r327, %r328, %r329, 202;
	// end inline asm
	shr.u32 	%r332, %r328, 4;
	// begin inline asm
	lop3.b32 %r407, %r327, %r332, %r333, 202;
	// end inline asm
	shl.b32 	%r337, %r341, 4;
	// begin inline asm
	lop3.b32 %r399, %r327, %r336, %r337, 202;
	// end inline asm
	shr.u32 	%r340, %r336, 4;
	// begin inline asm
	lop3.b32 %r415, %r327, %r340, %r341, 202;
	// end inline asm
	shl.b32 	%r345, %r349, 4;
	// begin inline asm
	lop3.b32 %r423, %r327, %r344, %r345, 202;
	// end inline asm
	shr.u32 	%r348, %r344, 4;
	// begin inline asm
	lop3.b32 %r439, %r327, %r348, %r349, 202;
	// end inline asm
	shl.b32 	%r353, %r357, 4;
	// begin inline asm
	lop3.b32 %r431, %r327, %r352, %r353, 202;
	// end inline asm
	shr.u32 	%r356, %r352, 4;
	// begin inline asm
	lop3.b32 %r447, %r327, %r356, %r357, 202;
	// end inline asm
	shl.b32 	%r361, %r365, 4;
	// begin inline asm
	lop3.b32 %r392, %r327, %r360, %r361, 202;
	// end inline asm
	shr.u32 	%r364, %r360, 4;
	// begin inline asm
	lop3.b32 %r408, %r327, %r364, %r365, 202;
	// end inline asm
	shl.b32 	%r369, %r373, 4;
	// begin inline asm
	lop3.b32 %r400, %r327, %r368, %r369, 202;
	// end inline asm
	shr.u32 	%r372, %r368, 4;
	// begin inline asm
	lop3.b32 %r416, %r327, %r372, %r373, 202;
	// end inline asm
	shl.b32 	%r377, %r381, 4;
	// begin inline asm
	lop3.b32 %r424, %r327, %r376, %r377, 202;
	// end inline asm
	shr.u32 	%r380, %r376, 4;
	// begin inline asm
	lop3.b32 %r440, %r327, %r380, %r381, 202;
	// end inline asm
	shl.b32 	%r385, %r389, 4;
	// begin inline asm
	lop3.b32 %r432, %r327, %r384, %r385, 202;
	// end inline asm
	shr.u32 	%r388, %r384, 4;
	// begin inline asm
	lop3.b32 %r448, %r327, %r388, %r389, 202;
	// end inline asm
	mov.u32 	%r393, 25152;
	// begin inline asm
	prmt.b32 %r455, %r391, %r392, %r393;
	// end inline asm
	mov.u32 	%r397, 29521;
	// begin inline asm
	prmt.b32 %r487, %r391, %r392, %r397;
	// end inline asm
	// begin inline asm
	prmt.b32 %r463, %r399, %r400, %r393;
	// end inline asm
	// begin inline asm
	prmt.b32 %r495, %r399, %r400, %r397;
	// end inline asm
	// begin inline asm
	prmt.b32 %r456, %r407, %r408, %r393;
	// end inline asm
	// begin inline asm
	prmt.b32 %r488, %r407, %r408, %r397;
	// end inline asm
	// begin inline asm
	prmt.b32 %r464, %r415, %r416, %r393;
	// end inline asm
	// begin inline asm
	prmt.b32 %r496, %r415, %r416, %r397;
	// end inline asm
	// begin inline asm
	prmt.b32 %r471, %r423, %r424, %r393;
	// end inline asm
	// begin inline asm
	prmt.b32 %r503, %r423, %r424, %r397;
	// end inline asm
	// begin inline asm
	prmt.b32 %r479, %r431, %r432, %r393;
	// end inline asm
	// begin inline asm
	prmt.b32 %r511, %r431, %r432, %r397;
	// end inline asm
	// begin inline asm
	prmt.b32 %r472, %r439, %r440, %r393;
	// end inline asm
	// begin inline asm
	prmt.b32 %r504, %r439, %r440, %r397;
	// end inline asm
	// begin inline asm
	prmt.b32 %r480, %r447, %r448, %r393;
	// end inline asm
	// begin inline asm
	prmt.b32 %r512, %r447, %r448, %r397;
	// end inline asm
	mov.u32 	%r513, 21520;
	// begin inline asm
	prmt.b32 %r454, %r455, %r456, %r513;
	// end inline asm
	mov.u32 	%r517, 30258;
	// begin inline asm
	prmt.b32 %r458, %r455, %r456, %r517;
	// end inline asm
	// begin inline asm
	prmt.b32 %r462, %r463, %r464, %r513;
	// end inline asm
	// begin inline asm
	prmt.b32 %r466, %r463, %r464, %r517;
	// end inline asm
	// begin inline asm
	prmt.b32 %r470, %r471, %r472, %r513;
	// end inline asm
	// begin inline asm
	prmt.b32 %r474, %r471, %r472, %r517;
	// end inline asm
	// begin inline asm
	prmt.b32 %r478, %r479, %r480, %r513;
	// end inline asm
	// begin inline asm
	prmt.b32 %r482, %r479, %r480, %r517;
	// end inline asm
	// begin inline asm
	prmt.b32 %r486, %r487, %r488, %r513;
	// end inline asm
	// begin inline asm
	prmt.b32 %r490, %r487, %r488, %r517;
	// end inline asm
	// begin inline asm
	prmt.b32 %r494, %r495, %r496, %r513;
	// end inline asm
	// begin inline asm
	prmt.b32 %r498, %r495, %r496, %r517;
	// end inline asm
	// begin inline asm
	prmt.b32 %r502, %r503, %r504, %r513;
	// end inline asm
	// begin inline asm
	prmt.b32 %r506, %r503, %r504, %r517;
	// end inline asm
	// begin inline asm
	prmt.b32 %r510, %r511, %r512, %r513;
	// end inline asm
	// begin inline asm
	prmt.b32 %r514, %r511, %r512, %r517;
	// end inline asm
	mul.hi.s16 	%rs53, %rs39, 10923;
	shr.u16 	%rs54, %rs53, 15;
	shr.s16 	%rs55, %rs53, 2;
	add.s16 	%rs56, %rs55, %rs54;
	mul.lo.s16 	%rs57, %rs56, 24;
	sub.s16 	%rs58, %rs39, %rs57;
	cvt.s32.s16 	%r562, %rs58;
	add.s32 	%r563, %r35, %r562;
	mul.wide.s32 	%rd65, %r563, 4;
	add.s64 	%rd67, %rd34, %rd65;
	st.shared.u32 	[%rd67], %r454;
	st.shared.u32 	[%rd67+512], %r462;
	st.shared.u32 	[%rd67+256], %r458;
	st.shared.u32 	[%rd67+768], %r466;
	add.s32 	%r564, %r36, %r562;
	mul.wide.s32 	%rd68, %r564, 4;
	add.s64 	%rd69, %rd34, %rd68;
	st.shared.u32 	[%rd69], %r470;
	st.shared.u32 	[%rd69+512], %r478;
	st.shared.u32 	[%rd69+256], %r474;
	st.shared.u32 	[%rd69+768], %r482;
	st.shared.u32 	[%rd67+128], %r486;
	st.shared.u32 	[%rd67+640], %r494;
	st.shared.u32 	[%rd67+384], %r490;
	st.shared.u32 	[%rd67+896], %r498;
	st.shared.u32 	[%rd69+128], %r502;
	st.shared.u32 	[%rd69+640], %r510;
	st.shared.u32 	[%rd69+384], %r506;
	st.shared.u32 	[%rd69+896], %r514;
	bar.sync 	0;
	add.s32 	%r565, %r60, %r16;
	cvt.u16.u32 	%rs59, %r565;
	mul.hi.s16 	%rs60, %rs59, 10923;
	shr.u16 	%rs61, %rs60, 15;
	shr.s16 	%rs62, %rs60, 2;
	add.s16 	%rs63, %rs62, %rs61;
	mul.lo.s16 	%rs64, %rs63, 24;
	sub.s16 	%rs65, %rs59, %rs64;
	cvt.s32.s16 	%r566, %rs65;
	add.s32 	%r567, %r39, %r566;
	add.s32 	%r568, %r567, %r37;
	mul.wide.s32 	%rd70, %r568, 4;
	add.s64 	%rd71, %rd34, %rd70;
	ld.shared.u32 	%r569, [%rd71];
	bar.sync 	0;
	shfl.sync.idx.b32	%r570, %r17, 0, 31, -1;
	shfl.sync.idx.b32	%r571, %r17, 1, 31, -1;
	shfl.sync.idx.b32	%r572, %r17, 2, 31, -1;
	shfl.sync.idx.b32	%r573, %r17, 3, 31, -1;
	shfl.sync.idx.b32	%r574, %r17, 4, 31, -1;
	shfl.sync.idx.b32	%r575, %r17, 5, 31, -1;
	shfl.sync.idx.b32	%r576, %r17, 6, 31, -1;
	shfl.sync.idx.b32	%r577, %r17, 7, 31, -1;
	shfl.sync.idx.b32	%r578, %r17, 8, 31, -1;
	shfl.sync.idx.b32	%r579, %r17, 9, 31, -1;
	shfl.sync.idx.b32	%r580, %r17, 10, 31, -1;
	shfl.sync.idx.b32	%r581, %r17, 11, 31, -1;
	shfl.sync.idx.b32	%r582, %r17, 12, 31, -1;
	shfl.sync.idx.b32	%r583, %r17, 13, 31, -1;
	shfl.sync.idx.b32	%r584, %r17, 14, 31, -1;
	shfl.sync.idx.b32	%r585, %r17, 15, 31, -1;
	shfl.sync.idx.b32	%r586, %r17, 16, 31, -1;
	shfl.sync.idx.b32	%r587, %r17, 17, 31, -1;
	shfl.sync.idx.b32	%r588, %r17, 18, 31, -1;
	shfl.sync.idx.b32	%r589, %r17, 19, 31, -1;
	shfl.sync.idx.b32	%r590, %r17, 20, 31, -1;
	shfl.sync.idx.b32	%r591, %r17, 21, 31, -1;
	shfl.sync.idx.b32	%r592, %r17, 22, 31, -1;
	shfl.sync.idx.b32	%r593, %r17, 23, 31, -1;
	add.s32 	%r594, %r570, %r566;
	mul.wide.s32 	%rd72, %r594, 4;
	add.s64 	%rd73, %rd34, %rd72;
	st.shared.u32 	[%rd73], %r569;
	add.s32 	%r595, %r571, %r566;
	mul.wide.s32 	%rd74, %r595, 4;
	add.s64 	%rd75, %rd34, %rd74;
	st.shared.u32 	[%rd75], %r569;
	add.s32 	%r596, %r572, %r566;
	mul.wide.s32 	%rd76, %r596, 4;
	add.s64 	%rd77, %rd34, %rd76;
	st.shared.u32 	[%rd77], %r569;
	add.s32 	%r597, %r573, %r566;
	mul.wide.s32 	%rd78, %r597, 4;
	add.s64 	%rd79, %rd34, %rd78;
	st.shared.u32 	[%rd79], %r569;
	add.s32 	%r598, %r574, %r566;
	mul.wide.s32 	%rd80, %r598, 4;
	add.s64 	%rd81, %rd34, %rd80;
	st.shared.u32 	[%rd81], %r569;
	add.s32 	%r599, %r575, %r566;
	mul.wide.s32 	%rd82, %r599, 4;
	add.s64 	%rd83, %rd34, %rd82;
	st.shared.u32 	[%rd83], %r569;
	add.s32 	%r600, %r576, %r566;
	mul.wide.s32 	%rd84, %r600, 4;
	add.s64 	%rd85, %rd34, %rd84;
	st.shared.u32 	[%rd85], %r569;
	add.s32 	%r601, %r577, %r566;
	mul.wide.s32 	%rd86, %r601, 4;
	add.s64 	%rd87, %rd34, %rd86;
	st.shared.u32 	[%rd87], %r569;
	add.s32 	%r602, %r578, %r566;
	mul.wide.s32 	%rd88, %r602, 4;
	add.s64 	%rd89, %rd34, %rd88;
	st.shared.u32 	[%rd89], %r569;
	add.s32 	%r603, %r579, %r566;
	mul.wide.s32 	%rd90, %r603, 4;
	add.s64 	%rd91, %rd34, %rd90;
	st.shared.u32 	[%rd91], %r569;
	add.s32 	%r604, %r580, %r566;
	mul.wide.s32 	%rd92, %r604, 4;
	add.s64 	%rd93, %rd34, %rd92;
	st.shared.u32 	[%rd93], %r569;
	add.s32 	%r605, %r581, %r566;
	mul.wide.s32 	%rd94, %r605, 4;
	add.s64 	%rd95, %rd34, %rd94;
	st.shared.u32 	[%rd95], %r569;
	add.s32 	%r606, %r582, %r566;
	mul.wide.s32 	%rd96, %r606, 4;
	add.s64 	%rd97, %rd34, %rd96;
	st.shared.u32 	[%rd97], %r569;
	add.s32 	%r607, %r583, %r566;
	mul.wide.s32 	%rd98, %r607, 4;
	add.s64 	%rd99, %rd34, %rd98;
	st.shared.u32 	[%rd99], %r569;
	add.s32 	%r608, %r584, %r566;
	mul.wide.s32 	%rd100, %r608, 4;
	add.s64 	%rd101, %rd34, %rd100;
	st.shared.u32 	[%rd101], %r569;
	add.s32 	%r609, %r585, %r566;
	mul.wide.s32 	%rd102, %r609, 4;
	add.s64 	%rd103, %rd34, %rd102;
	st.shared.u32 	[%rd103], %r569;
	add.s32 	%r610, %r586, %r566;
	mul.wide.s32 	%rd104, %r610, 4;
	add.s64 	%rd105, %rd34, %rd104;
	st.shared.u32 	[%rd105], %r569;
	add.s32 	%r611, %r587, %r566;
	mul.wide.s32 	%rd106, %r611, 4;
	add.s64 	%rd107, %rd34, %rd106;
	st.shared.u32 	[%rd107], %r569;
	add.s32 	%r612, %r588, %r566;
	mul.wide.s32 	%rd108, %r612, 4;
	add.s64 	%rd109, %rd34, %rd108;
	st.shared.u32 	[%rd109], %r569;
	add.s32 	%r613, %r589, %r566;
	mul.wide.s32 	%rd110, %r613, 4;
	add.s64 	%rd111, %rd34, %rd110;
	st.shared.u32 	[%rd111], %r569;
	add.s32 	%r614, %r590, %r566;
	mul.wide.s32 	%rd112, %r614, 4;
	add.s64 	%rd113, %rd34, %rd112;
	st.shared.u32 	[%rd113], %r569;
	add.s32 	%r615, %r591, %r566;
	mul.wide.s32 	%rd114, %r615, 4;
	add.s64 	%rd115, %rd34, %rd114;
	st.shared.u32 	[%rd115], %r569;
	add.s32 	%r616, %r592, %r566;
	mul.wide.s32 	%rd116, %r616, 4;
	add.s64 	%rd117, %rd34, %rd116;
	st.shared.u32 	[%rd117], %r2436;
	add.s32 	%r617, %r593, %r566;
	mul.wide.s32 	%rd118, %r617, 4;
	add.s64 	%rd119, %rd34, %rd118;
	st.shared.u32 	[%rd119], %r2436;
	bar.sync 	0;
	mov.u32 	%r2449, %r2436;
	mov.u32 	%r2450, %r2436;
	mov.u32 	%r2451, %r2436;
	mov.u32 	%r2452, %r2436;
	mov.u32 	%r2453, %r2436;
	mov.u32 	%r2454, %r2436;
	mov.u32 	%r2455, %r2436;
	mov.u32 	%r2456, %r2436;
	mov.u32 	%r2457, %r2436;
	mov.u32 	%r2458, %r2436;
	mov.u32 	%r2459, %r2436;
	mov.u32 	%r2460, %r2436;
	mov.u32 	%r2461, %r2436;
	mov.u32 	%r2462, %r2436;
	mov.u32 	%r2463, %r2436;
	mov.u32 	%r2464, %r2436;
	mov.u32 	%r2465, %r2436;
	mov.u32 	%r2466, %r2436;
	mov.u32 	%r2467, %r2436;
	mov.u32 	%r2468, %r2436;
	mov.u32 	%r2469, %r2436;
	mov.u32 	%r2470, %r2436;
	mov.u32 	%r2471, %r2436;
	mov.u32 	%r2472, %r2436;
	@%p37 bra 	LBB0_19;
	bra.uni 	LBB0_7;
LBB0_19:                                // %oksrem15879
                                        //   in Loop: Header=BB0_6 Depth=1
	cvt.u16.u32 	%rs66, %r60;
	mul.hi.s16 	%rs67, %rs66, 10923;
	shr.u16 	%rs68, %rs67, 15;
	shr.s16 	%rs69, %rs67, 2;
	add.s16 	%rs70, %rs69, %rs68;
	mul.lo.s16 	%rs71, %rs70, 24;
	sub.s16 	%rs72, %rs66, %rs71;
	cvt.s32.s16 	%r618, %rs72;
	add.s32 	%r619, %r40, %r618;
	add.s32 	%r620, %r619, %r41;
	add.s32 	%r621, %r620, %r42;
	add.s32 	%r622, %r621, %r43;
	mul.wide.s32 	%rd120, %r622, 4;
	add.s64 	%rd122, %rd34, %rd120;
	ld.shared.u32 	%r2449, [%rd122];
	ld.shared.u32 	%r2450, [%rd7+4];
	ld.shared.u32 	%r2451, [%rd7+8];
	ld.shared.u32 	%r2452, [%rd7+12];
	ld.shared.u32 	%r2453, [%rd7+16];
	ld.shared.u32 	%r2454, [%rd7+20];
	ld.shared.u32 	%r2455, [%rd7+24];
	ld.shared.u32 	%r2456, [%rd7+28];
	ld.shared.u32 	%r2457, [%rd7+32];
	ld.shared.u32 	%r2458, [%rd7+36];
	ld.shared.u32 	%r2459, [%rd7+40];
	ld.shared.u32 	%r2460, [%rd7+44];
	ld.shared.u32 	%r2461, [%rd7+48];
	ld.shared.u32 	%r2462, [%rd7+52];
	ld.shared.u32 	%r2463, [%rd7+56];
	ld.shared.u32 	%r2464, [%rd7+60];
	add.s16 	%rs73, %rs66, 16;
	mul.hi.s16 	%rs74, %rs73, 10923;
	shr.u16 	%rs75, %rs74, 15;
	shr.s16 	%rs76, %rs74, 2;
	add.s16 	%rs77, %rs76, %rs75;
	mul.lo.s16 	%rs78, %rs77, 24;
	sub.s16 	%rs79, %rs73, %rs78;
	cvt.s32.s16 	%r623, %rs79;
	add.s32 	%r624, %r40, %r623;
	add.s32 	%r625, %r624, %r41;
	add.s32 	%r626, %r625, %r42;
	add.s32 	%r627, %r626, %r43;
	mul.wide.s32 	%rd123, %r627, 4;
	add.s64 	%rd124, %rd34, %rd123;
	ld.shared.u32 	%r2465, [%rd124];
	add.s16 	%rs80, %rs66, 17;
	mul.hi.s16 	%rs81, %rs80, 10923;
	shr.u16 	%rs82, %rs81, 15;
	shr.s16 	%rs83, %rs81, 2;
	add.s16 	%rs84, %rs83, %rs82;
	mul.lo.s16 	%rs85, %rs84, 24;
	sub.s16 	%rs86, %rs80, %rs85;
	cvt.s32.s16 	%r628, %rs86;
	add.s32 	%r629, %r40, %r628;
	add.s32 	%r630, %r629, %r41;
	add.s32 	%r631, %r630, %r42;
	add.s32 	%r632, %r631, %r43;
	mul.wide.s32 	%rd125, %r632, 4;
	add.s64 	%rd126, %rd34, %rd125;
	ld.shared.u32 	%r2466, [%rd126];
	add.s16 	%rs87, %rs66, 18;
	mul.hi.s16 	%rs88, %rs87, 10923;
	shr.u16 	%rs89, %rs88, 15;
	shr.s16 	%rs90, %rs88, 2;
	add.s16 	%rs91, %rs90, %rs89;
	mul.lo.s16 	%rs92, %rs91, 24;
	sub.s16 	%rs93, %rs87, %rs92;
	cvt.s32.s16 	%r633, %rs93;
	add.s32 	%r634, %r40, %r633;
	add.s32 	%r635, %r634, %r41;
	add.s32 	%r636, %r635, %r42;
	add.s32 	%r637, %r636, %r43;
	mul.wide.s32 	%rd127, %r637, 4;
	add.s64 	%rd128, %rd34, %rd127;
	ld.shared.u32 	%r2467, [%rd128];
	add.s16 	%rs94, %rs66, 19;
	mul.hi.s16 	%rs95, %rs94, 10923;
	shr.u16 	%rs96, %rs95, 15;
	shr.s16 	%rs97, %rs95, 2;
	add.s16 	%rs98, %rs97, %rs96;
	mul.lo.s16 	%rs99, %rs98, 24;
	sub.s16 	%rs100, %rs94, %rs99;
	cvt.s32.s16 	%r638, %rs100;
	add.s32 	%r639, %r40, %r638;
	add.s32 	%r640, %r639, %r41;
	add.s32 	%r641, %r640, %r42;
	add.s32 	%r642, %r641, %r43;
	mul.wide.s32 	%rd129, %r642, 4;
	add.s64 	%rd130, %rd34, %rd129;
	ld.shared.u32 	%r2468, [%rd130];
	add.s16 	%rs101, %rs66, 20;
	mul.hi.s16 	%rs102, %rs101, 10923;
	shr.u16 	%rs103, %rs102, 15;
	shr.s16 	%rs104, %rs102, 2;
	add.s16 	%rs105, %rs104, %rs103;
	mul.lo.s16 	%rs106, %rs105, 24;
	sub.s16 	%rs107, %rs101, %rs106;
	cvt.s32.s16 	%r643, %rs107;
	add.s32 	%r644, %r40, %r643;
	add.s32 	%r645, %r644, %r41;
	add.s32 	%r646, %r645, %r42;
	add.s32 	%r647, %r646, %r43;
	mul.wide.s32 	%rd131, %r647, 4;
	add.s64 	%rd132, %rd34, %rd131;
	ld.shared.u32 	%r2469, [%rd132];
	add.s16 	%rs108, %rs66, 21;
	mul.hi.s16 	%rs109, %rs108, 10923;
	shr.u16 	%rs110, %rs109, 15;
	shr.s16 	%rs111, %rs109, 2;
	add.s16 	%rs112, %rs111, %rs110;
	mul.lo.s16 	%rs113, %rs112, 24;
	sub.s16 	%rs114, %rs108, %rs113;
	cvt.s32.s16 	%r648, %rs114;
	add.s32 	%r649, %r40, %r648;
	add.s32 	%r650, %r649, %r41;
	add.s32 	%r651, %r650, %r42;
	add.s32 	%r652, %r651, %r43;
	mul.wide.s32 	%rd133, %r652, 4;
	add.s64 	%rd134, %rd34, %rd133;
	ld.shared.u32 	%r2470, [%rd134];
	add.s16 	%rs115, %rs66, 22;
	mul.hi.s16 	%rs116, %rs115, 10923;
	shr.u16 	%rs117, %rs116, 15;
	shr.s16 	%rs118, %rs116, 2;
	add.s16 	%rs119, %rs118, %rs117;
	mul.lo.s16 	%rs120, %rs119, 24;
	sub.s16 	%rs121, %rs115, %rs120;
	cvt.s32.s16 	%r653, %rs121;
	add.s32 	%r654, %r40, %r653;
	add.s32 	%r655, %r654, %r41;
	add.s32 	%r656, %r655, %r42;
	add.s32 	%r657, %r656, %r43;
	mul.wide.s32 	%rd135, %r657, 4;
	add.s64 	%rd136, %rd34, %rd135;
	ld.shared.u32 	%r2471, [%rd136];
	add.s16 	%rs122, %rs66, 23;
	mul.hi.s16 	%rs123, %rs122, 10923;
	shr.u16 	%rs124, %rs123, 15;
	shr.s16 	%rs125, %rs123, 2;
	add.s16 	%rs126, %rs125, %rs124;
	mul.lo.s16 	%rs127, %rs126, 24;
	sub.s16 	%rs128, %rs122, %rs127;
	cvt.s32.s16 	%r658, %rs128;
	add.s32 	%r659, %r40, %r658;
	add.s32 	%r660, %r659, %r41;
	add.s32 	%r661, %r660, %r42;
	add.s32 	%r662, %r661, %r43;
	mul.wide.s32 	%rd137, %r662, 4;
	add.s64 	%rd138, %rd34, %rd137;
	ld.shared.u32 	%r2472, [%rd138];
LBB0_7:                                 // %L48625
                                        //   in Loop: Header=BB0_6 Depth=1
	bar.sync 	0;
	xor.b32  	%r668, %r2449, -2004318072;
	shr.u32 	%r690, %r668, 8;
	xor.b32  	%r714, %r2450, -2004318072;
	shr.u32 	%r736, %r714, 8;
	xor.b32  	%r760, %r2451, -2004318072;
	shr.u32 	%r782, %r760, 8;
	xor.b32  	%r806, %r2452, -2004318072;
	shr.u32 	%r828, %r806, 8;
	xor.b32  	%r852, %r2453, -2004318072;
	shr.u32 	%r874, %r852, 8;
	xor.b32  	%r898, %r2454, -2004318072;
	shr.u32 	%r920, %r898, 8;
	xor.b32  	%r944, %r2455, -2004318072;
	shr.u32 	%r966, %r944, 8;
	xor.b32  	%r990, %r2456, -2004318072;
	shr.u32 	%r1012, %r990, 8;
	xor.b32  	%r1036, %r2457, -2004318072;
	shr.u32 	%r1058, %r1036, 8;
	xor.b32  	%r1082, %r2458, -2004318072;
	shr.u32 	%r1104, %r1082, 8;
	xor.b32  	%r1128, %r2459, -2004318072;
	shr.u32 	%r1150, %r1128, 8;
	xor.b32  	%r1174, %r2460, -2004318072;
	shr.u32 	%r1196, %r1174, 8;
	xor.b32  	%r1220, %r2461, -2004318072;
	shr.u32 	%r1242, %r1220, 8;
	xor.b32  	%r1266, %r2462, -2004318072;
	shr.u32 	%r1288, %r1266, 8;
	xor.b32  	%r1312, %r2463, -2004318072;
	shr.u32 	%r1334, %r1312, 8;
	xor.b32  	%r1358, %r2464, -2004318072;
	shr.u32 	%r1380, %r1358, 8;
	xor.b32  	%r1404, %r2465, -2004318072;
	shr.u32 	%r1426, %r1404, 8;
	xor.b32  	%r1450, %r2466, -2004318072;
	shr.u32 	%r1472, %r1450, 8;
	xor.b32  	%r1496, %r2467, -2004318072;
	shr.u32 	%r1518, %r1496, 8;
	xor.b32  	%r1542, %r2468, -2004318072;
	shr.u32 	%r1564, %r1542, 8;
	xor.b32  	%r1588, %r2469, -2004318072;
	shr.u32 	%r1610, %r1588, 8;
	xor.b32  	%r1634, %r2470, -2004318072;
	shr.u32 	%r1656, %r1634, 8;
	xor.b32  	%r1680, %r2471, -2004318072;
	shr.u32 	%r1702, %r1680, 8;
	xor.b32  	%r1726, %r2472, -2004318072;
	shr.u32 	%r1748, %r1726, 8;
	add.s32 	%r133, %r60, 1;
	add.s32 	%r134, %r60, 2;
	add.s32 	%r135, %r60, 3;
	mov.u32 	%r2479, %r2436;
	bra.uni 	LBB0_8;
LBB0_16:                                // %L57622
                                        //   in Loop: Header=BB0_8 Depth=2
	setp.ne.s32 	%p56, %r2479, 44;
	bar.sync 	0;
	add.s32 	%r2479, %r2479, 4;
	@%p56 bra 	LBB0_8;
	bra.uni 	LBB0_17;
LBB0_8:                                 // %L48651
                                        //   Parent Loop BB0_6 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB0_9 Depth 3
	mov.u16 	%rs129, 25600;
	// begin inline asm
	mov.b32 %r669, {%rs129, %rs129};
	// end inline asm
	mov.u16 	%rs131, 21504;
	// begin inline asm
	mov.b32 %r680, {%rs131, %rs131};
	// end inline asm
	mov.u32 	%r667, 983055;
	// begin inline asm
	lop3.b32 %r675, %r667, %r668, %r669, 202;
	// end inline asm
	mov.u16 	%rs133, 18432;
	// begin inline asm
	mov.b32 %r673, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r676, %r669, %r673;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r674, %r675, %r676;
	// end inline asm
	mov.u32 	%r678, 15728880;
	// begin inline asm
	lop3.b32 %r686, %r678, %r668, %r680, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r684, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r687, %r680, %r684;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r685, %r686, %r687;
	// end inline asm
	// begin inline asm
	lop3.b32 %r697, %r667, %r690, %r669, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r695, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r698, %r669, %r695;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r696, %r697, %r698;
	// end inline asm
	// begin inline asm
	lop3.b32 %r708, %r678, %r690, %r680, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r706, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r709, %r680, %r706;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r707, %r708, %r709;
	// end inline asm
	// begin inline asm
	mov.b32 %r715, {%rs129, %rs129};
	// end inline asm
	// begin inline asm
	mov.b32 %r726, {%rs131, %rs131};
	// end inline asm
	// begin inline asm
	lop3.b32 %r721, %r667, %r714, %r715, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r719, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r722, %r715, %r719;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r720, %r721, %r722;
	// end inline asm
	// begin inline asm
	lop3.b32 %r732, %r678, %r714, %r726, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r730, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r733, %r726, %r730;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r731, %r732, %r733;
	// end inline asm
	// begin inline asm
	lop3.b32 %r743, %r667, %r736, %r715, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r741, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r744, %r715, %r741;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r742, %r743, %r744;
	// end inline asm
	// begin inline asm
	lop3.b32 %r754, %r678, %r736, %r726, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r752, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r755, %r726, %r752;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r753, %r754, %r755;
	// end inline asm
	// begin inline asm
	mov.b32 %r761, {%rs129, %rs129};
	// end inline asm
	// begin inline asm
	mov.b32 %r772, {%rs131, %rs131};
	// end inline asm
	// begin inline asm
	lop3.b32 %r767, %r667, %r760, %r761, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r765, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r768, %r761, %r765;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r766, %r767, %r768;
	// end inline asm
	// begin inline asm
	lop3.b32 %r778, %r678, %r760, %r772, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r776, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r779, %r772, %r776;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r777, %r778, %r779;
	// end inline asm
	// begin inline asm
	lop3.b32 %r789, %r667, %r782, %r761, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r787, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r790, %r761, %r787;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r788, %r789, %r790;
	// end inline asm
	// begin inline asm
	lop3.b32 %r800, %r678, %r782, %r772, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r798, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r801, %r772, %r798;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r799, %r800, %r801;
	// end inline asm
	// begin inline asm
	mov.b32 %r807, {%rs129, %rs129};
	// end inline asm
	// begin inline asm
	mov.b32 %r818, {%rs131, %rs131};
	// end inline asm
	// begin inline asm
	lop3.b32 %r813, %r667, %r806, %r807, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r811, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r814, %r807, %r811;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r812, %r813, %r814;
	// end inline asm
	// begin inline asm
	lop3.b32 %r824, %r678, %r806, %r818, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r822, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r825, %r818, %r822;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r823, %r824, %r825;
	// end inline asm
	// begin inline asm
	lop3.b32 %r835, %r667, %r828, %r807, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r833, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r836, %r807, %r833;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r834, %r835, %r836;
	// end inline asm
	// begin inline asm
	lop3.b32 %r846, %r678, %r828, %r818, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r844, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r847, %r818, %r844;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r845, %r846, %r847;
	// end inline asm
	// begin inline asm
	mov.b32 %r853, {%rs129, %rs129};
	// end inline asm
	// begin inline asm
	mov.b32 %r864, {%rs131, %rs131};
	// end inline asm
	// begin inline asm
	lop3.b32 %r859, %r667, %r852, %r853, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r857, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r860, %r853, %r857;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r858, %r859, %r860;
	// end inline asm
	// begin inline asm
	lop3.b32 %r870, %r678, %r852, %r864, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r868, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r871, %r864, %r868;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r869, %r870, %r871;
	// end inline asm
	// begin inline asm
	lop3.b32 %r881, %r667, %r874, %r853, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r879, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r882, %r853, %r879;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r880, %r881, %r882;
	// end inline asm
	// begin inline asm
	lop3.b32 %r892, %r678, %r874, %r864, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r890, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r893, %r864, %r890;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r891, %r892, %r893;
	// end inline asm
	// begin inline asm
	mov.b32 %r899, {%rs129, %rs129};
	// end inline asm
	// begin inline asm
	mov.b32 %r910, {%rs131, %rs131};
	// end inline asm
	// begin inline asm
	lop3.b32 %r905, %r667, %r898, %r899, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r903, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r906, %r899, %r903;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r904, %r905, %r906;
	// end inline asm
	// begin inline asm
	lop3.b32 %r916, %r678, %r898, %r910, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r914, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r917, %r910, %r914;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r915, %r916, %r917;
	// end inline asm
	// begin inline asm
	lop3.b32 %r927, %r667, %r920, %r899, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r925, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r928, %r899, %r925;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r926, %r927, %r928;
	// end inline asm
	// begin inline asm
	lop3.b32 %r938, %r678, %r920, %r910, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r936, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r939, %r910, %r936;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r937, %r938, %r939;
	// end inline asm
	// begin inline asm
	mov.b32 %r945, {%rs129, %rs129};
	// end inline asm
	// begin inline asm
	mov.b32 %r956, {%rs131, %rs131};
	// end inline asm
	// begin inline asm
	lop3.b32 %r951, %r667, %r944, %r945, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r949, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r952, %r945, %r949;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r950, %r951, %r952;
	// end inline asm
	// begin inline asm
	lop3.b32 %r962, %r678, %r944, %r956, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r960, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r963, %r956, %r960;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r961, %r962, %r963;
	// end inline asm
	// begin inline asm
	lop3.b32 %r973, %r667, %r966, %r945, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r971, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r974, %r945, %r971;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r972, %r973, %r974;
	// end inline asm
	// begin inline asm
	lop3.b32 %r984, %r678, %r966, %r956, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r982, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r985, %r956, %r982;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r983, %r984, %r985;
	// end inline asm
	// begin inline asm
	mov.b32 %r991, {%rs129, %rs129};
	// end inline asm
	// begin inline asm
	mov.b32 %r1002, {%rs131, %rs131};
	// end inline asm
	// begin inline asm
	lop3.b32 %r997, %r667, %r990, %r991, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r995, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r998, %r991, %r995;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r996, %r997, %r998;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1008, %r678, %r990, %r1002, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1006, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1009, %r1002, %r1006;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1007, %r1008, %r1009;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1019, %r667, %r1012, %r991, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1017, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1020, %r991, %r1017;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1018, %r1019, %r1020;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1030, %r678, %r1012, %r1002, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1028, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1031, %r1002, %r1028;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1029, %r1030, %r1031;
	// end inline asm
	// begin inline asm
	mov.b32 %r1037, {%rs129, %rs129};
	// end inline asm
	// begin inline asm
	mov.b32 %r1048, {%rs131, %rs131};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1043, %r667, %r1036, %r1037, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1041, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1044, %r1037, %r1041;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1042, %r1043, %r1044;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1054, %r678, %r1036, %r1048, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1052, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1055, %r1048, %r1052;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1053, %r1054, %r1055;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1065, %r667, %r1058, %r1037, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1063, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1066, %r1037, %r1063;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1064, %r1065, %r1066;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1076, %r678, %r1058, %r1048, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1074, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1077, %r1048, %r1074;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1075, %r1076, %r1077;
	// end inline asm
	// begin inline asm
	mov.b32 %r1083, {%rs129, %rs129};
	// end inline asm
	// begin inline asm
	mov.b32 %r1094, {%rs131, %rs131};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1089, %r667, %r1082, %r1083, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1087, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1090, %r1083, %r1087;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1088, %r1089, %r1090;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1100, %r678, %r1082, %r1094, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1098, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1101, %r1094, %r1098;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1099, %r1100, %r1101;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1111, %r667, %r1104, %r1083, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1109, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1112, %r1083, %r1109;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1110, %r1111, %r1112;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1122, %r678, %r1104, %r1094, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1120, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1123, %r1094, %r1120;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1121, %r1122, %r1123;
	// end inline asm
	// begin inline asm
	mov.b32 %r1129, {%rs129, %rs129};
	// end inline asm
	// begin inline asm
	mov.b32 %r1140, {%rs131, %rs131};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1135, %r667, %r1128, %r1129, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1133, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1136, %r1129, %r1133;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1134, %r1135, %r1136;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1146, %r678, %r1128, %r1140, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1144, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1147, %r1140, %r1144;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1145, %r1146, %r1147;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1157, %r667, %r1150, %r1129, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1155, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1158, %r1129, %r1155;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1156, %r1157, %r1158;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1168, %r678, %r1150, %r1140, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1166, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1169, %r1140, %r1166;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1167, %r1168, %r1169;
	// end inline asm
	// begin inline asm
	mov.b32 %r1175, {%rs129, %rs129};
	// end inline asm
	// begin inline asm
	mov.b32 %r1186, {%rs131, %rs131};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1181, %r667, %r1174, %r1175, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1179, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1182, %r1175, %r1179;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1180, %r1181, %r1182;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1192, %r678, %r1174, %r1186, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1190, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1193, %r1186, %r1190;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1191, %r1192, %r1193;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1203, %r667, %r1196, %r1175, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1201, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1204, %r1175, %r1201;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1202, %r1203, %r1204;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1214, %r678, %r1196, %r1186, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1212, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1215, %r1186, %r1212;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1213, %r1214, %r1215;
	// end inline asm
	// begin inline asm
	mov.b32 %r1221, {%rs129, %rs129};
	// end inline asm
	// begin inline asm
	mov.b32 %r1232, {%rs131, %rs131};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1227, %r667, %r1220, %r1221, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1225, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1228, %r1221, %r1225;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1226, %r1227, %r1228;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1238, %r678, %r1220, %r1232, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1236, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1239, %r1232, %r1236;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1237, %r1238, %r1239;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1249, %r667, %r1242, %r1221, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1247, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1250, %r1221, %r1247;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1248, %r1249, %r1250;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1260, %r678, %r1242, %r1232, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1258, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1261, %r1232, %r1258;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1259, %r1260, %r1261;
	// end inline asm
	// begin inline asm
	mov.b32 %r1267, {%rs129, %rs129};
	// end inline asm
	// begin inline asm
	mov.b32 %r1278, {%rs131, %rs131};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1273, %r667, %r1266, %r1267, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1271, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1274, %r1267, %r1271;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1272, %r1273, %r1274;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1284, %r678, %r1266, %r1278, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1282, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1285, %r1278, %r1282;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1283, %r1284, %r1285;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1295, %r667, %r1288, %r1267, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1293, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1296, %r1267, %r1293;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1294, %r1295, %r1296;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1306, %r678, %r1288, %r1278, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1304, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1307, %r1278, %r1304;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1305, %r1306, %r1307;
	// end inline asm
	// begin inline asm
	mov.b32 %r1313, {%rs129, %rs129};
	// end inline asm
	// begin inline asm
	mov.b32 %r1324, {%rs131, %rs131};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1319, %r667, %r1312, %r1313, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1317, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1320, %r1313, %r1317;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1318, %r1319, %r1320;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1330, %r678, %r1312, %r1324, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1328, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1331, %r1324, %r1328;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1329, %r1330, %r1331;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1341, %r667, %r1334, %r1313, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1339, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1342, %r1313, %r1339;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1340, %r1341, %r1342;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1352, %r678, %r1334, %r1324, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1350, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1353, %r1324, %r1350;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1351, %r1352, %r1353;
	// end inline asm
	// begin inline asm
	mov.b32 %r1359, {%rs129, %rs129};
	// end inline asm
	// begin inline asm
	mov.b32 %r1370, {%rs131, %rs131};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1365, %r667, %r1358, %r1359, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1363, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1366, %r1359, %r1363;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1364, %r1365, %r1366;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1376, %r678, %r1358, %r1370, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1374, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1377, %r1370, %r1374;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1375, %r1376, %r1377;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1387, %r667, %r1380, %r1359, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1385, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1388, %r1359, %r1385;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1386, %r1387, %r1388;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1398, %r678, %r1380, %r1370, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1396, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1399, %r1370, %r1396;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1397, %r1398, %r1399;
	// end inline asm
	// begin inline asm
	mov.b32 %r1405, {%rs129, %rs129};
	// end inline asm
	// begin inline asm
	mov.b32 %r1416, {%rs131, %rs131};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1411, %r667, %r1404, %r1405, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1409, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1412, %r1405, %r1409;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1410, %r1411, %r1412;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1422, %r678, %r1404, %r1416, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1420, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1423, %r1416, %r1420;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1421, %r1422, %r1423;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1433, %r667, %r1426, %r1405, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1431, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1434, %r1405, %r1431;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1432, %r1433, %r1434;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1444, %r678, %r1426, %r1416, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1442, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1445, %r1416, %r1442;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1443, %r1444, %r1445;
	// end inline asm
	// begin inline asm
	mov.b32 %r1451, {%rs129, %rs129};
	// end inline asm
	// begin inline asm
	mov.b32 %r1462, {%rs131, %rs131};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1457, %r667, %r1450, %r1451, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1455, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1458, %r1451, %r1455;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1456, %r1457, %r1458;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1468, %r678, %r1450, %r1462, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1466, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1469, %r1462, %r1466;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1467, %r1468, %r1469;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1479, %r667, %r1472, %r1451, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1477, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1480, %r1451, %r1477;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1478, %r1479, %r1480;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1490, %r678, %r1472, %r1462, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1488, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1491, %r1462, %r1488;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1489, %r1490, %r1491;
	// end inline asm
	// begin inline asm
	mov.b32 %r1497, {%rs129, %rs129};
	// end inline asm
	// begin inline asm
	mov.b32 %r1508, {%rs131, %rs131};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1503, %r667, %r1496, %r1497, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1501, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1504, %r1497, %r1501;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1502, %r1503, %r1504;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1514, %r678, %r1496, %r1508, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1512, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1515, %r1508, %r1512;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1513, %r1514, %r1515;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1525, %r667, %r1518, %r1497, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1523, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1526, %r1497, %r1523;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1524, %r1525, %r1526;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1536, %r678, %r1518, %r1508, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1534, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1537, %r1508, %r1534;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1535, %r1536, %r1537;
	// end inline asm
	// begin inline asm
	mov.b32 %r1543, {%rs129, %rs129};
	// end inline asm
	// begin inline asm
	mov.b32 %r1554, {%rs131, %rs131};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1549, %r667, %r1542, %r1543, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1547, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1550, %r1543, %r1547;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1548, %r1549, %r1550;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1560, %r678, %r1542, %r1554, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1558, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1561, %r1554, %r1558;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1559, %r1560, %r1561;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1571, %r667, %r1564, %r1543, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1569, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1572, %r1543, %r1569;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1570, %r1571, %r1572;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1582, %r678, %r1564, %r1554, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1580, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1583, %r1554, %r1580;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1581, %r1582, %r1583;
	// end inline asm
	// begin inline asm
	mov.b32 %r1589, {%rs129, %rs129};
	// end inline asm
	// begin inline asm
	mov.b32 %r1600, {%rs131, %rs131};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1595, %r667, %r1588, %r1589, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1593, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1596, %r1589, %r1593;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1594, %r1595, %r1596;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1606, %r678, %r1588, %r1600, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1604, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1607, %r1600, %r1604;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1605, %r1606, %r1607;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1617, %r667, %r1610, %r1589, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1615, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1618, %r1589, %r1615;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1616, %r1617, %r1618;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1628, %r678, %r1610, %r1600, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1626, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1629, %r1600, %r1626;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1627, %r1628, %r1629;
	// end inline asm
	// begin inline asm
	mov.b32 %r1635, {%rs129, %rs129};
	// end inline asm
	// begin inline asm
	mov.b32 %r1646, {%rs131, %rs131};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1641, %r667, %r1634, %r1635, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1639, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1642, %r1635, %r1639;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1640, %r1641, %r1642;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1652, %r678, %r1634, %r1646, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1650, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1653, %r1646, %r1650;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1651, %r1652, %r1653;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1663, %r667, %r1656, %r1635, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1661, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1664, %r1635, %r1661;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1662, %r1663, %r1664;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1674, %r678, %r1656, %r1646, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1672, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1675, %r1646, %r1672;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1673, %r1674, %r1675;
	// end inline asm
	// begin inline asm
	mov.b32 %r1681, {%rs129, %rs129};
	// end inline asm
	// begin inline asm
	mov.b32 %r1692, {%rs131, %rs131};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1687, %r667, %r1680, %r1681, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1685, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1688, %r1681, %r1685;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1686, %r1687, %r1688;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1698, %r678, %r1680, %r1692, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1696, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1699, %r1692, %r1696;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1697, %r1698, %r1699;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1709, %r667, %r1702, %r1681, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1707, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1710, %r1681, %r1707;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1708, %r1709, %r1710;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1720, %r678, %r1702, %r1692, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1718, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1721, %r1692, %r1718;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1719, %r1720, %r1721;
	// end inline asm
	// begin inline asm
	mov.b32 %r1727, {%rs129, %rs129};
	// end inline asm
	// begin inline asm
	mov.b32 %r1738, {%rs131, %rs131};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1733, %r667, %r1726, %r1727, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1731, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1734, %r1727, %r1731;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1732, %r1733, %r1734;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1744, %r678, %r1726, %r1738, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1742, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1745, %r1738, %r1742;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1743, %r1744, %r1745;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1755, %r667, %r1748, %r1727, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1753, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1756, %r1727, %r1753;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1754, %r1755, %r1756;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1766, %r678, %r1748, %r1738, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1764, {%rs133, %rs133};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1767, %r1738, %r1764;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1765, %r1766, %r1767;
	// end inline asm
	setp.eq.s32 	%p40, %r2479, 0;
	selp.b32 	%r2121, %r674, 0, %p40;
	setp.eq.s32 	%p41, %r2479, 4;
	selp.b32 	%r2122, %r858, %r2121, %p41;
	setp.eq.s32 	%p42, %r2479, 8;
	selp.b32 	%r2123, %r1042, %r2122, %p42;
	setp.eq.s32 	%p43, %r2479, 12;
	selp.b32 	%r2124, %r1226, %r2123, %p43;
	setp.eq.s32 	%p44, %r2479, 16;
	selp.b32 	%r2125, %r1410, %r2124, %p44;
	setp.eq.s32 	%p45, %r2479, 20;
	selp.b32 	%r2126, %r1594, %r2125, %p45;
	setp.eq.s32 	%p46, %r2479, 24;
	selp.b32 	%r2127, %r696, %r2126, %p46;
	setp.eq.s32 	%p47, %r2479, 28;
	selp.b32 	%r2128, %r880, %r2127, %p47;
	setp.eq.s32 	%p48, %r2479, 32;
	selp.b32 	%r2129, %r1064, %r2128, %p48;
	setp.eq.s32 	%p49, %r2479, 36;
	selp.b32 	%r2130, %r1248, %r2129, %p49;
	setp.eq.s32 	%p50, %r2479, 40;
	selp.b32 	%r2131, %r1432, %r2130, %p50;
	setp.eq.s32 	%p51, %r2479, 44;
	selp.b32 	%r1770, %r1616, %r2131, %p51;
	selp.b32 	%r2132, %r685, 0, %p40;
	selp.b32 	%r2133, %r869, %r2132, %p41;
	selp.b32 	%r2134, %r1053, %r2133, %p42;
	selp.b32 	%r2135, %r1237, %r2134, %p43;
	selp.b32 	%r2136, %r1421, %r2135, %p44;
	selp.b32 	%r2137, %r1605, %r2136, %p45;
	selp.b32 	%r2138, %r707, %r2137, %p46;
	selp.b32 	%r2139, %r891, %r2138, %p47;
	selp.b32 	%r2140, %r1075, %r2139, %p48;
	selp.b32 	%r2141, %r1259, %r2140, %p49;
	selp.b32 	%r2142, %r1443, %r2141, %p50;
	selp.b32 	%r1773, %r1627, %r2142, %p51;
	selp.b32 	%r2143, %r720, 0, %p40;
	selp.b32 	%r2144, %r904, %r2143, %p41;
	selp.b32 	%r2145, %r1088, %r2144, %p42;
	selp.b32 	%r2146, %r1272, %r2145, %p43;
	selp.b32 	%r2147, %r1456, %r2146, %p44;
	selp.b32 	%r2148, %r1640, %r2147, %p45;
	selp.b32 	%r2149, %r742, %r2148, %p46;
	selp.b32 	%r2150, %r926, %r2149, %p47;
	selp.b32 	%r2151, %r1110, %r2150, %p48;
	selp.b32 	%r2152, %r1294, %r2151, %p49;
	selp.b32 	%r2153, %r1478, %r2152, %p50;
	selp.b32 	%r1776, %r1662, %r2153, %p51;
	selp.b32 	%r2154, %r731, 0, %p40;
	selp.b32 	%r2155, %r915, %r2154, %p41;
	selp.b32 	%r2156, %r1099, %r2155, %p42;
	selp.b32 	%r2157, %r1283, %r2156, %p43;
	selp.b32 	%r2158, %r1467, %r2157, %p44;
	selp.b32 	%r2159, %r1651, %r2158, %p45;
	selp.b32 	%r2160, %r753, %r2159, %p46;
	selp.b32 	%r2161, %r937, %r2160, %p47;
	selp.b32 	%r2162, %r1121, %r2161, %p48;
	selp.b32 	%r2163, %r1305, %r2162, %p49;
	selp.b32 	%r2164, %r1489, %r2163, %p50;
	selp.b32 	%r1779, %r1673, %r2164, %p51;
	selp.b32 	%r2165, %r766, 0, %p40;
	selp.b32 	%r2166, %r950, %r2165, %p41;
	selp.b32 	%r2167, %r1134, %r2166, %p42;
	selp.b32 	%r2168, %r1318, %r2167, %p43;
	selp.b32 	%r2169, %r1502, %r2168, %p44;
	selp.b32 	%r2170, %r1686, %r2169, %p45;
	selp.b32 	%r2171, %r788, %r2170, %p46;
	selp.b32 	%r2172, %r972, %r2171, %p47;
	selp.b32 	%r2173, %r1156, %r2172, %p48;
	selp.b32 	%r2174, %r1340, %r2173, %p49;
	selp.b32 	%r2175, %r1524, %r2174, %p50;
	selp.b32 	%r1782, %r1708, %r2175, %p51;
	selp.b32 	%r2176, %r777, 0, %p40;
	selp.b32 	%r2177, %r961, %r2176, %p41;
	selp.b32 	%r2178, %r1145, %r2177, %p42;
	selp.b32 	%r2179, %r1329, %r2178, %p43;
	selp.b32 	%r2180, %r1513, %r2179, %p44;
	selp.b32 	%r2181, %r1697, %r2180, %p45;
	selp.b32 	%r2182, %r799, %r2181, %p46;
	selp.b32 	%r2183, %r983, %r2182, %p47;
	selp.b32 	%r2184, %r1167, %r2183, %p48;
	selp.b32 	%r2185, %r1351, %r2184, %p49;
	selp.b32 	%r2186, %r1535, %r2185, %p50;
	selp.b32 	%r1785, %r1719, %r2186, %p51;
	selp.b32 	%r2187, %r812, 0, %p40;
	selp.b32 	%r2188, %r996, %r2187, %p41;
	selp.b32 	%r2189, %r1180, %r2188, %p42;
	selp.b32 	%r2190, %r1364, %r2189, %p43;
	selp.b32 	%r2191, %r1548, %r2190, %p44;
	selp.b32 	%r2192, %r1732, %r2191, %p45;
	selp.b32 	%r2193, %r834, %r2192, %p46;
	selp.b32 	%r2194, %r1018, %r2193, %p47;
	selp.b32 	%r2195, %r1202, %r2194, %p48;
	selp.b32 	%r2196, %r1386, %r2195, %p49;
	selp.b32 	%r2197, %r1570, %r2196, %p50;
	selp.b32 	%r1788, %r1754, %r2197, %p51;
	selp.b32 	%r2198, %r823, 0, %p40;
	selp.b32 	%r2199, %r1007, %r2198, %p41;
	selp.b32 	%r2200, %r1191, %r2199, %p42;
	selp.b32 	%r2201, %r1375, %r2200, %p43;
	selp.b32 	%r2202, %r1559, %r2201, %p44;
	selp.b32 	%r2203, %r1743, %r2202, %p45;
	selp.b32 	%r2204, %r845, %r2203, %p46;
	selp.b32 	%r2205, %r1029, %r2204, %p47;
	selp.b32 	%r2206, %r1213, %r2205, %p48;
	selp.b32 	%r2207, %r1397, %r2206, %p49;
	selp.b32 	%r2208, %r1581, %r2207, %p50;
	selp.b32 	%r1791, %r1765, %r2208, %p51;
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1im, %r1re}, %r2440;
    mov.b32 {%r2im, %r2re}, %r1770;
    mul.f16 %retmp, %r1re, %r2re;
    mul.f16 %imtmp, %r1re, %r2im;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1796, {%r0im, %r0re};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1im, %r1re}, %r2441;
    mov.b32 {%r2im, %r2re}, %r1773;
    mul.f16 %retmp, %r1re, %r2re;
    mul.f16 %imtmp, %r1re, %r2im;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1803, {%r0im, %r0re};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1im, %r1re}, %r2440;
    mov.b32 {%r2im, %r2re}, %r1776;
    mul.f16 %retmp, %r1re, %r2re;
    mul.f16 %imtmp, %r1re, %r2im;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1810, {%r0im, %r0re};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1im, %r1re}, %r2441;
    mov.b32 {%r2im, %r2re}, %r1779;
    mul.f16 %retmp, %r1re, %r2re;
    mul.f16 %imtmp, %r1re, %r2im;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1817, {%r0im, %r0re};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1im, %r1re}, %r2440;
    mov.b32 {%r2im, %r2re}, %r1782;
    mul.f16 %retmp, %r1re, %r2re;
    mul.f16 %imtmp, %r1re, %r2im;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1824, {%r0im, %r0re};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1im, %r1re}, %r2441;
    mov.b32 {%r2im, %r2re}, %r1785;
    mul.f16 %retmp, %r1re, %r2re;
    mul.f16 %imtmp, %r1re, %r2im;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1831, {%r0im, %r0re};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1im, %r1re}, %r2440;
    mov.b32 {%r2im, %r2re}, %r1788;
    mul.f16 %retmp, %r1re, %r2re;
    mul.f16 %imtmp, %r1re, %r2im;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1838, {%r0im, %r0re};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1im, %r1re}, %r2441;
    mov.b32 {%r2im, %r2re}, %r1791;
    mul.f16 %retmp, %r1re, %r2re;
    mul.f16 %imtmp, %r1re, %r2im;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1845, {%r0im, %r0re};
}

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1852, %r1855}, {%r201, %r198}, {%r1796}, {%r2436, %r2436};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1861, %r1864}, {%r201, %r198}, {%r1803}, {%r2436, %r2436};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1870, %r1873}, {%r201, %r198}, {%r1810}, {%r2436, %r2436};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1879, %r1882}, {%r201, %r198}, {%r1817}, {%r2436, %r2436};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1888, %r1891}, {%r201, %r198}, {%r1824}, {%r2436, %r2436};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1897, %r1900}, {%r201, %r198}, {%r1831}, {%r2436, %r2436};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1906, %r1909}, {%r201, %r198}, {%r1838}, {%r2436, %r2436};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1915, %r1918}, {%r201, %r198}, {%r1845}, {%r2436, %r2436};
	// end inline asm
	// begin inline asm
	neg.f16x2 %r1851, %r207;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1856, %r1851, %r1852;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r1983, %r204, %r1855, %r1856;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r1860, %r207;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1865, %r1860, %r1861;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r1993, %r204, %r1864, %r1865;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r1869, %r207;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1874, %r1869, %r1870;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2003, %r204, %r1873, %r1874;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r1878, %r207;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1883, %r1878, %r1879;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2013, %r204, %r1882, %r1883;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r1887, %r207;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1892, %r1887, %r1888;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2023, %r204, %r1891, %r1892;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r1896, %r207;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1901, %r1896, %r1897;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2033, %r204, %r1900, %r1901;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r1905, %r207;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1910, %r1905, %r1906;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2043, %r204, %r1909, %r1910;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r1914, %r207;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1919, %r1914, %r1915;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2053, %r204, %r1918, %r1919;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1926, %r207, %r1855;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r1982, %r204, %r1852, %r1926;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1933, %r207, %r1864;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r1992, %r204, %r1861, %r1933;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1940, %r207, %r1873;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2002, %r204, %r1870, %r1940;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1947, %r207, %r1882;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2012, %r204, %r1879, %r1947;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1954, %r207, %r1891;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2022, %r204, %r1888, %r1954;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1961, %r207, %r1900;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2032, %r204, %r1897, %r1961;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1968, %r207, %r1909;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2042, %r204, %r1906, %r1968;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1975, %r207, %r1918;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2052, %r204, %r1915, %r1975;
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2057, %r2058}, {%r219, %r213, %r216, %r210}, {%r1982, %r1983}, {%r2436, %r2436};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2065, %r2066}, {%r219, %r213, %r216, %r210}, {%r1992, %r1993}, {%r2436, %r2436};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2073, %r2074}, {%r219, %r213, %r216, %r210}, {%r2002, %r2003}, {%r2436, %r2436};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2081, %r2082}, {%r219, %r213, %r216, %r210}, {%r2012, %r2013}, {%r2436, %r2436};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2089, %r2090}, {%r219, %r213, %r216, %r210}, {%r2022, %r2023}, {%r2436, %r2436};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2097, %r2098}, {%r219, %r213, %r216, %r210}, {%r2032, %r2033}, {%r2436, %r2436};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2105, %r2106}, {%r219, %r213, %r216, %r210}, {%r2042, %r2043}, {%r2436, %r2436};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2113, %r2114}, {%r219, %r213, %r216, %r210}, {%r2052, %r2053}, {%r2436, %r2436};
	// end inline asm
	// begin inline asm
	prmt.b32 %r2056, %r2057, %r2058, %r513;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2060, %r2057, %r2058, %r517;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2064, %r2065, %r2066, %r513;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2068, %r2065, %r2066, %r517;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2072, %r2073, %r2074, %r513;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2076, %r2073, %r2074, %r517;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2080, %r2081, %r2082, %r513;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2084, %r2081, %r2082, %r517;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2088, %r2089, %r2090, %r513;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2092, %r2089, %r2090, %r517;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2096, %r2097, %r2098, %r513;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2100, %r2097, %r2098, %r517;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2104, %r2105, %r2106, %r513;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2108, %r2105, %r2106, %r517;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2112, %r2113, %r2114, %r513;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2116, %r2113, %r2114, %r517;
	// end inline asm
	st.shared.u32 	[%rd5], %r2056;
	st.shared.u32 	[%rd6+33024], %r2060;
	st.shared.u32 	[%rd6+128], %r2064;
	st.shared.u32 	[%rd6+33152], %r2068;
	shr.u32 	%r2209, %r2479, 2;
	cvt.u16.u32 	%rs417, %r2209;
	and.b16  	%rs418, %rs417, 255;
	mul.lo.s16 	%rs419, %rs418, 171;
	shr.u16 	%rs420, %rs419, 11;
	mul.lo.s16 	%rs421, %rs420, 12;
	sub.s16 	%rs422, %rs417, %rs421;
	shl.b16 	%rs423, %rs422, 2;
	cvt.u32.u16 	%r2210, %rs423;
	and.b32  	%r2211, %r2210, 252;
	add.s32 	%r2212, %r133, %r2211;
	shr.s32 	%r2213, %r2212, 31;
	shr.u32 	%r2214, %r2213, 30;
	add.s32 	%r2215, %r2212, %r2214;
	and.b32  	%r2216, %r2215, 67108860;
	sub.s32 	%r2217, %r2212, %r2216;
	shl.b32 	%r2218, %r2217, 6;
	add.s32 	%r2219, %r44, %r2218;
	mul.wide.s32 	%rd139, %r2219, 4;
	add.s64 	%rd141, %rd34, %rd139;
	st.shared.u32 	[%rd141], %r2072;
	add.s32 	%r2220, %r2219, 8256;
	mul.wide.u32 	%rd142, %r2220, 4;
	add.s64 	%rd143, %rd34, %rd142;
	st.shared.u32 	[%rd143], %r2076;
	add.s32 	%r2221, %r2219, 32;
	mul.wide.s32 	%rd144, %r2221, 4;
	add.s64 	%rd145, %rd34, %rd144;
	st.shared.u32 	[%rd145], %r2080;
	add.s32 	%r2222, %r2219, 8288;
	mul.wide.u32 	%rd146, %r2222, 4;
	add.s64 	%rd147, %rd34, %rd146;
	st.shared.u32 	[%rd147], %r2084;
	add.s32 	%r2223, %r134, %r2211;
	shr.s32 	%r2224, %r2223, 31;
	shr.u32 	%r2225, %r2224, 30;
	add.s32 	%r2226, %r2223, %r2225;
	and.b32  	%r2227, %r2226, 67108860;
	sub.s32 	%r2228, %r2223, %r2227;
	shl.b32 	%r2229, %r2228, 6;
	add.s32 	%r2230, %r44, %r2229;
	mul.wide.s32 	%rd148, %r2230, 4;
	add.s64 	%rd149, %rd34, %rd148;
	st.shared.u32 	[%rd149], %r2088;
	add.s32 	%r2231, %r2230, 8256;
	mul.wide.u32 	%rd150, %r2231, 4;
	add.s64 	%rd151, %rd34, %rd150;
	st.shared.u32 	[%rd151], %r2092;
	add.s32 	%r2232, %r2230, 32;
	mul.wide.s32 	%rd152, %r2232, 4;
	add.s64 	%rd153, %rd34, %rd152;
	st.shared.u32 	[%rd153], %r2096;
	add.s32 	%r2233, %r2230, 8288;
	mul.wide.u32 	%rd154, %r2233, 4;
	add.s64 	%rd155, %rd34, %rd154;
	st.shared.u32 	[%rd155], %r2100;
	add.s32 	%r2234, %r135, %r2211;
	shr.s32 	%r2235, %r2234, 31;
	shr.u32 	%r2236, %r2235, 30;
	add.s32 	%r2237, %r2234, %r2236;
	and.b32  	%r2238, %r2237, 67108860;
	sub.s32 	%r2239, %r2234, %r2238;
	shl.b32 	%r2240, %r2239, 6;
	add.s32 	%r2241, %r44, %r2240;
	mul.wide.s32 	%rd156, %r2241, 4;
	add.s64 	%rd157, %rd34, %rd156;
	st.shared.u32 	[%rd157], %r2104;
	add.s32 	%r2242, %r2241, 8256;
	mul.wide.u32 	%rd158, %r2242, 4;
	add.s64 	%rd159, %rd34, %rd158;
	st.shared.u32 	[%rd159], %r2108;
	add.s32 	%r2243, %r2241, 32;
	mul.wide.s32 	%rd160, %r2243, 4;
	add.s64 	%rd161, %rd34, %rd160;
	st.shared.u32 	[%rd161], %r2112;
	add.s32 	%r2244, %r2241, 8288;
	mul.wide.u32 	%rd162, %r2244, 4;
	add.s64 	%rd163, %rd34, %rd162;
	st.shared.u32 	[%rd163], %r2116;
	bar.sync 	0;
	mov.u32 	%r2486, %r2436;
	bra.uni 	LBB0_9;
LBB0_14:                                // %L57602
                                        //   in Loop: Header=BB0_9 Depth=3
	add.s32 	%r2492, %r2492, 1;
	mov.u32 	%r2480, 0;
	mov.u32 	%r2482, %r2480;
	mov.u32 	%r2483, %r2480;
	mov.u32 	%r2484, %r2480;
	mov.u32 	%r2485, %r2480;
LBB0_15:                                // %L57603
                                        //   in Loop: Header=BB0_9 Depth=3
	add.s32 	%r2486, %r2486, 1;
	setp.ne.s32 	%p55, %r2486, 4;
	@%p55 bra 	LBB0_9;
	bra.uni 	LBB0_16;
LBB0_9:                                 // %L55561
                                        //   Parent Loop BB0_6 Depth=1
                                        //     Parent Loop BB0_8 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	setp.gt.u32 	%p52, %r1, 23;
	mov.u32 	%r2487, %r2436;
	mov.u32 	%r2488, %r2436;
	mov.u32 	%r2489, %r2436;
	mov.u32 	%r2490, %r2436;
	@%p52 bra 	LBB0_11;
// %bb.10:                              // %L55589
                                        //   in Loop: Header=BB0_9 Depth=3
	or.b32  	%r2246, %r2486, %r2479;
	add.s32 	%r2247, %r2246, %r60;
	shr.s32 	%r2248, %r2247, 31;
	shr.u32 	%r2249, %r2248, 30;
	add.s32 	%r2250, %r2247, %r2249;
	and.b32  	%r2251, %r2250, 67108860;
	sub.s32 	%r2252, %r2247, %r2251;
	shl.b32 	%r2253, %r2252, 6;
	add.s32 	%r2254, %r45, %r2253;
	add.s32 	%r2255, %r2254, %r18;
	add.s32 	%r2256, %r2255, %r46;
	add.s32 	%r2257, %r2256, %r47;
	add.s32 	%r2258, %r2257, %r48;
	add.s32 	%r2259, %r2258, %r49;
	mul.wide.s32 	%rd164, %r2259, 4;
	add.s64 	%rd166, %rd34, %rd164;
	ld.shared.u32 	%r2490, [%rd166];
	add.s32 	%r2260, %r2259, 8256;
	mul.wide.u32 	%rd167, %r2260, 4;
	add.s64 	%rd168, %rd34, %rd167;
	ld.shared.u32 	%r2489, [%rd168];
	add.s32 	%r2261, %r2259, 32;
	mul.wide.s32 	%rd169, %r2261, 4;
	add.s64 	%rd170, %rd34, %rd169;
	ld.shared.u32 	%r2488, [%rd170];
	add.s32 	%r2262, %r2259, 8288;
	mul.wide.u32 	%rd171, %r2262, 4;
	add.s64 	%rd172, %rd34, %rd171;
	ld.shared.u32 	%r2487, [%rd172];
LBB0_11:                                // %L56840
                                        //   in Loop: Header=BB0_9 Depth=3
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2295, %r2298}, {%r201, %r198}, {%r2490}, {%r2436, %r2436};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2304, %r2307}, {%r201, %r198}, {%r2489}, {%r2436, %r2436};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2313, %r2316}, {%r201, %r198}, {%r2488}, {%r2436, %r2436};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2322, %r2325}, {%r201, %r198}, {%r2487}, {%r2436, %r2436};
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2291, %r207;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2293, %r2291, %r2295;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2296, %r204, %r2298, %r2293;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2300, %r207;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2302, %r2300, %r2304;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2305, %r204, %r2307, %r2302;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2309, %r207;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2311, %r2309, %r2313;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2314, %r204, %r2316, %r2311;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2318, %r207;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2320, %r2318, %r2322;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2323, %r204, %r2325, %r2320;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2327, %r207, %r2298;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2330, %r204, %r2295, %r2327;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2334, %r207, %r2307;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2337, %r204, %r2304, %r2334;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2341, %r207, %r2316;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2344, %r204, %r2313, %r2341;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2348, %r207, %r2325;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2351, %r204, %r2322, %r2348;
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2396, %r2400}, {%r219, %r213, %r216, %r210}, {%r2330, %r2296}, {%r2436, %r2436};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2404, %r2408}, {%r219, %r213, %r216, %r210}, {%r2337, %r2305}, {%r2436, %r2436};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2412, %r2416}, {%r219, %r213, %r216, %r210}, {%r2344, %r2314}, {%r2436, %r2436};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2420, %r2424}, {%r219, %r213, %r216, %r210}, {%r2351, %r2323}, {%r2436, %r2436};
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2395, %r2396, %r2396, %r2485;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2485, %r2400, %r2400, %r2395;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2403, %r2404, %r2404, %r2484;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2484, %r2408, %r2408, %r2403;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2411, %r2412, %r2412, %r2483;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2483, %r2416, %r2416, %r2411;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2419, %r2420, %r2420, %r2482;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2482, %r2424, %r2424, %r2419;
	// end inline asm
	add.s32 	%r2480, %r2480, 1;
	setp.ne.s32 	%p53, %r2480, 40;
	@%p53 bra 	LBB0_15;
// %bb.12:                              // %L57024
                                        //   in Loop: Header=BB0_9 Depth=3
	@%p52 bra 	LBB0_14;
// %bb.13:                              // %L57089
                                        //   in Loop: Header=BB0_9 Depth=3
	mul.lo.s32 	%r2427, %r2492, 589824;
	or.b32  	%r2428, %r2427, %r16;
	add.s32 	%r2429, %r2428, %r50;
	add.s32 	%r2430, %r2429, %r51;
	mul.wide.u32 	%rd173, %r2430, 4;
	add.s64 	%rd174, %rd3, %rd173;
	st.global.u32 	[%rd174], %r2485;
	or.b32  	%r2431, %r52, %r2427;
	add.s32 	%r2432, %r2431, %r16;
	add.s32 	%r2433, %r2432, %r51;
	mul.wide.u32 	%rd175, %r2433, 4;
	add.s64 	%rd176, %rd3, %rd175;
	st.global.u32 	[%rd176], %r2484;
	cvt.u64.u32 	%rd177, %r51;
	cvt.u64.u32 	%rd178, %r16;
	cvt.u64.u32 	%rd179, %r50;
	cvt.u64.u32 	%rd180, %r2427;
	add.s64 	%rd181, %rd180, %rd179;
	add.s64 	%rd182, %rd181, %rd178;
	add.s64 	%rd183, %rd182, %rd177;
	shl.b64 	%rd184, %rd183, 2;
	add.s64 	%rd185, %rd3, %rd184;
	st.global.u32 	[%rd185+1179648], %r2483;
	cvt.u64.u32 	%rd186, %r52;
	add.s64 	%rd187, %rd180, %rd186;
	add.s64 	%rd188, %rd187, %rd178;
	add.s64 	%rd189, %rd188, %rd177;
	shl.b64 	%rd190, %rd189, 2;
	add.s64 	%rd191, %rd3, %rd190;
	st.global.u32 	[%rd191+1179648], %r2482;
	bra.uni 	LBB0_14;
LBB0_18:                                // %L57661
	mov.u32 	%r2435, 0;
	st.global.u32 	[%rd4], %r2435;
	ret;
LBB0_1:                                 // %L9
	ld.param.u64 	%rd8, [_Z14julia_frb_550613CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_0];
	mov.u64 	%rd17, exception1;
	cvta.global.u64 	%rd18, %rd17;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd18;
	call.uni 
	gpu_report_exception, 
	(
	param0
	);
	} // callseq 0
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .align 8 .b8 param0[8];
	st.param.b64 	[param0+0], %rd8;
	call.uni 
	gpu_signal_exception, 
	(
	param0
	);
	} // callseq 1
	// begin inline asm
	exit;
	// end inline asm
                                        // -- End function
}
