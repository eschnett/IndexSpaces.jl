CHORD FRB beamformer
Compiling kernel...
// PTX CompilerJob of kernel #frb(CuDeviceVector{Int32, 1}, CuDeviceVector{Float16x2, 1}, CuDeviceVector{Int4x8, 1}, CuDeviceVector{Float16x2, 1}, CuDeviceVector{Int32, 1}, CuDeviceVector{Int4x8, 1}, CuDeviceVector{Int4x8, 1}, CuDeviceVector{Float16x2, 1}) for sm_86, minthreads=768, blocks_per_sm=1

//
// Generated by LLVM NVPTX Back-End
//

.version 7.1
.target sm_86
.address_size 64

	// .globl	_Z15julia_frb_1221013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE // -- Begin function _Z15julia_frb_1221013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE
.extern .func gpu_report_exception
(
	.param .b64 gpu_report_exception_param_0
)
;
.extern .func gpu_signal_exception
(
	.param .align 8 .b8 gpu_signal_exception_param_0[8]
)
;
.extern .shared .align 32 .b8 shmem[];
.global .align 1 .b8 exception12155[10] = {101, 120, 99, 101, 112, 116, 105, 111, 110, 0};
                                        // @_Z15julia_frb_1221013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE
.visible .entry _Z15julia_frb_1221013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE(
	.param .align 8 .b8 _Z15julia_frb_1221013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_0[8],
	.param .align 8 .b8 _Z15julia_frb_1221013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_1[32],
	.param .align 8 .b8 _Z15julia_frb_1221013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_2[32],
	.param .align 8 .b8 _Z15julia_frb_1221013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_3[32],
	.param .align 8 .b8 _Z15julia_frb_1221013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_4[32],
	.param .align 8 .b8 _Z15julia_frb_1221013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_5[32],
	.param .align 8 .b8 _Z15julia_frb_1221013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_6[32],
	.param .align 8 .b8 _Z15julia_frb_1221013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_7[32],
	.param .align 8 .b8 _Z15julia_frb_1221013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_8[32]
)
.reqntid 768, 1, 1
.minnctapersm 1
{
	.reg .pred 	%p<77>;
	.reg .b16 	%rs<471>;
	.reg .f32 	%f<202>;
	.reg .b32 	%r<3217>;
	.reg .b64 	%rd<330>;

// %bb.0:                               // %conversion
	// begin inline asm
	mov.u32 %r285, %dynamic_smem_size;
	// end inline asm
	setp.gt.u32 	%p1, %r285, 76895;
	@%p1 bra 	LBB0_2;
	bra.uni 	LBB0_1;
LBB0_2:                                 // %L11
	ld.param.u64 	%rd12, [_Z15julia_frb_1221013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_5];
	mov.u32 	%r1, %tid.y;
	shl.b32 	%r2, %r1, 5;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r292, %r3, %r2;
	mov.u32 	%r4, %ctaid.x;
	mad.lo.s32 	%r293, %r4, 768, %r292;
	mul.wide.u32 	%rd18, %r293, 4;
	add.s64 	%rd5, %rd12, %rd18;
	mov.u32 	%r294, 1;
	st.global.u32 	[%rd5], %r294;
	and.b32  	%r5, %r3, 3;
	shr.u32 	%r6, %r3, 2;
	mul.lo.s32 	%r295, %r5, %r6;
	and.b32  	%r296, %r295, 7;
	cvt.rn.f32.u32 	%f18, %r296;
	mov.f32 	%f19, 0f40800000;
	div.approx.f32 	%f20, %f18, %f19;
	add.f32 	%f21, %f20, %f20;
	mov.b32 	%r297, %f21;
	and.b32  	%r298, %r297, -2147483648;
	or.b32  	%r299, %r298, 1056964608;
	mov.b32 	%f22, %r299;
	add.f32 	%f23, %f21, %f22;
	cvt.rzi.f32.f32 	%f24, %f23;
	abs.f32 	%f25, %f21;
	setp.gt.f32 	%p2, %f25, 0f4B000000;
	selp.f32 	%f26, %f21, %f24, %p2;
	cvt.rzi.f32.f32 	%f27, %f21;
	setp.lt.f32 	%p3, %f25, 0f3F000000;
	selp.f32 	%f28, %f27, %f26, %p3;
	cvt.rzi.s32.f32 	%r300, %f28;
	fma.rn.f32 	%f29, %f28, 0fBF000000, %f20;
	mul.f32 	%f30, %f29, 0f34222169;
	fma.rn.f32 	%f31, %f29, 0f40490FDA, %f30;
	mul.f32 	%f32, %f31, %f31;
	fma.rn.f32 	%f33, %f32, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f34, %f33, %f32, 0f3D2AAABB;
	fma.rn.f32 	%f35, %f34, %f32, 0fBEFFFFFF;
	fma.rn.f32 	%f36, %f35, %f32, 0f3F800000;
	fma.rn.f32 	%f37, %f32, %f31, 0f00000000;
	fma.rn.f32 	%f38, %f32, 0fB94D4153, 0f3C0885E4;
	fma.rn.f32 	%f39, %f38, %f32, 0fBE2AAAA8;
	fma.rn.f32 	%f40, %f39, %f37, %f31;
	and.b32  	%r301, %r300, 1;
	setp.eq.b32 	%p4, %r301, 1;
	selp.f32 	%f41, %f36, %f40, %p4;
	selp.f32 	%f42, %f40, %f36, %p4;
	and.b32  	%r302, %r300, 2;
	setp.eq.s32 	%p5, %r302, 0;
	neg.f32 	%f43, %f41;
	selp.f32 	%f44, %f41, %f43, %p5;
	add.s32 	%r303, %r300, 1;
	and.b32  	%r304, %r303, 2;
	mov.f32 	%f200, 0f00000000;
	cvt.rzi.f32.f32 	%f47, %f20;
	setp.eq.f32 	%p7, %f47, %f20;
	mul.f32 	%f48, %f20, 0f00000000;
	shl.b32 	%r9, %r3, 1;
	and.b32  	%r10, %r9, 6;
	or.b32  	%r11, %r10, 1;
	setp.eq.s32 	%p9, %r10, 6;
	mov.f32 	%f192, 0f41C00000;
	mul.lo.s32 	%r3128, %r10, %r6;
	mov.f32 	%f194, %f200;
	mov.f32 	%f195, %f200;
	@%p9 bra 	LBB0_4;
// %bb.3:                               // %L206
	cvt.u16.u32 	%rs1, %r3128;
	and.b16  	%rs2, %rs1, 255;
	mul.lo.s16 	%rs3, %rs2, 171;
	shr.u16 	%rs4, %rs3, 13;
	mul.lo.s16 	%rs5, %rs4, 48;
	sub.s16 	%rs6, %rs1, %rs5;
	and.b16  	%rs7, %rs6, 255;
	cvt.rn.f32.u16 	%f53, %rs7;
	div.approx.f32 	%f55, %f53, %f192;
	add.f32 	%f56, %f55, %f55;
	mov.b32 	%r306, %f56;
	and.b32  	%r307, %r306, -2147483648;
	or.b32  	%r308, %r307, 1056964608;
	mov.b32 	%f57, %r308;
	add.f32 	%f58, %f56, %f57;
	cvt.rzi.f32.f32 	%f59, %f58;
	abs.f32 	%f60, %f56;
	setp.gt.f32 	%p10, %f60, 0f4B000000;
	selp.f32 	%f61, %f56, %f59, %p10;
	cvt.rzi.f32.f32 	%f62, %f56;
	setp.lt.f32 	%p11, %f60, 0f3F000000;
	selp.f32 	%f63, %f62, %f61, %p11;
	cvt.rzi.s32.f32 	%r309, %f63;
	fma.rn.f32 	%f64, %f63, 0fBF000000, %f55;
	mul.f32 	%f65, %f64, 0f34222169;
	fma.rn.f32 	%f66, %f64, 0f40490FDA, %f65;
	mul.f32 	%f67, %f66, %f66;
	fma.rn.f32 	%f68, %f67, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f69, %f68, %f67, 0f3D2AAABB;
	fma.rn.f32 	%f70, %f69, %f67, 0fBEFFFFFF;
	fma.rn.f32 	%f71, %f70, %f67, 0f3F800000;
	fma.rn.f32 	%f72, %f67, %f66, 0f00000000;
	fma.rn.f32 	%f73, %f67, 0fB94D4153, 0f3C0885E4;
	fma.rn.f32 	%f74, %f73, %f67, 0fBE2AAAA8;
	fma.rn.f32 	%f75, %f74, %f72, %f66;
	and.b32  	%r310, %r309, 1;
	setp.eq.b32 	%p12, %r310, 1;
	selp.f32 	%f76, %f71, %f75, %p12;
	selp.f32 	%f77, %f75, %f71, %p12;
	and.b32  	%r311, %r309, 2;
	setp.eq.s32 	%p13, %r311, 0;
	neg.f32 	%f78, %f76;
	selp.f32 	%f79, %f76, %f78, %p13;
	add.s32 	%r312, %r309, 1;
	and.b32  	%r313, %r312, 2;
	setp.eq.s32 	%p14, %r313, 0;
	mov.f32 	%f80, 0f00000000;
	sub.f32 	%f81, %f80, %f77;
	selp.f32 	%f82, %f77, %f81, %p14;
	cvt.rzi.f32.f32 	%f83, %f55;
	setp.eq.f32 	%p15, %f83, %f55;
	mul.f32 	%f84, %f55, 0f00000000;
	selp.f32 	%f195, %f84, %f79, %p15;
	abs.f32 	%f85, %f55;
	setp.gt.f32 	%p16, %f85, 0f4B800000;
	add.f32 	%f86, %f195, 0f3F800000;
	selp.f32 	%f194, %f86, %f82, %p16;
LBB0_4:                                 // %L221
	setp.eq.s32 	%p6, %r304, 0;
	sub.f32 	%f45, %f200, %f42;
	selp.f32 	%f49, %f48, %f44, %p7;
	abs.f32 	%f50, %f20;
	setp.gt.u32 	%p17, %r11, 5;
	mul.lo.s32 	%r3129, %r11, %r6;
	mov.f32 	%f196, %f200;
	mov.f32 	%f197, %f200;
	@%p17 bra 	LBB0_6;
// %bb.5:                               // %L225
	cvt.u16.u32 	%rs8, %r3129;
	and.b16  	%rs9, %rs8, 255;
	mul.lo.s16 	%rs10, %rs9, 171;
	shr.u16 	%rs11, %rs10, 13;
	mul.lo.s16 	%rs12, %rs11, 48;
	sub.s16 	%rs13, %rs8, %rs12;
	and.b16  	%rs14, %rs13, 255;
	cvt.rn.f32.u16 	%f88, %rs14;
	div.approx.f32 	%f90, %f88, %f192;
	add.f32 	%f91, %f90, %f90;
	mov.b32 	%r315, %f91;
	and.b32  	%r316, %r315, -2147483648;
	or.b32  	%r317, %r316, 1056964608;
	mov.b32 	%f92, %r317;
	add.f32 	%f93, %f91, %f92;
	cvt.rzi.f32.f32 	%f94, %f93;
	abs.f32 	%f95, %f91;
	setp.gt.f32 	%p18, %f95, 0f4B000000;
	selp.f32 	%f96, %f91, %f94, %p18;
	cvt.rzi.f32.f32 	%f97, %f91;
	setp.lt.f32 	%p19, %f95, 0f3F000000;
	selp.f32 	%f98, %f97, %f96, %p19;
	cvt.rzi.s32.f32 	%r318, %f98;
	fma.rn.f32 	%f99, %f98, 0fBF000000, %f90;
	mul.f32 	%f100, %f99, 0f34222169;
	fma.rn.f32 	%f101, %f99, 0f40490FDA, %f100;
	mul.f32 	%f102, %f101, %f101;
	fma.rn.f32 	%f103, %f102, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f104, %f103, %f102, 0f3D2AAABB;
	fma.rn.f32 	%f105, %f104, %f102, 0fBEFFFFFF;
	fma.rn.f32 	%f106, %f105, %f102, 0f3F800000;
	fma.rn.f32 	%f107, %f102, %f101, 0f00000000;
	fma.rn.f32 	%f108, %f102, 0fB94D4153, 0f3C0885E4;
	fma.rn.f32 	%f109, %f108, %f102, 0fBE2AAAA8;
	fma.rn.f32 	%f110, %f109, %f107, %f101;
	and.b32  	%r319, %r318, 1;
	setp.eq.b32 	%p20, %r319, 1;
	selp.f32 	%f111, %f106, %f110, %p20;
	selp.f32 	%f112, %f110, %f106, %p20;
	and.b32  	%r320, %r318, 2;
	setp.eq.s32 	%p21, %r320, 0;
	neg.f32 	%f113, %f111;
	selp.f32 	%f114, %f111, %f113, %p21;
	add.s32 	%r321, %r318, 1;
	and.b32  	%r322, %r321, 2;
	setp.eq.s32 	%p22, %r322, 0;
	mov.f32 	%f115, 0f00000000;
	sub.f32 	%f116, %f115, %f112;
	selp.f32 	%f117, %f112, %f116, %p22;
	cvt.rzi.f32.f32 	%f118, %f90;
	setp.eq.f32 	%p23, %f118, %f90;
	mul.f32 	%f119, %f90, 0f00000000;
	selp.f32 	%f197, %f119, %f114, %p23;
	abs.f32 	%f120, %f90;
	setp.gt.f32 	%p24, %f120, 0f4B800000;
	add.f32 	%f121, %f197, 0f3F800000;
	selp.f32 	%f196, %f121, %f117, %p24;
LBB0_6:                                 // %L240
	selp.f32 	%f46, %f42, %f45, %p6;
	setp.gt.f32 	%p8, %f50, 0f4B800000;
	add.f32 	%f51, %f49, 0f3F800000;
	setp.gt.u32 	%p26, %r3, 23;
	or.pred  	%p27, %p9, %p26;
	mov.f32 	%f193, 0f40400000;
	mov.f32 	%f198, %f200;
	mov.f32 	%f199, %f200;
	@%p27 bra 	LBB0_8;
// %bb.7:                               // %L282
	cvt.u16.u32 	%rs15, %r3128;
	and.b16  	%rs16, %rs15, 255;
	mul.lo.s16 	%rs17, %rs16, 171;
	shr.u16 	%rs18, %rs17, 10;
	mul.lo.s16 	%rs19, %rs18, 6;
	sub.s16 	%rs20, %rs15, %rs19;
	and.b16  	%rs21, %rs20, 255;
	cvt.rn.f32.u16 	%f123, %rs21;
	div.approx.f32 	%f125, %f123, %f193;
	add.f32 	%f126, %f125, %f125;
	mov.b32 	%r330, %f126;
	and.b32  	%r331, %r330, -2147483648;
	or.b32  	%r332, %r331, 1056964608;
	mov.b32 	%f127, %r332;
	add.f32 	%f128, %f126, %f127;
	cvt.rzi.f32.f32 	%f129, %f128;
	abs.f32 	%f130, %f126;
	setp.gt.f32 	%p28, %f130, 0f4B000000;
	selp.f32 	%f131, %f126, %f129, %p28;
	cvt.rzi.f32.f32 	%f132, %f126;
	setp.lt.f32 	%p29, %f130, 0f3F000000;
	selp.f32 	%f133, %f132, %f131, %p29;
	cvt.rzi.s32.f32 	%r333, %f133;
	fma.rn.f32 	%f134, %f133, 0fBF000000, %f125;
	mul.f32 	%f135, %f134, 0f34222169;
	fma.rn.f32 	%f136, %f134, 0f40490FDA, %f135;
	mul.f32 	%f137, %f136, %f136;
	fma.rn.f32 	%f138, %f137, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f139, %f138, %f137, 0f3D2AAABB;
	fma.rn.f32 	%f140, %f139, %f137, 0fBEFFFFFF;
	fma.rn.f32 	%f141, %f140, %f137, 0f3F800000;
	fma.rn.f32 	%f142, %f137, %f136, 0f00000000;
	fma.rn.f32 	%f143, %f137, 0fB94D4153, 0f3C0885E4;
	fma.rn.f32 	%f144, %f143, %f137, 0fBE2AAAA8;
	fma.rn.f32 	%f145, %f144, %f142, %f136;
	and.b32  	%r334, %r333, 1;
	setp.eq.b32 	%p30, %r334, 1;
	selp.f32 	%f146, %f141, %f145, %p30;
	selp.f32 	%f147, %f145, %f141, %p30;
	and.b32  	%r335, %r333, 2;
	setp.eq.s32 	%p31, %r335, 0;
	neg.f32 	%f148, %f146;
	selp.f32 	%f149, %f146, %f148, %p31;
	add.s32 	%r336, %r333, 1;
	and.b32  	%r337, %r336, 2;
	setp.eq.s32 	%p32, %r337, 0;
	mov.f32 	%f150, 0f00000000;
	sub.f32 	%f151, %f150, %f147;
	selp.f32 	%f152, %f147, %f151, %p32;
	cvt.rzi.f32.f32 	%f153, %f125;
	setp.eq.f32 	%p33, %f153, %f125;
	mul.f32 	%f154, %f125, 0f00000000;
	selp.f32 	%f199, %f154, %f149, %p33;
	abs.f32 	%f155, %f125;
	setp.gt.f32 	%p34, %f155, 0f4B800000;
	add.f32 	%f156, %f199, 0f3F800000;
	selp.f32 	%f198, %f156, %f152, %p34;
LBB0_8:                                 // %L297
	selp.f32 	%f52, %f51, %f46, %p8;
	or.pred  	%p37, %p17, %p26;
	mov.f32 	%f201, %f200;
	@%p37 bra 	LBB0_10;
// %bb.9:                               // %L305
	cvt.u16.u32 	%rs22, %r3129;
	and.b16  	%rs23, %rs22, 255;
	mul.lo.s16 	%rs24, %rs23, 171;
	shr.u16 	%rs25, %rs24, 10;
	mul.lo.s16 	%rs26, %rs25, 6;
	sub.s16 	%rs27, %rs22, %rs26;
	and.b16  	%rs28, %rs27, 255;
	cvt.rn.f32.u16 	%f158, %rs28;
	div.approx.f32 	%f160, %f158, %f193;
	add.f32 	%f161, %f160, %f160;
	mov.b32 	%r339, %f161;
	and.b32  	%r340, %r339, -2147483648;
	or.b32  	%r341, %r340, 1056964608;
	mov.b32 	%f162, %r341;
	add.f32 	%f163, %f161, %f162;
	cvt.rzi.f32.f32 	%f164, %f163;
	abs.f32 	%f165, %f161;
	setp.gt.f32 	%p38, %f165, 0f4B000000;
	selp.f32 	%f166, %f161, %f164, %p38;
	cvt.rzi.f32.f32 	%f167, %f161;
	setp.lt.f32 	%p39, %f165, 0f3F000000;
	selp.f32 	%f168, %f167, %f166, %p39;
	cvt.rzi.s32.f32 	%r342, %f168;
	fma.rn.f32 	%f169, %f168, 0fBF000000, %f160;
	mul.f32 	%f170, %f169, 0f34222169;
	fma.rn.f32 	%f171, %f169, 0f40490FDA, %f170;
	mul.f32 	%f172, %f171, %f171;
	fma.rn.f32 	%f173, %f172, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f174, %f173, %f172, 0f3D2AAABB;
	fma.rn.f32 	%f175, %f174, %f172, 0fBEFFFFFF;
	fma.rn.f32 	%f176, %f175, %f172, 0f3F800000;
	fma.rn.f32 	%f177, %f172, %f171, 0f00000000;
	fma.rn.f32 	%f178, %f172, 0fB94D4153, 0f3C0885E4;
	fma.rn.f32 	%f179, %f178, %f172, 0fBE2AAAA8;
	fma.rn.f32 	%f180, %f179, %f177, %f171;
	and.b32  	%r343, %r342, 1;
	setp.eq.b32 	%p40, %r343, 1;
	selp.f32 	%f181, %f176, %f180, %p40;
	selp.f32 	%f182, %f180, %f176, %p40;
	and.b32  	%r344, %r342, 2;
	setp.eq.s32 	%p41, %r344, 0;
	neg.f32 	%f183, %f181;
	selp.f32 	%f184, %f181, %f183, %p41;
	add.s32 	%r345, %r342, 1;
	and.b32  	%r346, %r345, 2;
	setp.eq.s32 	%p42, %r346, 0;
	mov.f32 	%f185, 0f00000000;
	sub.f32 	%f186, %f185, %f182;
	selp.f32 	%f187, %f182, %f186, %p42;
	cvt.rzi.f32.f32 	%f188, %f160;
	setp.eq.f32 	%p43, %f188, %f160;
	mul.f32 	%f189, %f160, 0f00000000;
	selp.f32 	%f201, %f189, %f184, %p43;
	abs.f32 	%f190, %f160;
	setp.gt.f32 	%p44, %f190, 0f4B800000;
	add.f32 	%f191, %f201, 0f3F800000;
	selp.f32 	%f200, %f191, %f187, %p44;
LBB0_10:                                // %L320
	mov.b32 	%r288, %f52;
	mov.b32 	%r291, %f49;
	mov.b32 	%r348, %f198;
	mov.b32 	%r349, %f200;
	mov.b32 	%r354, %f199;
	mov.b32 	%r355, %f201;
	mov.u32 	%r3131, 999999999;
	cvt.u16.u32 	%rs469, %r3;
	@%p26 bra 	LBB0_12;
// %bb.11:                              // %L363
	ld.param.u64 	%rd1, [_Z15julia_frb_1221013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_1];
	and.b16  	%rs30, %rs469, 255;
	mul.lo.s16 	%rs31, %rs30, 171;
	shr.u16 	%rs32, %rs31, 12;
	mul.lo.s16 	%rs33, %rs32, 24;
	sub.s16 	%rs34, %rs469, %rs33;
	cvt.u32.u16 	%r360, %rs34;
	and.b32  	%r361, %r360, 255;
	mad.lo.s32 	%r362, %r361, 24, %r1;
	cvt.u16.u32 	%rs35, %r362;
	mul.hi.u16 	%rs36, %rs35, -7281;
	shr.u16 	%rs37, %rs36, 9;
	mul.lo.s16 	%rs38, %rs37, 576;
	sub.s16 	%rs39, %rs35, %rs38;
	cvt.u32.u16 	%r363, %rs39;
	mul.wide.u32 	%rd19, %r363, 4;
	add.s64 	%rd20, %rd1, %rd19;
	ld.global.u32 	%r3131, [%rd20];
LBB0_12:                                // %L440
	xor.b32  	%r287, %r291, -2147483648;
	mov.b32 	%r324, %f194;
	mov.b32 	%r325, %f196;
	mov.b32 	%r327, %f195;
	mov.b32 	%r328, %f197;
	xor.b32  	%r351, %r354, -2147483648;
	xor.b32  	%r352, %r355, -2147483648;
	and.b32  	%r20, %r3, 24;
	setp.ne.s32 	%p46, %r20, 24;
	cvt.u16.u32 	%rs470, %r6;
	@%p46 bra 	LBB0_14;
// %bb.13:                              // %L440.L785_crit_edge
	cvt.u16.u32 	%rs52, %r1;
	and.b16  	%rs53, %rs52, 255;
	mul.lo.s16 	%rs54, %rs53, 171;
	shr.u16 	%rs55, %rs54, 10;
	mul.lo.s16 	%rs56, %rs55, -6;
	add.s16 	%rs57, %rs56, %rs52;
	cvt.u32.u16 	%r381, %rs57;
	and.b32  	%r3135, %r381, 255;
	mul.lo.s16 	%rs59, %rs470, 171;
	shr.u16 	%rs60, %rs59, 10;
	mul.lo.s16 	%rs61, %rs60, 6;
	sub.s16 	%rs62, %rs470, %rs61;
	cvt.u32.u16 	%r382, %rs62;
	and.b32  	%r3134, %r382, 255;
	cvt.u32.u16 	%r3133, %rs55;
	mul.wide.u16 	%r3132, %rs55, 6;
	mov.u32 	%r3136, 0;
	mov.u32 	%r3137, %r3136;
	bra.uni 	LBB0_15;
LBB0_14:                                // %L469
	ld.param.u64 	%rd2, [_Z15julia_frb_1221013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_2];
	mul.lo.s32 	%r364, %r5, 144;
	cvt.u16.u32 	%rs40, %r1;
	and.b16  	%rs41, %rs40, 255;
	mul.lo.s16 	%rs42, %rs41, 171;
	shr.u16 	%rs43, %rs42, 10;
	mul.lo.s16 	%rs44, %rs43, -6;
	add.s16 	%rs45, %rs44, %rs40;
	cvt.u32.u16 	%r366, %rs45;
	and.b32  	%r3135, %r366, 255;
	or.b32  	%r367, %r364, %r3135;
	mul.lo.s32 	%r368, %r4, 576;
	add.s32 	%r369, %r367, %r368;
	cvt.u32.u16 	%r3133, %rs43;
	mul.wide.u16 	%r3132, %rs43, 6;
	add.s32 	%r370, %r369, %r3132;
	mul.lo.s16 	%rs47, %rs470, 171;
	shr.u16 	%rs48, %rs47, 10;
	mul.lo.s16 	%rs49, %rs48, 6;
	sub.s16 	%rs50, %rs470, %rs49;
	cvt.u32.u16 	%r371, %rs50;
	and.b32  	%r3134, %r371, 255;
	and.b16  	%rs51, %rs50, 255;
	mul.wide.u16 	%r372, %rs51, 24;
	add.s32 	%r373, %r370, %r372;
	mul.wide.u32 	%rd21, %r373, 4;
	add.s64 	%rd22, %rd2, %rd21;
	ld.global.u32 	%r3136, [%rd22];
	add.s32 	%r374, %r364, 48384;
	or.b32  	%r375, %r374, %r3135;
	add.s32 	%r376, %r375, %r368;
	add.s32 	%r377, %r376, %r3132;
	add.s32 	%r378, %r377, %r372;
	mul.wide.u32 	%rd23, %r378, 4;
	add.s64 	%rd24, %rd2, %rd23;
	ld.global.u32 	%r3137, [%rd24];
LBB0_15:                                // %L785
	ld.param.u64 	%rd3, [_Z15julia_frb_1221013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_3];
	ld.param.u64 	%rd4, [_Z15julia_frb_1221013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_4];
	// begin inline asm
	cvt.rn.f16x2.f32 %r286, %r288, %r287;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r289, %r291, %r288;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r323, %r325, %r324;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r326, %r328, %r327;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r347, %r349, %r348;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r350, %r352, %r351;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r353, %r355, %r354;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r356, %r349, %r348;
	// end inline asm
	mov.u32 	%r3130, 0;
	shl.b32 	%r384, %r3, 2;
	and.b32  	%r385, %r384, 60;
	shr.u32 	%r37, %r3, 4;
	mul.lo.s32 	%r386, %r37, 10752;
	or.b32  	%r38, %r386, %r385;
	shl.b32 	%r39, %r4, 7;
	or.b32  	%r387, %r384, %r386;
	or.b32  	%r40, %r387, 64;
	and.b32  	%r388, %r9, 30;
	or.b32  	%r389, %r37, %r388;
	mul.lo.s32 	%r41, %r389, 257;
	or.b32  	%r390, %r9, %r37;
	or.b32  	%r391, %r390, 32;
	mul.lo.s32 	%r42, %r391, 257;
	shr.u32 	%r392, %r1, 3;
	and.b32  	%r393, %r2, 224;
	mad.lo.s32 	%r43, %r392, 257, %r393;
	and.b16  	%rs64, %rs469, 255;
	mul.lo.s16 	%rs65, %rs64, 171;
	shr.u16 	%rs66, %rs65, 12;
	mul.lo.s16 	%rs67, %rs66, 24;
	sub.s16 	%rs68, %rs469, %rs67;
	cvt.u32.u16 	%r394, %rs68;
	and.b32  	%r44, %r394, 255;
	add.s32 	%r395, %r1, 24;
	shr.u32 	%r396, %r395, 3;
	mad.lo.s32 	%r45, %r396, 257, %r393;
	add.s32 	%r397, %r1, 48;
	shr.u32 	%r398, %r397, 3;
	mad.lo.s32 	%r46, %r398, 257, %r393;
	add.s32 	%r399, %r1, 72;
	shr.u32 	%r400, %r399, 3;
	mad.lo.s32 	%r47, %r400, 257, %r393;
	or.b32  	%r401, %r392, 12;
	mad.lo.s32 	%r48, %r401, 257, %r393;
	add.s32 	%r402, %r1, 120;
	shr.u32 	%r403, %r402, 3;
	mad.lo.s32 	%r49, %r403, 257, %r393;
	add.s32 	%r404, %r1, 144;
	shr.u32 	%r405, %r404, 3;
	mad.lo.s32 	%r50, %r405, 257, %r393;
	add.s32 	%r406, %r1, 168;
	shr.u32 	%r407, %r406, 3;
	mad.lo.s32 	%r51, %r407, 257, %r393;
	or.b32  	%r408, %r392, 24;
	mad.lo.s32 	%r52, %r408, 257, %r393;
	add.s32 	%r409, %r1, 216;
	shr.u32 	%r410, %r409, 3;
	mad.lo.s32 	%r53, %r410, 257, %r393;
	add.s32 	%r411, %r1, 240;
	shr.u32 	%r412, %r411, 3;
	mad.lo.s32 	%r54, %r412, 257, %r393;
	add.s32 	%r413, %r1, 264;
	shr.u32 	%r414, %r413, 3;
	mad.lo.s32 	%r55, %r414, 257, %r393;
	or.b32  	%r415, %r392, 36;
	mad.lo.s32 	%r56, %r415, 257, %r393;
	add.s32 	%r416, %r1, 312;
	shr.u32 	%r417, %r416, 3;
	mad.lo.s32 	%r57, %r417, 257, %r393;
	add.s32 	%r418, %r1, 336;
	shr.u32 	%r419, %r418, 3;
	mad.lo.s32 	%r58, %r419, 257, %r393;
	add.s32 	%r420, %r1, 360;
	shr.u32 	%r421, %r420, 3;
	mad.lo.s32 	%r59, %r421, 257, %r393;
	or.b32  	%r422, %r392, 48;
	mad.lo.s32 	%r60, %r422, 257, %r393;
	add.s32 	%r423, %r1, 408;
	shr.u32 	%r424, %r423, 3;
	mad.lo.s32 	%r61, %r424, 257, %r393;
	add.s32 	%r425, %r1, 432;
	shr.u32 	%r426, %r425, 3;
	mad.lo.s32 	%r62, %r426, 257, %r393;
	add.s32 	%r427, %r1, 456;
	shr.u32 	%r428, %r427, 3;
	mad.lo.s32 	%r63, %r428, 257, %r393;
	or.b32  	%r429, %r392, 60;
	mad.lo.s32 	%r64, %r429, 257, %r393;
	add.s32 	%r430, %r1, 504;
	bfe.u32 	%r431, %r430, 3, 6;
	mad.lo.s32 	%r65, %r431, 257, %r393;
	mul.lo.s32 	%r66, %r3135, 33;
	mul.lo.s32 	%r67, %r5, 4806;
	mul.lo.s32 	%r68, %r3134, 801;
	mul.lo.s32 	%r69, %r3133, 198;
	and.b32  	%r432, %r3, 1;
	mul.lo.s32 	%r433, %r432, 4112;
	bfe.u32 	%r434, %r3, 1, 1;
	mul.lo.s32 	%r435, %r434, 2056;
	add.s32 	%r436, %r435, %r433;
	add.s32 	%r437, %r436, %r3135;
	and.b32  	%r438, %r6, 1;
	mul.lo.s32 	%r439, %r438, 1028;
	add.s32 	%r440, %r437, %r439;
	mul.lo.s32 	%r441, %r37, 257;
	add.s32 	%r442, %r440, %r441;
	bfe.u32 	%r443, %r3, 3, 1;
	mul.lo.s32 	%r444, %r443, 514;
	add.s32 	%r445, %r442, %r444;
	add.s32 	%r70, %r445, %r3132;
	mul.wide.u32 	%rd25, %r70, 4;
	mov.u64 	%rd26, shmem;
	add.s64 	%rd6, %rd26, %rd25;
	cvt.u64.u32 	%rd27, %r3132;
	cvt.u64.u32 	%rd28, %r444;
	cvt.u64.u32 	%rd29, %r441;
	cvt.u64.u32 	%rd30, %r439;
	cvt.u64.u32 	%rd31, %r3135;
	cvt.u64.u32 	%rd32, %r435;
	cvt.u64.u32 	%rd33, %r433;
	add.s64 	%rd34, %rd33, %rd32;
	add.s64 	%rd35, %rd34, %rd31;
	add.s64 	%rd36, %rd35, %rd30;
	add.s64 	%rd37, %rd36, %rd29;
	add.s64 	%rd38, %rd37, %rd28;
	add.s64 	%rd39, %rd38, %rd27;
	shl.b64 	%rd40, %rd39, 2;
	add.s64 	%rd7, %rd26, %rd40;
	and.b32  	%r446, %r1, 1;
	mul.lo.s32 	%r447, %r446, 4112;
	bfe.u32 	%r448, %r1, 1, 1;
	mul.lo.s32 	%r449, %r448, 2056;
	add.s32 	%r450, %r449, %r447;
	add.s32 	%r451, %r450, %r3134;
	bfe.u32 	%r452, %r1, 2, 1;
	mul.lo.s32 	%r453, %r452, 1028;
	add.s32 	%r454, %r451, %r453;
	shr.u32 	%r455, %r1, 4;
	mul.lo.s32 	%r456, %r455, 257;
	add.s32 	%r457, %r454, %r456;
	bfe.u32 	%r458, %r1, 3, 1;
	mul.lo.s32 	%r459, %r458, 514;
	add.s32 	%r460, %r457, %r459;
	mul.lo.s32 	%r461, %r5, 6;
	add.s32 	%r71, %r460, %r461;
	mul.wide.u32 	%rd41, %r71, 4;
	add.s64 	%rd8, %rd26, %rd41;
	cvt.u64.u32 	%rd42, %r461;
	cvt.u64.u32 	%rd43, %r459;
	cvt.u64.u32 	%rd44, %r456;
	cvt.u64.u32 	%rd45, %r453;
	cvt.u64.u32 	%rd46, %r3134;
	cvt.u64.u32 	%rd47, %r449;
	cvt.u64.u32 	%rd48, %r447;
	add.s64 	%rd49, %rd48, %rd47;
	add.s64 	%rd50, %rd49, %rd46;
	add.s64 	%rd51, %rd50, %rd45;
	add.s64 	%rd52, %rd51, %rd44;
	add.s64 	%rd53, %rd52, %rd43;
	add.s64 	%rd54, %rd53, %rd42;
	shl.b64 	%rd55, %rd54, 2;
	add.s64 	%rd9, %rd26, %rd55;
	cvt.u16.u32 	%rs69, %r1;
	shl.b16 	%rs70, %rs69, 1;
	and.b16  	%rs71, %rs70, 254;
	mul.lo.s16 	%rs72, %rs71, 171;
	shr.u16 	%rs73, %rs72, 13;
	mul.lo.s16 	%rs74, %rs73, 48;
	sub.s16 	%rs75, %rs70, %rs74;
	and.b16  	%rs76, %rs75, 254;
	mul.wide.u16 	%r72, %rs76, 24;
	mul.lo.s32 	%r73, %r4, 1152;
	or.b16  	%rs77, %rs70, 1;
	and.b16  	%rs78, %rs77, 255;
	mul.lo.s16 	%rs79, %rs78, 171;
	shr.u16 	%rs80, %rs79, 13;
	mul.lo.s16 	%rs81, %rs80, 48;
	sub.s16 	%rs82, %rs77, %rs81;
	and.b16  	%rs83, %rs82, 255;
	mul.wide.u16 	%r74, %rs83, 24;
	cvt.u64.u32 	%rd56, %r69;
	cvt.u64.u32 	%rd57, %r68;
	cvt.u64.u32 	%rd58, %r67;
	cvt.u64.u32 	%rd59, %r66;
	add.s64 	%rd60, %rd59, %rd58;
	add.s64 	%rd61, %rd60, %rd57;
	add.s64 	%rd62, %rd61, %rd56;
	shl.b64 	%rd63, %rd62, 2;
	add.s64 	%rd10, %rd26, %rd63;
	setp.gt.u32 	%p47, %r1, 7;
	setp.eq.s32 	%p48, %r37, 1;
	setp.lt.u32 	%p50, %r3, 24;
	mov.u32 	%r3138, %r3130;
	mov.u32 	%r3171, %r3130;
	mov.u32 	%r3172, %r3130;
	mov.u32 	%r3173, %r3130;
	mov.u32 	%r3174, %r3130;
	mov.u32 	%r3175, %r3130;
	mov.u32 	%r3176, %r3130;
	bra.uni 	LBB0_16;
LBB0_39:                                // %guard_pass10729
                                        //   in Loop: Header=BB0_16 Depth=1
	add.s32 	%r284, %r3138, 48;
	setp.ne.s32 	%p75, %r3138, 2016;
	mov.u32 	%r3138, %r284;
	@%p75 bra 	LBB0_16;
	bra.uni 	LBB0_40;
LBB0_16:                                // %L788
                                        // =>This Loop Header: Depth=1
                                        //     Child Loop BB0_18 Depth 2
	mul.hi.u32 	%r655, %r3138, -1431655765;
	shr.u32 	%r656, %r655, 5;
	mul.lo.s32 	%r82, %r656, 48;
	add.s32 	%r657, %r1, %r82;
	cvt.u16.u32 	%rs84, %r657;
	mul.hi.s16 	%rs85, %rs84, 16257;
	shr.u16 	%rs86, %rs85, 15;
	shr.s16 	%rs87, %rs85, 9;
	add.s16 	%rs88, %rs87, %rs86;
	mul.lo.s16 	%rs89, %rs88, 2064;
	sub.s16 	%rs90, %rs84, %rs89;
	mul.wide.s16 	%r658, %rs90, 21504;
	add.s32 	%r659, %r38, %r658;
	add.s32 	%r660, %r659, %r39;
	mul.wide.s32 	%rd64, %r660, 4;
	add.s64 	%rd65, %rd3, %rd64;
	ld.global.v4.u32 	{%r661, %r662, %r663, %r664}, [%rd65];
	add.s32 	%r665, %r658, %r40;
	add.s32 	%r666, %r665, %r39;
	mul.wide.s32 	%rd66, %r666, 4;
	add.s64 	%rd67, %rd3, %rd66;
	ld.global.v4.u32 	{%r667, %r668, %r669, %r670}, [%rd67];
	add.s16 	%rs91, %rs84, 24;
	mul.hi.s16 	%rs92, %rs91, 16257;
	shr.u16 	%rs93, %rs92, 15;
	shr.s16 	%rs94, %rs92, 9;
	add.s16 	%rs95, %rs94, %rs93;
	mul.lo.s16 	%rs96, %rs95, 2064;
	sub.s16 	%rs97, %rs91, %rs96;
	mul.wide.s16 	%r671, %rs97, 21504;
	add.s32 	%r672, %r38, %r671;
	add.s32 	%r673, %r672, %r39;
	mul.wide.s32 	%rd68, %r673, 4;
	add.s64 	%rd69, %rd3, %rd68;
	ld.global.v4.u32 	{%r674, %r675, %r676, %r677}, [%rd69];
	add.s32 	%r678, %r671, %r40;
	add.s32 	%r679, %r678, %r39;
	mul.wide.s32 	%rd70, %r679, 4;
	add.s64 	%rd71, %rd3, %rd70;
	ld.global.v4.u32 	{%r680, %r681, %r682, %r683}, [%rd71];
	selp.b32 	%r684, %r661, %r663, %p48;
	shfl.sync.bfly.b32	%r685, %r684, 16, 31, -1;
	selp.b32 	%r464, %r685, %r661, %p48;
	selp.b32 	%r469, %r663, %r685, %p48;
	selp.b32 	%r686, %r662, %r664, %p48;
	shfl.sync.bfly.b32	%r687, %r686, 16, 31, -1;
	selp.b32 	%r472, %r687, %r662, %p48;
	selp.b32 	%r477, %r664, %r687, %p48;
	selp.b32 	%r688, %r667, %r669, %p48;
	shfl.sync.bfly.b32	%r689, %r688, 16, 31, -1;
	selp.b32 	%r480, %r689, %r667, %p48;
	selp.b32 	%r485, %r669, %r689, %p48;
	selp.b32 	%r690, %r668, %r670, %p48;
	shfl.sync.bfly.b32	%r691, %r690, 16, 31, -1;
	selp.b32 	%r488, %r691, %r668, %p48;
	selp.b32 	%r493, %r670, %r691, %p48;
	selp.b32 	%r692, %r674, %r676, %p48;
	shfl.sync.bfly.b32	%r693, %r692, 16, 31, -1;
	selp.b32 	%r496, %r693, %r674, %p48;
	selp.b32 	%r501, %r676, %r693, %p48;
	selp.b32 	%r694, %r675, %r677, %p48;
	shfl.sync.bfly.b32	%r695, %r694, 16, 31, -1;
	selp.b32 	%r504, %r695, %r675, %p48;
	selp.b32 	%r509, %r677, %r695, %p48;
	selp.b32 	%r696, %r680, %r682, %p48;
	shfl.sync.bfly.b32	%r697, %r696, 16, 31, -1;
	selp.b32 	%r512, %r697, %r680, %p48;
	selp.b32 	%r517, %r682, %r697, %p48;
	selp.b32 	%r698, %r681, %r683, %p48;
	shfl.sync.bfly.b32	%r699, %r698, 16, 31, -1;
	selp.b32 	%r520, %r699, %r681, %p48;
	selp.b32 	%r525, %r683, %r699, %p48;
	shl.b32 	%r465, %r469, 4;
	mov.u32 	%r463, 252645135;
	// begin inline asm
	lop3.b32 %r527, %r463, %r464, %r465, 202;
	// end inline asm
	shr.u32 	%r468, %r464, 4;
	// begin inline asm
	lop3.b32 %r543, %r463, %r468, %r469, 202;
	// end inline asm
	shl.b32 	%r473, %r477, 4;
	// begin inline asm
	lop3.b32 %r535, %r463, %r472, %r473, 202;
	// end inline asm
	shr.u32 	%r476, %r472, 4;
	// begin inline asm
	lop3.b32 %r551, %r463, %r476, %r477, 202;
	// end inline asm
	shl.b32 	%r481, %r485, 4;
	// begin inline asm
	lop3.b32 %r559, %r463, %r480, %r481, 202;
	// end inline asm
	shr.u32 	%r484, %r480, 4;
	// begin inline asm
	lop3.b32 %r575, %r463, %r484, %r485, 202;
	// end inline asm
	shl.b32 	%r489, %r493, 4;
	// begin inline asm
	lop3.b32 %r567, %r463, %r488, %r489, 202;
	// end inline asm
	shr.u32 	%r492, %r488, 4;
	// begin inline asm
	lop3.b32 %r583, %r463, %r492, %r493, 202;
	// end inline asm
	shl.b32 	%r497, %r501, 4;
	// begin inline asm
	lop3.b32 %r528, %r463, %r496, %r497, 202;
	// end inline asm
	shr.u32 	%r500, %r496, 4;
	// begin inline asm
	lop3.b32 %r544, %r463, %r500, %r501, 202;
	// end inline asm
	shl.b32 	%r505, %r509, 4;
	// begin inline asm
	lop3.b32 %r536, %r463, %r504, %r505, 202;
	// end inline asm
	shr.u32 	%r508, %r504, 4;
	// begin inline asm
	lop3.b32 %r552, %r463, %r508, %r509, 202;
	// end inline asm
	shl.b32 	%r513, %r517, 4;
	// begin inline asm
	lop3.b32 %r560, %r463, %r512, %r513, 202;
	// end inline asm
	shr.u32 	%r516, %r512, 4;
	// begin inline asm
	lop3.b32 %r576, %r463, %r516, %r517, 202;
	// end inline asm
	shl.b32 	%r521, %r525, 4;
	// begin inline asm
	lop3.b32 %r568, %r463, %r520, %r521, 202;
	// end inline asm
	shr.u32 	%r524, %r520, 4;
	// begin inline asm
	lop3.b32 %r584, %r463, %r524, %r525, 202;
	// end inline asm
	mov.u32 	%r529, 25152;
	// begin inline asm
	prmt.b32 %r591, %r527, %r528, %r529;
	// end inline asm
	mov.u32 	%r533, 29521;
	// begin inline asm
	prmt.b32 %r623, %r527, %r528, %r533;
	// end inline asm
	// begin inline asm
	prmt.b32 %r599, %r535, %r536, %r529;
	// end inline asm
	// begin inline asm
	prmt.b32 %r631, %r535, %r536, %r533;
	// end inline asm
	// begin inline asm
	prmt.b32 %r592, %r543, %r544, %r529;
	// end inline asm
	// begin inline asm
	prmt.b32 %r624, %r543, %r544, %r533;
	// end inline asm
	// begin inline asm
	prmt.b32 %r600, %r551, %r552, %r529;
	// end inline asm
	// begin inline asm
	prmt.b32 %r632, %r551, %r552, %r533;
	// end inline asm
	// begin inline asm
	prmt.b32 %r607, %r559, %r560, %r529;
	// end inline asm
	// begin inline asm
	prmt.b32 %r639, %r559, %r560, %r533;
	// end inline asm
	// begin inline asm
	prmt.b32 %r615, %r567, %r568, %r529;
	// end inline asm
	// begin inline asm
	prmt.b32 %r647, %r567, %r568, %r533;
	// end inline asm
	// begin inline asm
	prmt.b32 %r608, %r575, %r576, %r529;
	// end inline asm
	// begin inline asm
	prmt.b32 %r640, %r575, %r576, %r533;
	// end inline asm
	// begin inline asm
	prmt.b32 %r616, %r583, %r584, %r529;
	// end inline asm
	// begin inline asm
	prmt.b32 %r648, %r583, %r584, %r533;
	// end inline asm
	mov.u32 	%r649, 21520;
	// begin inline asm
	prmt.b32 %r590, %r591, %r592, %r649;
	// end inline asm
	mov.u32 	%r653, 30258;
	// begin inline asm
	prmt.b32 %r594, %r591, %r592, %r653;
	// end inline asm
	// begin inline asm
	prmt.b32 %r598, %r599, %r600, %r649;
	// end inline asm
	// begin inline asm
	prmt.b32 %r602, %r599, %r600, %r653;
	// end inline asm
	// begin inline asm
	prmt.b32 %r606, %r607, %r608, %r649;
	// end inline asm
	// begin inline asm
	prmt.b32 %r610, %r607, %r608, %r653;
	// end inline asm
	// begin inline asm
	prmt.b32 %r614, %r615, %r616, %r649;
	// end inline asm
	// begin inline asm
	prmt.b32 %r618, %r615, %r616, %r653;
	// end inline asm
	// begin inline asm
	prmt.b32 %r622, %r623, %r624, %r649;
	// end inline asm
	// begin inline asm
	prmt.b32 %r626, %r623, %r624, %r653;
	// end inline asm
	// begin inline asm
	prmt.b32 %r630, %r631, %r632, %r649;
	// end inline asm
	// begin inline asm
	prmt.b32 %r634, %r631, %r632, %r653;
	// end inline asm
	// begin inline asm
	prmt.b32 %r638, %r639, %r640, %r649;
	// end inline asm
	// begin inline asm
	prmt.b32 %r642, %r639, %r640, %r653;
	// end inline asm
	// begin inline asm
	prmt.b32 %r646, %r647, %r648, %r649;
	// end inline asm
	// begin inline asm
	prmt.b32 %r650, %r647, %r648, %r653;
	// end inline asm
	mul.hi.s16 	%rs98, %rs84, 10923;
	shr.u16 	%rs99, %rs98, 15;
	shr.s16 	%rs100, %rs98, 2;
	add.s16 	%rs101, %rs100, %rs99;
	mul.lo.s16 	%rs102, %rs101, 24;
	sub.s16 	%rs103, %rs84, %rs102;
	cvt.s32.s16 	%r700, %rs103;
	add.s32 	%r701, %r41, %r700;
	mul.wide.s32 	%rd72, %r701, 4;
	add.s64 	%rd74, %rd26, %rd72;
	st.shared.u32 	[%rd74], %r590;
	st.shared.u32 	[%rd74+512], %r598;
	st.shared.u32 	[%rd74+256], %r594;
	st.shared.u32 	[%rd74+768], %r602;
	add.s32 	%r702, %r42, %r700;
	mul.wide.s32 	%rd75, %r702, 4;
	add.s64 	%rd76, %rd26, %rd75;
	st.shared.u32 	[%rd76], %r606;
	st.shared.u32 	[%rd76+512], %r614;
	st.shared.u32 	[%rd76+256], %r610;
	st.shared.u32 	[%rd76+768], %r618;
	st.shared.u32 	[%rd74+128], %r622;
	st.shared.u32 	[%rd74+640], %r630;
	st.shared.u32 	[%rd74+384], %r626;
	st.shared.u32 	[%rd74+896], %r634;
	st.shared.u32 	[%rd76+128], %r638;
	st.shared.u32 	[%rd76+640], %r646;
	st.shared.u32 	[%rd76+384], %r642;
	st.shared.u32 	[%rd76+896], %r650;
	bar.sync 	0;
	add.s32 	%r703, %r82, %r44;
	cvt.u16.u32 	%rs104, %r703;
	mul.hi.s16 	%rs105, %rs104, 10923;
	shr.u16 	%rs106, %rs105, 15;
	shr.s16 	%rs107, %rs105, 2;
	add.s16 	%rs108, %rs107, %rs106;
	mul.lo.s16 	%rs109, %rs108, 24;
	sub.s16 	%rs110, %rs104, %rs109;
	cvt.s32.s16 	%r704, %rs110;
	add.s32 	%r705, %r43, %r704;
	mul.wide.s32 	%rd77, %r705, 4;
	add.s64 	%rd78, %rd26, %rd77;
	ld.shared.u32 	%r706, [%rd78];
	add.s32 	%r707, %r45, %r704;
	mul.wide.u32 	%rd79, %r707, 4;
	add.s64 	%rd80, %rd26, %rd79;
	ld.shared.u32 	%r708, [%rd80];
	add.s32 	%r709, %r46, %r704;
	mul.wide.u32 	%rd81, %r709, 4;
	add.s64 	%rd82, %rd26, %rd81;
	ld.shared.u32 	%r710, [%rd82];
	add.s32 	%r711, %r47, %r704;
	mul.wide.u32 	%rd83, %r711, 4;
	add.s64 	%rd84, %rd26, %rd83;
	ld.shared.u32 	%r712, [%rd84];
	add.s32 	%r713, %r48, %r704;
	mul.wide.s32 	%rd85, %r713, 4;
	add.s64 	%rd86, %rd26, %rd85;
	ld.shared.u32 	%r714, [%rd86];
	add.s32 	%r715, %r49, %r704;
	mul.wide.u32 	%rd87, %r715, 4;
	add.s64 	%rd88, %rd26, %rd87;
	ld.shared.u32 	%r716, [%rd88];
	add.s32 	%r717, %r50, %r704;
	mul.wide.u32 	%rd89, %r717, 4;
	add.s64 	%rd90, %rd26, %rd89;
	ld.shared.u32 	%r718, [%rd90];
	add.s32 	%r719, %r51, %r704;
	mul.wide.u32 	%rd91, %r719, 4;
	add.s64 	%rd92, %rd26, %rd91;
	ld.shared.u32 	%r720, [%rd92];
	add.s32 	%r721, %r52, %r704;
	mul.wide.s32 	%rd93, %r721, 4;
	add.s64 	%rd94, %rd26, %rd93;
	ld.shared.u32 	%r722, [%rd94];
	add.s32 	%r723, %r53, %r704;
	mul.wide.u32 	%rd95, %r723, 4;
	add.s64 	%rd96, %rd26, %rd95;
	ld.shared.u32 	%r724, [%rd96];
	add.s32 	%r725, %r54, %r704;
	mul.wide.u32 	%rd97, %r725, 4;
	add.s64 	%rd98, %rd26, %rd97;
	ld.shared.u32 	%r726, [%rd98];
	add.s32 	%r727, %r55, %r704;
	mul.wide.u32 	%rd99, %r727, 4;
	add.s64 	%rd100, %rd26, %rd99;
	ld.shared.u32 	%r728, [%rd100];
	add.s32 	%r729, %r56, %r704;
	mul.wide.s32 	%rd101, %r729, 4;
	add.s64 	%rd102, %rd26, %rd101;
	ld.shared.u32 	%r730, [%rd102];
	add.s32 	%r731, %r57, %r704;
	mul.wide.u32 	%rd103, %r731, 4;
	add.s64 	%rd104, %rd26, %rd103;
	ld.shared.u32 	%r732, [%rd104];
	add.s32 	%r733, %r58, %r704;
	mul.wide.u32 	%rd105, %r733, 4;
	add.s64 	%rd106, %rd26, %rd105;
	ld.shared.u32 	%r734, [%rd106];
	add.s32 	%r735, %r59, %r704;
	mul.wide.u32 	%rd107, %r735, 4;
	add.s64 	%rd108, %rd26, %rd107;
	ld.shared.u32 	%r736, [%rd108];
	add.s32 	%r737, %r60, %r704;
	mul.wide.s32 	%rd109, %r737, 4;
	add.s64 	%rd110, %rd26, %rd109;
	ld.shared.u32 	%r738, [%rd110];
	add.s32 	%r739, %r61, %r704;
	mul.wide.u32 	%rd111, %r739, 4;
	add.s64 	%rd112, %rd26, %rd111;
	ld.shared.u32 	%r740, [%rd112];
	add.s32 	%r741, %r62, %r704;
	mul.wide.u32 	%rd113, %r741, 4;
	add.s64 	%rd114, %rd26, %rd113;
	ld.shared.u32 	%r742, [%rd114];
	add.s32 	%r743, %r63, %r704;
	mul.wide.u32 	%rd115, %r743, 4;
	add.s64 	%rd116, %rd26, %rd115;
	ld.shared.u32 	%r744, [%rd116];
	add.s32 	%r745, %r64, %r704;
	mul.wide.s32 	%rd117, %r745, 4;
	add.s64 	%rd118, %rd26, %rd117;
	ld.shared.u32 	%r746, [%rd118];
	add.s32 	%r747, %r65, %r704;
	mul.wide.s32 	%rd119, %r747, 4;
	add.s64 	%rd120, %rd26, %rd119;
	ld.shared.u32 	%r748, [%rd120];
	bar.sync 	0;
	shfl.sync.idx.b32	%r749, %r3131, 0, 31, -1;
	shfl.sync.idx.b32	%r750, %r3131, 1, 31, -1;
	shfl.sync.idx.b32	%r751, %r3131, 2, 31, -1;
	shfl.sync.idx.b32	%r752, %r3131, 3, 31, -1;
	shfl.sync.idx.b32	%r753, %r3131, 4, 31, -1;
	shfl.sync.idx.b32	%r754, %r3131, 5, 31, -1;
	shfl.sync.idx.b32	%r755, %r3131, 6, 31, -1;
	shfl.sync.idx.b32	%r756, %r3131, 7, 31, -1;
	shfl.sync.idx.b32	%r757, %r3131, 8, 31, -1;
	shfl.sync.idx.b32	%r758, %r3131, 9, 31, -1;
	shfl.sync.idx.b32	%r759, %r3131, 10, 31, -1;
	shfl.sync.idx.b32	%r760, %r3131, 11, 31, -1;
	shfl.sync.idx.b32	%r761, %r3131, 12, 31, -1;
	shfl.sync.idx.b32	%r762, %r3131, 13, 31, -1;
	shfl.sync.idx.b32	%r763, %r3131, 14, 31, -1;
	shfl.sync.idx.b32	%r764, %r3131, 15, 31, -1;
	shfl.sync.idx.b32	%r765, %r3131, 16, 31, -1;
	shfl.sync.idx.b32	%r766, %r3131, 17, 31, -1;
	shfl.sync.idx.b32	%r767, %r3131, 18, 31, -1;
	shfl.sync.idx.b32	%r768, %r3131, 19, 31, -1;
	shfl.sync.idx.b32	%r769, %r3131, 20, 31, -1;
	shfl.sync.idx.b32	%r770, %r3131, 21, 31, -1;
	shfl.sync.idx.b32	%r771, %r3131, 22, 31, -1;
	shfl.sync.idx.b32	%r772, %r3131, 23, 31, -1;
	add.s32 	%r773, %r749, %r704;
	mul.wide.s32 	%rd121, %r773, 4;
	add.s64 	%rd122, %rd26, %rd121;
	st.shared.u32 	[%rd122], %r706;
	add.s32 	%r774, %r750, %r704;
	mul.wide.s32 	%rd123, %r774, 4;
	add.s64 	%rd124, %rd26, %rd123;
	st.shared.u32 	[%rd124], %r708;
	add.s32 	%r775, %r751, %r704;
	mul.wide.s32 	%rd125, %r775, 4;
	add.s64 	%rd126, %rd26, %rd125;
	st.shared.u32 	[%rd126], %r710;
	add.s32 	%r776, %r752, %r704;
	mul.wide.s32 	%rd127, %r776, 4;
	add.s64 	%rd128, %rd26, %rd127;
	st.shared.u32 	[%rd128], %r712;
	add.s32 	%r777, %r753, %r704;
	mul.wide.s32 	%rd129, %r777, 4;
	add.s64 	%rd130, %rd26, %rd129;
	st.shared.u32 	[%rd130], %r714;
	add.s32 	%r778, %r754, %r704;
	mul.wide.s32 	%rd131, %r778, 4;
	add.s64 	%rd132, %rd26, %rd131;
	st.shared.u32 	[%rd132], %r716;
	add.s32 	%r779, %r755, %r704;
	mul.wide.s32 	%rd133, %r779, 4;
	add.s64 	%rd134, %rd26, %rd133;
	st.shared.u32 	[%rd134], %r718;
	add.s32 	%r780, %r756, %r704;
	mul.wide.s32 	%rd135, %r780, 4;
	add.s64 	%rd136, %rd26, %rd135;
	st.shared.u32 	[%rd136], %r720;
	add.s32 	%r781, %r757, %r704;
	mul.wide.s32 	%rd137, %r781, 4;
	add.s64 	%rd138, %rd26, %rd137;
	st.shared.u32 	[%rd138], %r722;
	add.s32 	%r782, %r758, %r704;
	mul.wide.s32 	%rd139, %r782, 4;
	add.s64 	%rd140, %rd26, %rd139;
	st.shared.u32 	[%rd140], %r724;
	add.s32 	%r783, %r759, %r704;
	mul.wide.s32 	%rd141, %r783, 4;
	add.s64 	%rd142, %rd26, %rd141;
	st.shared.u32 	[%rd142], %r726;
	add.s32 	%r784, %r760, %r704;
	mul.wide.s32 	%rd143, %r784, 4;
	add.s64 	%rd144, %rd26, %rd143;
	st.shared.u32 	[%rd144], %r728;
	add.s32 	%r785, %r761, %r704;
	mul.wide.s32 	%rd145, %r785, 4;
	add.s64 	%rd146, %rd26, %rd145;
	st.shared.u32 	[%rd146], %r730;
	add.s32 	%r786, %r762, %r704;
	mul.wide.s32 	%rd147, %r786, 4;
	add.s64 	%rd148, %rd26, %rd147;
	st.shared.u32 	[%rd148], %r732;
	add.s32 	%r787, %r763, %r704;
	mul.wide.s32 	%rd149, %r787, 4;
	add.s64 	%rd150, %rd26, %rd149;
	st.shared.u32 	[%rd150], %r734;
	add.s32 	%r788, %r764, %r704;
	mul.wide.s32 	%rd151, %r788, 4;
	add.s64 	%rd152, %rd26, %rd151;
	st.shared.u32 	[%rd152], %r736;
	add.s32 	%r789, %r765, %r704;
	mul.wide.s32 	%rd153, %r789, 4;
	add.s64 	%rd154, %rd26, %rd153;
	st.shared.u32 	[%rd154], %r738;
	add.s32 	%r790, %r766, %r704;
	mul.wide.s32 	%rd155, %r790, 4;
	add.s64 	%rd156, %rd26, %rd155;
	st.shared.u32 	[%rd156], %r740;
	add.s32 	%r791, %r767, %r704;
	mul.wide.s32 	%rd157, %r791, 4;
	add.s64 	%rd158, %rd26, %rd157;
	st.shared.u32 	[%rd158], %r742;
	add.s32 	%r792, %r768, %r704;
	mul.wide.s32 	%rd159, %r792, 4;
	add.s64 	%rd160, %rd26, %rd159;
	st.shared.u32 	[%rd160], %r744;
	add.s32 	%r793, %r769, %r704;
	mul.wide.s32 	%rd161, %r793, 4;
	add.s64 	%rd162, %rd26, %rd161;
	st.shared.u32 	[%rd162], %r746;
	selp.b32 	%r794, 0, %r748, %p47;
	add.s32 	%r795, %r770, %r704;
	mul.wide.s32 	%rd163, %r795, 4;
	add.s64 	%rd164, %rd26, %rd163;
	st.shared.u32 	[%rd164], %r794;
	add.s32 	%r796, %r771, %r704;
	mul.wide.s32 	%rd165, %r796, 4;
	add.s64 	%rd166, %rd26, %rd165;
	st.shared.u32 	[%rd166], %r3130;
	add.s32 	%r797, %r772, %r704;
	mul.wide.s32 	%rd167, %r797, 4;
	add.s64 	%rd168, %rd26, %rd167;
	st.shared.u32 	[%rd168], %r3130;
	bar.sync 	0;
	mov.u32 	%r3145, %r3130;
	mov.u32 	%r3146, %r3130;
	mov.u32 	%r3147, %r3130;
	mov.u32 	%r3148, %r3130;
	mov.u32 	%r3149, %r3130;
	mov.u32 	%r3150, %r3130;
	mov.u32 	%r3151, %r3130;
	mov.u32 	%r3152, %r3130;
	mov.u32 	%r3153, %r3130;
	mov.u32 	%r3154, %r3130;
	mov.u32 	%r3155, %r3130;
	mov.u32 	%r3156, %r3130;
	mov.u32 	%r3157, %r3130;
	mov.u32 	%r3158, %r3130;
	mov.u32 	%r3159, %r3130;
	mov.u32 	%r3160, %r3130;
	mov.u32 	%r3161, %r3130;
	mov.u32 	%r3162, %r3130;
	mov.u32 	%r3163, %r3130;
	mov.u32 	%r3164, %r3130;
	mov.u32 	%r3165, %r3130;
	mov.u32 	%r3166, %r3130;
	mov.u32 	%r3167, %r3130;
	mov.u32 	%r3168, %r3130;
	@%p46 bra 	LBB0_43;
	bra.uni 	LBB0_17;
LBB0_43:                                // %oksrem3271
                                        //   in Loop: Header=BB0_16 Depth=1
	cvt.u16.u32 	%rs111, %r82;
	mul.hi.s16 	%rs112, %rs111, 10923;
	shr.u16 	%rs113, %rs112, 15;
	shr.s16 	%rs114, %rs112, 2;
	add.s16 	%rs115, %rs114, %rs113;
	mul.lo.s16 	%rs116, %rs115, 24;
	sub.s16 	%rs117, %rs111, %rs116;
	cvt.s32.s16 	%r798, %rs117;
	add.s32 	%r799, %r66, %r798;
	add.s32 	%r800, %r799, %r67;
	add.s32 	%r801, %r800, %r68;
	add.s32 	%r802, %r801, %r69;
	mul.wide.s32 	%rd169, %r802, 4;
	add.s64 	%rd171, %rd26, %rd169;
	ld.shared.u32 	%r3145, [%rd171];
	ld.shared.u32 	%r3146, [%rd10+4];
	ld.shared.u32 	%r3147, [%rd10+8];
	ld.shared.u32 	%r3148, [%rd10+12];
	ld.shared.u32 	%r3149, [%rd10+16];
	ld.shared.u32 	%r3150, [%rd10+20];
	ld.shared.u32 	%r3151, [%rd10+24];
	ld.shared.u32 	%r3152, [%rd10+28];
	ld.shared.u32 	%r3153, [%rd10+32];
	ld.shared.u32 	%r3154, [%rd10+36];
	ld.shared.u32 	%r3155, [%rd10+40];
	ld.shared.u32 	%r3156, [%rd10+44];
	ld.shared.u32 	%r3157, [%rd10+48];
	ld.shared.u32 	%r3158, [%rd10+52];
	ld.shared.u32 	%r3159, [%rd10+56];
	ld.shared.u32 	%r3160, [%rd10+60];
	add.s16 	%rs118, %rs111, 16;
	mul.hi.s16 	%rs119, %rs118, 10923;
	shr.u16 	%rs120, %rs119, 15;
	shr.s16 	%rs121, %rs119, 2;
	add.s16 	%rs122, %rs121, %rs120;
	mul.lo.s16 	%rs123, %rs122, 24;
	sub.s16 	%rs124, %rs118, %rs123;
	cvt.s32.s16 	%r803, %rs124;
	add.s32 	%r804, %r66, %r803;
	add.s32 	%r805, %r804, %r67;
	add.s32 	%r806, %r805, %r68;
	add.s32 	%r807, %r806, %r69;
	mul.wide.s32 	%rd172, %r807, 4;
	add.s64 	%rd173, %rd26, %rd172;
	ld.shared.u32 	%r3161, [%rd173];
	add.s16 	%rs125, %rs111, 17;
	mul.hi.s16 	%rs126, %rs125, 10923;
	shr.u16 	%rs127, %rs126, 15;
	shr.s16 	%rs128, %rs126, 2;
	add.s16 	%rs129, %rs128, %rs127;
	mul.lo.s16 	%rs130, %rs129, 24;
	sub.s16 	%rs131, %rs125, %rs130;
	cvt.s32.s16 	%r808, %rs131;
	add.s32 	%r809, %r66, %r808;
	add.s32 	%r810, %r809, %r67;
	add.s32 	%r811, %r810, %r68;
	add.s32 	%r812, %r811, %r69;
	mul.wide.s32 	%rd174, %r812, 4;
	add.s64 	%rd175, %rd26, %rd174;
	ld.shared.u32 	%r3162, [%rd175];
	add.s16 	%rs132, %rs111, 18;
	mul.hi.s16 	%rs133, %rs132, 10923;
	shr.u16 	%rs134, %rs133, 15;
	shr.s16 	%rs135, %rs133, 2;
	add.s16 	%rs136, %rs135, %rs134;
	mul.lo.s16 	%rs137, %rs136, 24;
	sub.s16 	%rs138, %rs132, %rs137;
	cvt.s32.s16 	%r813, %rs138;
	add.s32 	%r814, %r66, %r813;
	add.s32 	%r815, %r814, %r67;
	add.s32 	%r816, %r815, %r68;
	add.s32 	%r817, %r816, %r69;
	mul.wide.s32 	%rd176, %r817, 4;
	add.s64 	%rd177, %rd26, %rd176;
	ld.shared.u32 	%r3163, [%rd177];
	add.s16 	%rs139, %rs111, 19;
	mul.hi.s16 	%rs140, %rs139, 10923;
	shr.u16 	%rs141, %rs140, 15;
	shr.s16 	%rs142, %rs140, 2;
	add.s16 	%rs143, %rs142, %rs141;
	mul.lo.s16 	%rs144, %rs143, 24;
	sub.s16 	%rs145, %rs139, %rs144;
	cvt.s32.s16 	%r818, %rs145;
	add.s32 	%r819, %r66, %r818;
	add.s32 	%r820, %r819, %r67;
	add.s32 	%r821, %r820, %r68;
	add.s32 	%r822, %r821, %r69;
	mul.wide.s32 	%rd178, %r822, 4;
	add.s64 	%rd179, %rd26, %rd178;
	ld.shared.u32 	%r3164, [%rd179];
	add.s16 	%rs146, %rs111, 20;
	mul.hi.s16 	%rs147, %rs146, 10923;
	shr.u16 	%rs148, %rs147, 15;
	shr.s16 	%rs149, %rs147, 2;
	add.s16 	%rs150, %rs149, %rs148;
	mul.lo.s16 	%rs151, %rs150, 24;
	sub.s16 	%rs152, %rs146, %rs151;
	cvt.s32.s16 	%r823, %rs152;
	add.s32 	%r824, %r66, %r823;
	add.s32 	%r825, %r824, %r67;
	add.s32 	%r826, %r825, %r68;
	add.s32 	%r827, %r826, %r69;
	mul.wide.s32 	%rd180, %r827, 4;
	add.s64 	%rd181, %rd26, %rd180;
	ld.shared.u32 	%r3165, [%rd181];
	add.s16 	%rs153, %rs111, 21;
	mul.hi.s16 	%rs154, %rs153, 10923;
	shr.u16 	%rs155, %rs154, 15;
	shr.s16 	%rs156, %rs154, 2;
	add.s16 	%rs157, %rs156, %rs155;
	mul.lo.s16 	%rs158, %rs157, 24;
	sub.s16 	%rs159, %rs153, %rs158;
	cvt.s32.s16 	%r828, %rs159;
	add.s32 	%r829, %r66, %r828;
	add.s32 	%r830, %r829, %r67;
	add.s32 	%r831, %r830, %r68;
	add.s32 	%r832, %r831, %r69;
	mul.wide.s32 	%rd182, %r832, 4;
	add.s64 	%rd183, %rd26, %rd182;
	ld.shared.u32 	%r3166, [%rd183];
	add.s16 	%rs160, %rs111, 22;
	mul.hi.s16 	%rs161, %rs160, 10923;
	shr.u16 	%rs162, %rs161, 15;
	shr.s16 	%rs163, %rs161, 2;
	add.s16 	%rs164, %rs163, %rs162;
	mul.lo.s16 	%rs165, %rs164, 24;
	sub.s16 	%rs166, %rs160, %rs165;
	cvt.s32.s16 	%r833, %rs166;
	add.s32 	%r834, %r66, %r833;
	add.s32 	%r835, %r834, %r67;
	add.s32 	%r836, %r835, %r68;
	add.s32 	%r837, %r836, %r69;
	mul.wide.s32 	%rd184, %r837, 4;
	add.s64 	%rd185, %rd26, %rd184;
	ld.shared.u32 	%r3167, [%rd185];
	add.s16 	%rs167, %rs111, 23;
	mul.hi.s16 	%rs168, %rs167, 10923;
	shr.u16 	%rs169, %rs168, 15;
	shr.s16 	%rs170, %rs168, 2;
	add.s16 	%rs171, %rs170, %rs169;
	mul.lo.s16 	%rs172, %rs171, 24;
	sub.s16 	%rs173, %rs167, %rs172;
	cvt.s32.s16 	%r838, %rs173;
	add.s32 	%r839, %r66, %r838;
	add.s32 	%r840, %r839, %r67;
	add.s32 	%r841, %r840, %r68;
	add.s32 	%r842, %r841, %r69;
	mul.wide.s32 	%rd186, %r842, 4;
	add.s64 	%rd187, %rd26, %rd186;
	ld.shared.u32 	%r3168, [%rd187];
LBB0_17:                                // %L12784
                                        //   in Loop: Header=BB0_16 Depth=1
	bar.sync 	0;
	xor.b32  	%r107, %r3145, -2004318072;
	shr.u32 	%r108, %r107, 8;
	xor.b32  	%r109, %r3146, -2004318072;
	shr.u32 	%r110, %r109, 8;
	xor.b32  	%r111, %r3147, -2004318072;
	shr.u32 	%r112, %r111, 8;
	xor.b32  	%r113, %r3148, -2004318072;
	shr.u32 	%r114, %r113, 8;
	xor.b32  	%r115, %r3149, -2004318072;
	shr.u32 	%r116, %r115, 8;
	xor.b32  	%r117, %r3150, -2004318072;
	shr.u32 	%r118, %r117, 8;
	xor.b32  	%r119, %r3151, -2004318072;
	shr.u32 	%r120, %r119, 8;
	xor.b32  	%r121, %r3152, -2004318072;
	shr.u32 	%r122, %r121, 8;
	xor.b32  	%r123, %r3153, -2004318072;
	shr.u32 	%r124, %r123, 8;
	xor.b32  	%r125, %r3154, -2004318072;
	shr.u32 	%r126, %r125, 8;
	xor.b32  	%r127, %r3155, -2004318072;
	shr.u32 	%r128, %r127, 8;
	xor.b32  	%r129, %r3156, -2004318072;
	shr.u32 	%r130, %r129, 8;
	xor.b32  	%r131, %r3157, -2004318072;
	shr.u32 	%r132, %r131, 8;
	xor.b32  	%r133, %r3158, -2004318072;
	shr.u32 	%r134, %r133, 8;
	xor.b32  	%r135, %r3159, -2004318072;
	shr.u32 	%r136, %r135, 8;
	xor.b32  	%r137, %r3160, -2004318072;
	shr.u32 	%r138, %r137, 8;
	xor.b32  	%r139, %r3161, -2004318072;
	shr.u32 	%r140, %r139, 8;
	xor.b32  	%r141, %r3162, -2004318072;
	shr.u32 	%r142, %r141, 8;
	xor.b32  	%r143, %r3163, -2004318072;
	shr.u32 	%r144, %r143, 8;
	xor.b32  	%r145, %r3164, -2004318072;
	shr.u32 	%r146, %r145, 8;
	xor.b32  	%r147, %r3165, -2004318072;
	shr.u32 	%r148, %r147, 8;
	xor.b32  	%r149, %r3166, -2004318072;
	shr.u32 	%r150, %r149, 8;
	xor.b32  	%r151, %r3167, -2004318072;
	shr.u32 	%r152, %r151, 8;
	xor.b32  	%r153, %r3168, -2004318072;
	shr.u32 	%r154, %r153, 8;
	add.s32 	%r155, %r82, 1;
	add.s32 	%r156, %r82, 2;
	add.s32 	%r157, %r82, 3;
	mov.u32 	%r3169, 24;
	mov.u32 	%r3170, %r3130;
	bra.uni 	LBB0_18;
LBB0_37:                                // %L27540
                                        //   in Loop: Header=BB0_18 Depth=2
	add.s32 	%r3172, %r3172, 1;
	mov.u32 	%r3173, 0;
	mov.u32 	%r3174, %r3173;
	mov.u32 	%r3175, %r3173;
	mov.u32 	%r3176, %r3173;
	mov.u32 	%r3171, %r3173;
LBB0_38:                                // %L27541
                                        //   in Loop: Header=BB0_18 Depth=2
	bar.sync 	0;
	add.s32 	%r3170, %r3170, 1;
	add.s32 	%r3169, %r3169, -4;
	setp.eq.s32 	%p74, %r3169, -24;
	@%p74 bra 	LBB0_39;
LBB0_18:                                // %L12810
                                        //   Parent Loop BB0_16 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	mov.u16 	%rs174, 25600;
	// begin inline asm
	mov.b32 %r850, {%rs174, %rs174};
	// end inline asm
	mov.u16 	%rs176, 21504;
	// begin inline asm
	mov.b32 %r861, {%rs176, %rs176};
	// end inline asm
	mov.u32 	%r848, 983055;
	// begin inline asm
	lop3.b32 %r847, %r848, %r107, %r850, 202;
	// end inline asm
	mov.u16 	%rs178, 18432;
	// begin inline asm
	mov.b32 %r851, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r852, %r850, %r851;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r855, %r847, %r852;
	// end inline asm
	mov.u32 	%r859, 15728880;
	// begin inline asm
	lop3.b32 %r858, %r859, %r107, %r861, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r862, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r863, %r861, %r862;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r866, %r858, %r863;
	// end inline asm
	// begin inline asm
	lop3.b32 %r869, %r848, %r108, %r850, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r873, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r874, %r850, %r873;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r877, %r869, %r874;
	// end inline asm
	// begin inline asm
	lop3.b32 %r880, %r859, %r108, %r861, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r884, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r885, %r861, %r884;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r888, %r880, %r885;
	// end inline asm
	// begin inline asm
	mov.b32 %r896, {%rs174, %rs174};
	// end inline asm
	// begin inline asm
	mov.b32 %r907, {%rs176, %rs176};
	// end inline asm
	// begin inline asm
	lop3.b32 %r893, %r848, %r109, %r896, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r897, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r898, %r896, %r897;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r901, %r893, %r898;
	// end inline asm
	// begin inline asm
	lop3.b32 %r904, %r859, %r109, %r907, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r908, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r909, %r907, %r908;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r912, %r904, %r909;
	// end inline asm
	// begin inline asm
	lop3.b32 %r915, %r848, %r110, %r896, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r919, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r920, %r896, %r919;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r923, %r915, %r920;
	// end inline asm
	// begin inline asm
	lop3.b32 %r926, %r859, %r110, %r907, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r930, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r931, %r907, %r930;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r934, %r926, %r931;
	// end inline asm
	// begin inline asm
	mov.b32 %r942, {%rs174, %rs174};
	// end inline asm
	// begin inline asm
	mov.b32 %r953, {%rs176, %rs176};
	// end inline asm
	// begin inline asm
	lop3.b32 %r939, %r848, %r111, %r942, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r943, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r944, %r942, %r943;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r947, %r939, %r944;
	// end inline asm
	// begin inline asm
	lop3.b32 %r950, %r859, %r111, %r953, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r954, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r955, %r953, %r954;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r958, %r950, %r955;
	// end inline asm
	// begin inline asm
	lop3.b32 %r961, %r848, %r112, %r942, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r965, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r966, %r942, %r965;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r969, %r961, %r966;
	// end inline asm
	// begin inline asm
	lop3.b32 %r972, %r859, %r112, %r953, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r976, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r977, %r953, %r976;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r980, %r972, %r977;
	// end inline asm
	// begin inline asm
	mov.b32 %r988, {%rs174, %rs174};
	// end inline asm
	// begin inline asm
	mov.b32 %r999, {%rs176, %rs176};
	// end inline asm
	// begin inline asm
	lop3.b32 %r985, %r848, %r113, %r988, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r989, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r990, %r988, %r989;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r993, %r985, %r990;
	// end inline asm
	// begin inline asm
	lop3.b32 %r996, %r859, %r113, %r999, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1000, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1001, %r999, %r1000;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1004, %r996, %r1001;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1007, %r848, %r114, %r988, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1011, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1012, %r988, %r1011;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1015, %r1007, %r1012;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1018, %r859, %r114, %r999, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1022, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1023, %r999, %r1022;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1026, %r1018, %r1023;
	// end inline asm
	// begin inline asm
	mov.b32 %r1034, {%rs174, %rs174};
	// end inline asm
	// begin inline asm
	mov.b32 %r1045, {%rs176, %rs176};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1031, %r848, %r115, %r1034, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1035, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1036, %r1034, %r1035;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1039, %r1031, %r1036;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1042, %r859, %r115, %r1045, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1046, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1047, %r1045, %r1046;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1050, %r1042, %r1047;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1053, %r848, %r116, %r1034, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1057, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1058, %r1034, %r1057;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1061, %r1053, %r1058;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1064, %r859, %r116, %r1045, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1068, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1069, %r1045, %r1068;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1072, %r1064, %r1069;
	// end inline asm
	// begin inline asm
	mov.b32 %r1080, {%rs174, %rs174};
	// end inline asm
	// begin inline asm
	mov.b32 %r1091, {%rs176, %rs176};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1077, %r848, %r117, %r1080, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1081, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1082, %r1080, %r1081;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1085, %r1077, %r1082;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1088, %r859, %r117, %r1091, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1092, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1093, %r1091, %r1092;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1096, %r1088, %r1093;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1099, %r848, %r118, %r1080, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1103, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1104, %r1080, %r1103;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1107, %r1099, %r1104;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1110, %r859, %r118, %r1091, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1114, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1115, %r1091, %r1114;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1118, %r1110, %r1115;
	// end inline asm
	// begin inline asm
	mov.b32 %r1126, {%rs174, %rs174};
	// end inline asm
	// begin inline asm
	mov.b32 %r1137, {%rs176, %rs176};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1123, %r848, %r119, %r1126, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1127, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1128, %r1126, %r1127;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1131, %r1123, %r1128;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1134, %r859, %r119, %r1137, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1138, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1139, %r1137, %r1138;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1142, %r1134, %r1139;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1145, %r848, %r120, %r1126, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1149, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1150, %r1126, %r1149;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1153, %r1145, %r1150;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1156, %r859, %r120, %r1137, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1160, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1161, %r1137, %r1160;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1164, %r1156, %r1161;
	// end inline asm
	// begin inline asm
	mov.b32 %r1172, {%rs174, %rs174};
	// end inline asm
	// begin inline asm
	mov.b32 %r1183, {%rs176, %rs176};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1169, %r848, %r121, %r1172, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1173, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1174, %r1172, %r1173;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1177, %r1169, %r1174;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1180, %r859, %r121, %r1183, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1184, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1185, %r1183, %r1184;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1188, %r1180, %r1185;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1191, %r848, %r122, %r1172, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1195, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1196, %r1172, %r1195;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1199, %r1191, %r1196;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1202, %r859, %r122, %r1183, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1206, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1207, %r1183, %r1206;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1210, %r1202, %r1207;
	// end inline asm
	// begin inline asm
	mov.b32 %r1218, {%rs174, %rs174};
	// end inline asm
	// begin inline asm
	mov.b32 %r1229, {%rs176, %rs176};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1215, %r848, %r123, %r1218, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1219, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1220, %r1218, %r1219;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1223, %r1215, %r1220;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1226, %r859, %r123, %r1229, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1230, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1231, %r1229, %r1230;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1234, %r1226, %r1231;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1237, %r848, %r124, %r1218, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1241, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1242, %r1218, %r1241;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1245, %r1237, %r1242;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1248, %r859, %r124, %r1229, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1252, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1253, %r1229, %r1252;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1256, %r1248, %r1253;
	// end inline asm
	// begin inline asm
	mov.b32 %r1264, {%rs174, %rs174};
	// end inline asm
	// begin inline asm
	mov.b32 %r1275, {%rs176, %rs176};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1261, %r848, %r125, %r1264, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1265, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1266, %r1264, %r1265;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1269, %r1261, %r1266;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1272, %r859, %r125, %r1275, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1276, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1277, %r1275, %r1276;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1280, %r1272, %r1277;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1283, %r848, %r126, %r1264, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1287, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1288, %r1264, %r1287;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1291, %r1283, %r1288;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1294, %r859, %r126, %r1275, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1298, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1299, %r1275, %r1298;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1302, %r1294, %r1299;
	// end inline asm
	// begin inline asm
	mov.b32 %r1310, {%rs174, %rs174};
	// end inline asm
	// begin inline asm
	mov.b32 %r1321, {%rs176, %rs176};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1307, %r848, %r127, %r1310, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1311, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1312, %r1310, %r1311;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1315, %r1307, %r1312;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1318, %r859, %r127, %r1321, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1322, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1323, %r1321, %r1322;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1326, %r1318, %r1323;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1329, %r848, %r128, %r1310, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1333, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1334, %r1310, %r1333;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1337, %r1329, %r1334;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1340, %r859, %r128, %r1321, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1344, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1345, %r1321, %r1344;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1348, %r1340, %r1345;
	// end inline asm
	// begin inline asm
	mov.b32 %r1356, {%rs174, %rs174};
	// end inline asm
	// begin inline asm
	mov.b32 %r1367, {%rs176, %rs176};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1353, %r848, %r129, %r1356, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1357, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1358, %r1356, %r1357;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1361, %r1353, %r1358;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1364, %r859, %r129, %r1367, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1368, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1369, %r1367, %r1368;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1372, %r1364, %r1369;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1375, %r848, %r130, %r1356, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1379, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1380, %r1356, %r1379;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1383, %r1375, %r1380;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1386, %r859, %r130, %r1367, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1390, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1391, %r1367, %r1390;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1394, %r1386, %r1391;
	// end inline asm
	// begin inline asm
	mov.b32 %r1402, {%rs174, %rs174};
	// end inline asm
	// begin inline asm
	mov.b32 %r1413, {%rs176, %rs176};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1399, %r848, %r131, %r1402, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1403, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1404, %r1402, %r1403;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1407, %r1399, %r1404;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1410, %r859, %r131, %r1413, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1414, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1415, %r1413, %r1414;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1418, %r1410, %r1415;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1421, %r848, %r132, %r1402, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1425, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1426, %r1402, %r1425;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1429, %r1421, %r1426;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1432, %r859, %r132, %r1413, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1436, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1437, %r1413, %r1436;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1440, %r1432, %r1437;
	// end inline asm
	// begin inline asm
	mov.b32 %r1448, {%rs174, %rs174};
	// end inline asm
	// begin inline asm
	mov.b32 %r1459, {%rs176, %rs176};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1445, %r848, %r133, %r1448, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1449, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1450, %r1448, %r1449;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1453, %r1445, %r1450;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1456, %r859, %r133, %r1459, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1460, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1461, %r1459, %r1460;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1464, %r1456, %r1461;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1467, %r848, %r134, %r1448, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1471, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1472, %r1448, %r1471;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1475, %r1467, %r1472;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1478, %r859, %r134, %r1459, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1482, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1483, %r1459, %r1482;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1486, %r1478, %r1483;
	// end inline asm
	// begin inline asm
	mov.b32 %r1494, {%rs174, %rs174};
	// end inline asm
	// begin inline asm
	mov.b32 %r1505, {%rs176, %rs176};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1491, %r848, %r135, %r1494, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1495, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1496, %r1494, %r1495;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1499, %r1491, %r1496;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1502, %r859, %r135, %r1505, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1506, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1507, %r1505, %r1506;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1510, %r1502, %r1507;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1513, %r848, %r136, %r1494, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1517, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1518, %r1494, %r1517;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1521, %r1513, %r1518;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1524, %r859, %r136, %r1505, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1528, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1529, %r1505, %r1528;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1532, %r1524, %r1529;
	// end inline asm
	// begin inline asm
	mov.b32 %r1540, {%rs174, %rs174};
	// end inline asm
	// begin inline asm
	mov.b32 %r1551, {%rs176, %rs176};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1537, %r848, %r137, %r1540, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1541, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1542, %r1540, %r1541;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1545, %r1537, %r1542;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1548, %r859, %r137, %r1551, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1552, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1553, %r1551, %r1552;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1556, %r1548, %r1553;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1559, %r848, %r138, %r1540, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1563, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1564, %r1540, %r1563;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1567, %r1559, %r1564;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1570, %r859, %r138, %r1551, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1574, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1575, %r1551, %r1574;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1578, %r1570, %r1575;
	// end inline asm
	// begin inline asm
	mov.b32 %r1586, {%rs174, %rs174};
	// end inline asm
	// begin inline asm
	mov.b32 %r1597, {%rs176, %rs176};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1583, %r848, %r139, %r1586, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1587, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1588, %r1586, %r1587;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1591, %r1583, %r1588;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1594, %r859, %r139, %r1597, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1598, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1599, %r1597, %r1598;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1602, %r1594, %r1599;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1605, %r848, %r140, %r1586, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1609, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1610, %r1586, %r1609;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1613, %r1605, %r1610;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1616, %r859, %r140, %r1597, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1620, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1621, %r1597, %r1620;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1624, %r1616, %r1621;
	// end inline asm
	// begin inline asm
	mov.b32 %r1632, {%rs174, %rs174};
	// end inline asm
	// begin inline asm
	mov.b32 %r1643, {%rs176, %rs176};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1629, %r848, %r141, %r1632, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1633, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1634, %r1632, %r1633;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1637, %r1629, %r1634;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1640, %r859, %r141, %r1643, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1644, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1645, %r1643, %r1644;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1648, %r1640, %r1645;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1651, %r848, %r142, %r1632, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1655, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1656, %r1632, %r1655;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1659, %r1651, %r1656;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1662, %r859, %r142, %r1643, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1666, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1667, %r1643, %r1666;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1670, %r1662, %r1667;
	// end inline asm
	// begin inline asm
	mov.b32 %r1678, {%rs174, %rs174};
	// end inline asm
	// begin inline asm
	mov.b32 %r1689, {%rs176, %rs176};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1675, %r848, %r143, %r1678, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1679, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1680, %r1678, %r1679;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1683, %r1675, %r1680;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1686, %r859, %r143, %r1689, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1690, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1691, %r1689, %r1690;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1694, %r1686, %r1691;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1697, %r848, %r144, %r1678, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1701, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1702, %r1678, %r1701;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1705, %r1697, %r1702;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1708, %r859, %r144, %r1689, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1712, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1713, %r1689, %r1712;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1716, %r1708, %r1713;
	// end inline asm
	// begin inline asm
	mov.b32 %r1724, {%rs174, %rs174};
	// end inline asm
	// begin inline asm
	mov.b32 %r1735, {%rs176, %rs176};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1721, %r848, %r145, %r1724, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1725, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1726, %r1724, %r1725;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1729, %r1721, %r1726;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1732, %r859, %r145, %r1735, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1736, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1737, %r1735, %r1736;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1740, %r1732, %r1737;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1743, %r848, %r146, %r1724, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1747, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1748, %r1724, %r1747;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1751, %r1743, %r1748;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1754, %r859, %r146, %r1735, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1758, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1759, %r1735, %r1758;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1762, %r1754, %r1759;
	// end inline asm
	// begin inline asm
	mov.b32 %r1770, {%rs174, %rs174};
	// end inline asm
	// begin inline asm
	mov.b32 %r1781, {%rs176, %rs176};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1767, %r848, %r147, %r1770, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1771, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1772, %r1770, %r1771;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1775, %r1767, %r1772;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1778, %r859, %r147, %r1781, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1782, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1783, %r1781, %r1782;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1786, %r1778, %r1783;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1789, %r848, %r148, %r1770, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1793, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1794, %r1770, %r1793;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1797, %r1789, %r1794;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1800, %r859, %r148, %r1781, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1804, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1805, %r1781, %r1804;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1808, %r1800, %r1805;
	// end inline asm
	// begin inline asm
	mov.b32 %r1816, {%rs174, %rs174};
	// end inline asm
	// begin inline asm
	mov.b32 %r1827, {%rs176, %rs176};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1813, %r848, %r149, %r1816, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1817, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1818, %r1816, %r1817;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1821, %r1813, %r1818;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1824, %r859, %r149, %r1827, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1828, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1829, %r1827, %r1828;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1832, %r1824, %r1829;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1835, %r848, %r150, %r1816, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1839, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1840, %r1816, %r1839;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1843, %r1835, %r1840;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1846, %r859, %r150, %r1827, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1850, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1851, %r1827, %r1850;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1854, %r1846, %r1851;
	// end inline asm
	// begin inline asm
	mov.b32 %r1862, {%rs174, %rs174};
	// end inline asm
	// begin inline asm
	mov.b32 %r1873, {%rs176, %rs176};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1859, %r848, %r151, %r1862, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1863, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1864, %r1862, %r1863;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1867, %r1859, %r1864;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1870, %r859, %r151, %r1873, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1874, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1875, %r1873, %r1874;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1878, %r1870, %r1875;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1881, %r848, %r152, %r1862, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1885, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1886, %r1862, %r1885;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1889, %r1881, %r1886;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1892, %r859, %r152, %r1873, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1896, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1897, %r1873, %r1896;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1900, %r1892, %r1897;
	// end inline asm
	// begin inline asm
	mov.b32 %r1908, {%rs174, %rs174};
	// end inline asm
	// begin inline asm
	mov.b32 %r1919, {%rs176, %rs176};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1905, %r848, %r153, %r1908, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1909, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1910, %r1908, %r1909;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1913, %r1905, %r1910;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1916, %r859, %r153, %r1919, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1920, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1921, %r1919, %r1920;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1924, %r1916, %r1921;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1927, %r848, %r154, %r1908, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1931, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1932, %r1908, %r1931;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1935, %r1927, %r1932;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1938, %r859, %r154, %r1919, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1942, {%rs178, %rs178};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1943, %r1919, %r1942;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1946, %r1938, %r1943;
	// end inline asm
	setp.eq.s32 	%p51, %r3169, 24;
	selp.b32 	%r2302, %r855, 0, %p51;
	setp.eq.s32 	%p52, %r3169, 20;
	selp.b32 	%r2303, %r1039, %r2302, %p52;
	setp.eq.s32 	%p53, %r3169, 16;
	selp.b32 	%r2304, %r1223, %r2303, %p53;
	setp.eq.s32 	%p54, %r3169, 12;
	selp.b32 	%r2305, %r1407, %r2304, %p54;
	setp.eq.s32 	%p55, %r3169, 8;
	selp.b32 	%r2306, %r1591, %r2305, %p55;
	setp.eq.s32 	%p56, %r3169, 4;
	selp.b32 	%r2307, %r1775, %r2306, %p56;
	setp.eq.s32 	%p57, %r3169, 0;
	selp.b32 	%r2308, %r877, %r2307, %p57;
	setp.eq.s32 	%p58, %r3169, -4;
	selp.b32 	%r2309, %r1061, %r2308, %p58;
	setp.eq.s32 	%p59, %r3169, -8;
	selp.b32 	%r2310, %r1245, %r2309, %p59;
	setp.eq.s32 	%p60, %r3169, -12;
	selp.b32 	%r2311, %r1429, %r2310, %p60;
	setp.eq.s32 	%p61, %r3169, -16;
	selp.b32 	%r2312, %r1613, %r2311, %p61;
	setp.eq.s32 	%p62, %r3169, -20;
	selp.b32 	%r1951, %r1797, %r2312, %p62;
	selp.b32 	%r2313, %r866, 0, %p51;
	selp.b32 	%r2314, %r1050, %r2313, %p52;
	selp.b32 	%r2315, %r1234, %r2314, %p53;
	selp.b32 	%r2316, %r1418, %r2315, %p54;
	selp.b32 	%r2317, %r1602, %r2316, %p55;
	selp.b32 	%r2318, %r1786, %r2317, %p56;
	selp.b32 	%r2319, %r888, %r2318, %p57;
	selp.b32 	%r2320, %r1072, %r2319, %p58;
	selp.b32 	%r2321, %r1256, %r2320, %p59;
	selp.b32 	%r2322, %r1440, %r2321, %p60;
	selp.b32 	%r2323, %r1624, %r2322, %p61;
	selp.b32 	%r1954, %r1808, %r2323, %p62;
	selp.b32 	%r2324, %r901, 0, %p51;
	selp.b32 	%r2325, %r1085, %r2324, %p52;
	selp.b32 	%r2326, %r1269, %r2325, %p53;
	selp.b32 	%r2327, %r1453, %r2326, %p54;
	selp.b32 	%r2328, %r1637, %r2327, %p55;
	selp.b32 	%r2329, %r1821, %r2328, %p56;
	selp.b32 	%r2330, %r923, %r2329, %p57;
	selp.b32 	%r2331, %r1107, %r2330, %p58;
	selp.b32 	%r2332, %r1291, %r2331, %p59;
	selp.b32 	%r2333, %r1475, %r2332, %p60;
	selp.b32 	%r2334, %r1659, %r2333, %p61;
	selp.b32 	%r1957, %r1843, %r2334, %p62;
	selp.b32 	%r2335, %r912, 0, %p51;
	selp.b32 	%r2336, %r1096, %r2335, %p52;
	selp.b32 	%r2337, %r1280, %r2336, %p53;
	selp.b32 	%r2338, %r1464, %r2337, %p54;
	selp.b32 	%r2339, %r1648, %r2338, %p55;
	selp.b32 	%r2340, %r1832, %r2339, %p56;
	selp.b32 	%r2341, %r934, %r2340, %p57;
	selp.b32 	%r2342, %r1118, %r2341, %p58;
	selp.b32 	%r2343, %r1302, %r2342, %p59;
	selp.b32 	%r2344, %r1486, %r2343, %p60;
	selp.b32 	%r2345, %r1670, %r2344, %p61;
	selp.b32 	%r1960, %r1854, %r2345, %p62;
	selp.b32 	%r2346, %r947, 0, %p51;
	selp.b32 	%r2347, %r1131, %r2346, %p52;
	selp.b32 	%r2348, %r1315, %r2347, %p53;
	selp.b32 	%r2349, %r1499, %r2348, %p54;
	selp.b32 	%r2350, %r1683, %r2349, %p55;
	selp.b32 	%r2351, %r1867, %r2350, %p56;
	selp.b32 	%r2352, %r969, %r2351, %p57;
	selp.b32 	%r2353, %r1153, %r2352, %p58;
	selp.b32 	%r2354, %r1337, %r2353, %p59;
	selp.b32 	%r2355, %r1521, %r2354, %p60;
	selp.b32 	%r2356, %r1705, %r2355, %p61;
	selp.b32 	%r1963, %r1889, %r2356, %p62;
	selp.b32 	%r2357, %r958, 0, %p51;
	selp.b32 	%r2358, %r1142, %r2357, %p52;
	selp.b32 	%r2359, %r1326, %r2358, %p53;
	selp.b32 	%r2360, %r1510, %r2359, %p54;
	selp.b32 	%r2361, %r1694, %r2360, %p55;
	selp.b32 	%r2362, %r1878, %r2361, %p56;
	selp.b32 	%r2363, %r980, %r2362, %p57;
	selp.b32 	%r2364, %r1164, %r2363, %p58;
	selp.b32 	%r2365, %r1348, %r2364, %p59;
	selp.b32 	%r2366, %r1532, %r2365, %p60;
	selp.b32 	%r2367, %r1716, %r2366, %p61;
	selp.b32 	%r1966, %r1900, %r2367, %p62;
	selp.b32 	%r2368, %r993, 0, %p51;
	selp.b32 	%r2369, %r1177, %r2368, %p52;
	selp.b32 	%r2370, %r1361, %r2369, %p53;
	selp.b32 	%r2371, %r1545, %r2370, %p54;
	selp.b32 	%r2372, %r1729, %r2371, %p55;
	selp.b32 	%r2373, %r1913, %r2372, %p56;
	selp.b32 	%r2374, %r1015, %r2373, %p57;
	selp.b32 	%r2375, %r1199, %r2374, %p58;
	selp.b32 	%r2376, %r1383, %r2375, %p59;
	selp.b32 	%r2377, %r1567, %r2376, %p60;
	selp.b32 	%r2378, %r1751, %r2377, %p61;
	selp.b32 	%r1969, %r1935, %r2378, %p62;
	selp.b32 	%r2379, %r1004, 0, %p51;
	selp.b32 	%r2380, %r1188, %r2379, %p52;
	selp.b32 	%r2381, %r1372, %r2380, %p53;
	selp.b32 	%r2382, %r1556, %r2381, %p54;
	selp.b32 	%r2383, %r1740, %r2382, %p55;
	selp.b32 	%r2384, %r1924, %r2383, %p56;
	selp.b32 	%r2385, %r1026, %r2384, %p57;
	selp.b32 	%r2386, %r1210, %r2385, %p58;
	selp.b32 	%r2387, %r1394, %r2386, %p59;
	selp.b32 	%r2388, %r1578, %r2387, %p60;
	selp.b32 	%r2389, %r1762, %r2388, %p61;
	selp.b32 	%r1972, %r1946, %r2389, %p62;
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1im, %r1re}, %r3136;
    mov.b32 {%r2im, %r2re}, %r1951;
    mul.f16 %retmp, %r1re, %r2re;
    mul.f16 %imtmp, %r1re, %r2im;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1949, {%r0im, %r0re};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1im, %r1re}, %r3137;
    mov.b32 {%r2im, %r2re}, %r1954;
    mul.f16 %retmp, %r1re, %r2re;
    mul.f16 %imtmp, %r1re, %r2im;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1952, {%r0im, %r0re};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1im, %r1re}, %r3136;
    mov.b32 {%r2im, %r2re}, %r1957;
    mul.f16 %retmp, %r1re, %r2re;
    mul.f16 %imtmp, %r1re, %r2im;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1955, {%r0im, %r0re};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1im, %r1re}, %r3137;
    mov.b32 {%r2im, %r2re}, %r1960;
    mul.f16 %retmp, %r1re, %r2re;
    mul.f16 %imtmp, %r1re, %r2im;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1958, {%r0im, %r0re};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1im, %r1re}, %r3136;
    mov.b32 {%r2im, %r2re}, %r1963;
    mul.f16 %retmp, %r1re, %r2re;
    mul.f16 %imtmp, %r1re, %r2im;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1961, {%r0im, %r0re};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1im, %r1re}, %r3137;
    mov.b32 {%r2im, %r2re}, %r1966;
    mul.f16 %retmp, %r1re, %r2re;
    mul.f16 %imtmp, %r1re, %r2im;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1964, {%r0im, %r0re};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1im, %r1re}, %r3136;
    mov.b32 {%r2im, %r2re}, %r1969;
    mul.f16 %retmp, %r1re, %r2re;
    mul.f16 %imtmp, %r1re, %r2im;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1967, {%r0im, %r0re};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1im, %r1re}, %r3137;
    mov.b32 {%r2im, %r2re}, %r1972;
    mul.f16 %retmp, %r1re, %r2re;
    mul.f16 %imtmp, %r1re, %r2im;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1970, {%r0im, %r0re};
}

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2033, %r2036}, {%r289, %r286}, {%r1949}, {%r3130, %r3130};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2042, %r2045}, {%r289, %r286}, {%r1952}, {%r3130, %r3130};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2051, %r2054}, {%r289, %r286}, {%r1955}, {%r3130, %r3130};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2060, %r2063}, {%r289, %r286}, {%r1958}, {%r3130, %r3130};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2069, %r2072}, {%r289, %r286}, {%r1961}, {%r3130, %r3130};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2078, %r2081}, {%r289, %r286}, {%r1964}, {%r3130, %r3130};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2087, %r2090}, {%r289, %r286}, {%r1967}, {%r3130, %r3130};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2096, %r2099}, {%r289, %r286}, {%r1970}, {%r3130, %r3130};
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2029, %r326;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2031, %r2029, %r2033;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2034, %r323, %r2036, %r2031;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2038, %r326;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2040, %r2038, %r2042;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2043, %r323, %r2045, %r2040;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2047, %r326;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2049, %r2047, %r2051;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2052, %r323, %r2054, %r2049;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2056, %r326;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2058, %r2056, %r2060;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2061, %r323, %r2063, %r2058;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2065, %r326;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2067, %r2065, %r2069;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2070, %r323, %r2072, %r2067;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2074, %r326;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2076, %r2074, %r2078;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2079, %r323, %r2081, %r2076;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2083, %r326;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2085, %r2083, %r2087;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2088, %r323, %r2090, %r2085;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2092, %r326;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2094, %r2092, %r2096;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2097, %r323, %r2099, %r2094;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2101, %r326, %r2036;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2104, %r323, %r2033, %r2101;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2108, %r326, %r2045;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2111, %r323, %r2042, %r2108;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2115, %r326, %r2054;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2118, %r323, %r2051, %r2115;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2122, %r326, %r2063;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2125, %r323, %r2060, %r2122;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2129, %r326, %r2072;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2132, %r323, %r2069, %r2129;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2136, %r326, %r2081;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2139, %r323, %r2078, %r2136;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2143, %r326, %r2090;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2146, %r323, %r2087, %r2143;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2150, %r326, %r2099;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2153, %r323, %r2096, %r2150;
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2238, %r2239}, {%r356, %r350, %r353, %r347}, {%r2104, %r2034}, {%r3130, %r3130};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2246, %r2247}, {%r356, %r350, %r353, %r347}, {%r2111, %r2043}, {%r3130, %r3130};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2254, %r2255}, {%r356, %r350, %r353, %r347}, {%r2118, %r2052}, {%r3130, %r3130};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2262, %r2263}, {%r356, %r350, %r353, %r347}, {%r2125, %r2061}, {%r3130, %r3130};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2270, %r2271}, {%r356, %r350, %r353, %r347}, {%r2132, %r2070}, {%r3130, %r3130};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2278, %r2279}, {%r356, %r350, %r353, %r347}, {%r2139, %r2079}, {%r3130, %r3130};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2286, %r2287}, {%r356, %r350, %r353, %r347}, {%r2146, %r2088}, {%r3130, %r3130};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2294, %r2295}, {%r356, %r350, %r353, %r347}, {%r2153, %r2097}, {%r3130, %r3130};
	// end inline asm
	// begin inline asm
	prmt.b32 %r2237, %r2238, %r2239, %r649;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2241, %r2238, %r2239, %r653;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2245, %r2246, %r2247, %r649;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2249, %r2246, %r2247, %r653;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2253, %r2254, %r2255, %r649;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2257, %r2254, %r2255, %r653;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2261, %r2262, %r2263, %r649;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2265, %r2262, %r2263, %r653;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2269, %r2270, %r2271, %r649;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2273, %r2270, %r2271, %r653;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2277, %r2278, %r2279, %r649;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2281, %r2278, %r2279, %r653;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2285, %r2286, %r2287, %r649;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2289, %r2286, %r2287, %r653;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2293, %r2294, %r2295, %r649;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2297, %r2294, %r2295, %r653;
	// end inline asm
	st.shared.u32 	[%rd6], %r2237;
	st.shared.u32 	[%rd7+33024], %r2241;
	st.shared.u32 	[%rd7+128], %r2245;
	st.shared.u32 	[%rd7+33152], %r2249;
	cvt.u16.u32 	%rs462, %r3170;
	and.b16  	%rs463, %rs462, 255;
	mul.lo.s16 	%rs464, %rs463, 171;
	shr.u16 	%rs465, %rs464, 11;
	mul.lo.s16 	%rs466, %rs465, 12;
	sub.s16 	%rs467, %rs462, %rs466;
	shl.b16 	%rs468, %rs467, 2;
	cvt.u32.u16 	%r2390, %rs468;
	and.b32  	%r2391, %r2390, 252;
	add.s32 	%r2392, %r155, %r2391;
	shr.s32 	%r2393, %r2392, 31;
	shr.u32 	%r2394, %r2393, 30;
	add.s32 	%r2395, %r2392, %r2394;
	and.b32  	%r2396, %r2395, 67108860;
	sub.s32 	%r2397, %r2392, %r2396;
	shl.b32 	%r166, %r2397, 6;
	add.s32 	%r2398, %r70, %r166;
	mul.wide.s32 	%rd188, %r2398, 4;
	add.s64 	%rd190, %rd26, %rd188;
	st.shared.u32 	[%rd190], %r2253;
	add.s32 	%r167, %r166, 8256;
	add.s32 	%r2399, %r70, %r167;
	mul.wide.u32 	%rd191, %r2399, 4;
	add.s64 	%rd192, %rd26, %rd191;
	st.shared.u32 	[%rd192], %r2257;
	or.b32  	%r168, %r166, 32;
	add.s32 	%r2400, %r70, %r168;
	mul.wide.s32 	%rd193, %r2400, 4;
	add.s64 	%rd194, %rd26, %rd193;
	st.shared.u32 	[%rd194], %r2261;
	add.s32 	%r169, %r166, 8288;
	add.s32 	%r2401, %r70, %r169;
	mul.wide.u32 	%rd195, %r2401, 4;
	add.s64 	%rd196, %rd26, %rd195;
	st.shared.u32 	[%rd196], %r2265;
	add.s32 	%r2402, %r156, %r2391;
	shr.s32 	%r2403, %r2402, 31;
	shr.u32 	%r2404, %r2403, 30;
	add.s32 	%r2405, %r2402, %r2404;
	and.b32  	%r2406, %r2405, 67108860;
	sub.s32 	%r2407, %r2402, %r2406;
	shl.b32 	%r170, %r2407, 6;
	add.s32 	%r2408, %r70, %r170;
	mul.wide.s32 	%rd197, %r2408, 4;
	add.s64 	%rd198, %rd26, %rd197;
	st.shared.u32 	[%rd198], %r2269;
	add.s32 	%r171, %r170, 8256;
	add.s32 	%r2409, %r70, %r171;
	mul.wide.u32 	%rd199, %r2409, 4;
	add.s64 	%rd200, %rd26, %rd199;
	st.shared.u32 	[%rd200], %r2273;
	or.b32  	%r172, %r170, 32;
	add.s32 	%r2410, %r70, %r172;
	mul.wide.s32 	%rd201, %r2410, 4;
	add.s64 	%rd202, %rd26, %rd201;
	st.shared.u32 	[%rd202], %r2277;
	add.s32 	%r173, %r170, 8288;
	add.s32 	%r2411, %r70, %r173;
	mul.wide.u32 	%rd203, %r2411, 4;
	add.s64 	%rd204, %rd26, %rd203;
	st.shared.u32 	[%rd204], %r2281;
	add.s32 	%r2412, %r157, %r2391;
	shr.s32 	%r2413, %r2412, 31;
	shr.u32 	%r2414, %r2413, 30;
	add.s32 	%r2415, %r2412, %r2414;
	and.b32  	%r2416, %r2415, 67108860;
	sub.s32 	%r2417, %r2412, %r2416;
	shl.b32 	%r174, %r2417, 6;
	add.s32 	%r2418, %r70, %r174;
	mul.wide.s32 	%rd205, %r2418, 4;
	add.s64 	%rd206, %rd26, %rd205;
	st.shared.u32 	[%rd206], %r2285;
	add.s32 	%r175, %r174, 8256;
	add.s32 	%r2419, %r70, %r175;
	mul.wide.u32 	%rd207, %r2419, 4;
	add.s64 	%rd208, %rd26, %rd207;
	st.shared.u32 	[%rd208], %r2289;
	or.b32  	%r176, %r174, 32;
	add.s32 	%r2420, %r70, %r176;
	mul.wide.s32 	%rd209, %r2420, 4;
	add.s64 	%rd210, %rd26, %rd209;
	st.shared.u32 	[%rd210], %r2293;
	add.s32 	%r177, %r174, 8288;
	add.s32 	%r2421, %r70, %r177;
	mul.wide.u32 	%rd211, %r2421, 4;
	add.s64 	%rd212, %rd26, %rd211;
	st.shared.u32 	[%rd212], %r2297;
	bar.sync 	0;
	mov.u32 	%r3177, %r3130;
	mov.u32 	%r3178, %r3130;
	mov.u32 	%r3179, %r3130;
	mov.u32 	%r3180, %r3130;
	@%p50 bra 	LBB0_44;
	bra.uni 	LBB0_19;
LBB0_44:                                // %oksrem7204
                                        //   in Loop: Header=BB0_18 Depth=2
	ld.shared.u32 	%r3177, [%rd8];
	ld.shared.u32 	%r3178, [%rd9+33024];
	ld.shared.u32 	%r3179, [%rd9+128];
	ld.shared.u32 	%r3180, [%rd9+33152];
LBB0_19:                                // %L20884
                                        //   in Loop: Header=BB0_18 Depth=2
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2454, %r2457}, {%r289, %r286}, {%r3177}, {%r3130, %r3130};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2463, %r2466}, {%r289, %r286}, {%r3178}, {%r3130, %r3130};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2472, %r2475}, {%r289, %r286}, {%r3179}, {%r3130, %r3130};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2481, %r2484}, {%r289, %r286}, {%r3180}, {%r3130, %r3130};
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2450, %r326;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2452, %r2450, %r2454;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2455, %r323, %r2457, %r2452;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2459, %r326;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2461, %r2459, %r2463;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2464, %r323, %r2466, %r2461;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2468, %r326;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2470, %r2468, %r2472;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2473, %r323, %r2475, %r2470;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2477, %r326;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2479, %r2477, %r2481;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2482, %r323, %r2484, %r2479;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2486, %r326, %r2457;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2489, %r323, %r2454, %r2486;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2493, %r326, %r2466;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2496, %r323, %r2463, %r2493;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2500, %r326, %r2475;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2503, %r323, %r2472, %r2500;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2507, %r326, %r2484;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2510, %r323, %r2481, %r2507;
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2555, %r2559}, {%r356, %r350, %r353, %r347}, {%r2489, %r2455}, {%r3130, %r3130};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2563, %r2567}, {%r356, %r350, %r353, %r347}, {%r2496, %r2464}, {%r3130, %r3130};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2571, %r2575}, {%r356, %r350, %r353, %r347}, {%r2503, %r2473}, {%r3130, %r3130};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2579, %r2583}, {%r356, %r350, %r353, %r347}, {%r2510, %r2482}, {%r3130, %r3130};
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2554, %r2555, %r2555, %r3176;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r3186, %r2559, %r2559, %r2554;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2562, %r2563, %r2563, %r3175;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r3185, %r2567, %r2567, %r2562;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2570, %r2571, %r2571, %r3174;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r3184, %r2575, %r2575, %r2570;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2578, %r2579, %r2579, %r3173;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r3183, %r2583, %r2583, %r2578;
	// end inline asm
	add.s32 	%r3181, %r3171, 1;
	setp.ne.s32 	%p63, %r3181, 40;
	@%p63 bra 	LBB0_23;
// %bb.20:                              // %L21067
                                        //   in Loop: Header=BB0_18 Depth=2
	@%p26 bra 	LBB0_22;
// %bb.21:                              // %L21132
                                        //   in Loop: Header=BB0_18 Depth=2
	mul.lo.s32 	%r2586, %r3172, 193536;
	add.s32 	%r2587, %r73, %r2586;
	add.s32 	%r2588, %r2587, %r72;
	add.s32 	%r2589, %r2588, %r44;
	mul.wide.u32 	%rd213, %r2589, 4;
	add.s64 	%rd214, %rd4, %rd213;
	st.global.u32 	[%rd214], %r3186;
	add.s32 	%r2590, %r2587, %r74;
	add.s32 	%r2591, %r2590, %r44;
	mul.wide.u32 	%rd215, %r2591, 4;
	add.s64 	%rd216, %rd4, %rd215;
	st.global.u32 	[%rd216], %r3185;
	cvt.u64.u32 	%rd217, %r44;
	cvt.u64.u32 	%rd218, %r72;
	cvt.u64.u32 	%rd219, %r73;
	cvt.u64.u32 	%rd220, %r2586;
	add.s64 	%rd221, %rd220, %rd219;
	add.s64 	%rd222, %rd221, %rd218;
	add.s64 	%rd223, %rd222, %rd217;
	shl.b64 	%rd224, %rd223, 2;
	add.s64 	%rd225, %rd4, %rd224;
	st.global.u32 	[%rd225+387072], %r3184;
	cvt.u64.u32 	%rd226, %r74;
	add.s64 	%rd227, %rd221, %rd226;
	add.s64 	%rd228, %rd227, %rd217;
	shl.b64 	%rd229, %rd228, 2;
	add.s64 	%rd230, %rd4, %rd229;
	st.global.u32 	[%rd230+387072], %r3183;
LBB0_22:                                // %L21645
                                        //   in Loop: Header=BB0_18 Depth=2
	add.s32 	%r3172, %r3172, 1;
	mov.u32 	%r3181, 0;
	mov.u32 	%r3183, %r3181;
	mov.u32 	%r3184, %r3181;
	mov.u32 	%r3185, %r3181;
	mov.u32 	%r3186, %r3181;
LBB0_23:                                // %L21646
                                        //   in Loop: Header=BB0_18 Depth=2
	mov.u32 	%r2593, 0;
	mov.u32 	%r3187, %r2593;
	mov.u32 	%r3188, %r2593;
	mov.u32 	%r3189, %r2593;
	mov.u32 	%r3190, %r2593;
	@%p50 bra 	LBB0_45;
	bra.uni 	LBB0_24;
LBB0_45:                                // %oksrem7958
                                        //   in Loop: Header=BB0_18 Depth=2
	add.s32 	%r2594, %r71, %r166;
	mul.wide.s32 	%rd231, %r2594, 4;
	add.s64 	%rd233, %rd26, %rd231;
	ld.shared.u32 	%r3187, [%rd233];
	add.s32 	%r2595, %r71, %r167;
	mul.wide.u32 	%rd234, %r2595, 4;
	add.s64 	%rd235, %rd26, %rd234;
	ld.shared.u32 	%r3188, [%rd235];
	add.s32 	%r2596, %r71, %r168;
	mul.wide.s32 	%rd236, %r2596, 4;
	add.s64 	%rd237, %rd26, %rd236;
	ld.shared.u32 	%r3189, [%rd237];
	add.s32 	%r2597, %r71, %r169;
	mul.wide.u32 	%rd238, %r2597, 4;
	add.s64 	%rd239, %rd26, %rd238;
	ld.shared.u32 	%r3190, [%rd239];
LBB0_24:                                // %L22849
                                        //   in Loop: Header=BB0_18 Depth=2
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2630, %r2633}, {%r289, %r286}, {%r3187}, {%r2593, %r2593};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2639, %r2642}, {%r289, %r286}, {%r3188}, {%r2593, %r2593};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2648, %r2651}, {%r289, %r286}, {%r3189}, {%r2593, %r2593};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2657, %r2660}, {%r289, %r286}, {%r3190}, {%r2593, %r2593};
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2626, %r326;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2628, %r2626, %r2630;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2631, %r323, %r2633, %r2628;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2635, %r326;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2637, %r2635, %r2639;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2640, %r323, %r2642, %r2637;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2644, %r326;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2646, %r2644, %r2648;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2649, %r323, %r2651, %r2646;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2653, %r326;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2655, %r2653, %r2657;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2658, %r323, %r2660, %r2655;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2662, %r326, %r2633;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2665, %r323, %r2630, %r2662;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2669, %r326, %r2642;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2672, %r323, %r2639, %r2669;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2676, %r326, %r2651;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2679, %r323, %r2648, %r2676;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2683, %r326, %r2660;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2686, %r323, %r2657, %r2683;
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2731, %r2735}, {%r356, %r350, %r353, %r347}, {%r2665, %r2631}, {%r2593, %r2593};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2739, %r2743}, {%r356, %r350, %r353, %r347}, {%r2672, %r2640}, {%r2593, %r2593};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2747, %r2751}, {%r356, %r350, %r353, %r347}, {%r2679, %r2649}, {%r2593, %r2593};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2755, %r2759}, {%r356, %r350, %r353, %r347}, {%r2686, %r2658}, {%r2593, %r2593};
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2730, %r2731, %r2731, %r3186;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r3196, %r2735, %r2735, %r2730;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2738, %r2739, %r2739, %r3185;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r3195, %r2743, %r2743, %r2738;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2746, %r2747, %r2747, %r3184;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r3194, %r2751, %r2751, %r2746;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2754, %r2755, %r2755, %r3183;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r3193, %r2759, %r2759, %r2754;
	// end inline asm
	add.s32 	%r3191, %r3181, 1;
	setp.ne.s32 	%p66, %r3191, 40;
	@%p66 bra 	LBB0_28;
// %bb.25:                              // %L23032
                                        //   in Loop: Header=BB0_18 Depth=2
	@%p26 bra 	LBB0_27;
// %bb.26:                              // %L23097
                                        //   in Loop: Header=BB0_18 Depth=2
	mul.lo.s32 	%r2762, %r3172, 193536;
	add.s32 	%r2763, %r73, %r2762;
	add.s32 	%r2764, %r2763, %r72;
	add.s32 	%r2765, %r2764, %r44;
	mul.wide.u32 	%rd240, %r2765, 4;
	add.s64 	%rd241, %rd4, %rd240;
	st.global.u32 	[%rd241], %r3196;
	add.s32 	%r2766, %r2763, %r74;
	add.s32 	%r2767, %r2766, %r44;
	mul.wide.u32 	%rd242, %r2767, 4;
	add.s64 	%rd243, %rd4, %rd242;
	st.global.u32 	[%rd243], %r3195;
	cvt.u64.u32 	%rd244, %r44;
	cvt.u64.u32 	%rd245, %r72;
	cvt.u64.u32 	%rd246, %r73;
	cvt.u64.u32 	%rd247, %r2762;
	add.s64 	%rd248, %rd247, %rd246;
	add.s64 	%rd249, %rd248, %rd245;
	add.s64 	%rd250, %rd249, %rd244;
	shl.b64 	%rd251, %rd250, 2;
	add.s64 	%rd252, %rd4, %rd251;
	st.global.u32 	[%rd252+387072], %r3194;
	cvt.u64.u32 	%rd253, %r74;
	add.s64 	%rd254, %rd248, %rd253;
	add.s64 	%rd255, %rd254, %rd244;
	shl.b64 	%rd256, %rd255, 2;
	add.s64 	%rd257, %rd4, %rd256;
	st.global.u32 	[%rd257+387072], %r3193;
LBB0_27:                                // %L23610
                                        //   in Loop: Header=BB0_18 Depth=2
	add.s32 	%r3172, %r3172, 1;
	mov.u32 	%r3191, 0;
	mov.u32 	%r3193, %r3191;
	mov.u32 	%r3194, %r3191;
	mov.u32 	%r3195, %r3191;
	mov.u32 	%r3196, %r3191;
LBB0_28:                                // %L23611
                                        //   in Loop: Header=BB0_18 Depth=2
	mov.u32 	%r2769, 0;
	mov.u32 	%r3197, %r2769;
	mov.u32 	%r3198, %r2769;
	mov.u32 	%r3199, %r2769;
	mov.u32 	%r3200, %r2769;
	@%p50 bra 	LBB0_46;
	bra.uni 	LBB0_29;
LBB0_46:                                // %oksrem8712
                                        //   in Loop: Header=BB0_18 Depth=2
	add.s32 	%r2770, %r71, %r170;
	mul.wide.s32 	%rd258, %r2770, 4;
	add.s64 	%rd260, %rd26, %rd258;
	ld.shared.u32 	%r3197, [%rd260];
	add.s32 	%r2771, %r71, %r171;
	mul.wide.u32 	%rd261, %r2771, 4;
	add.s64 	%rd262, %rd26, %rd261;
	ld.shared.u32 	%r3198, [%rd262];
	add.s32 	%r2772, %r71, %r172;
	mul.wide.s32 	%rd263, %r2772, 4;
	add.s64 	%rd264, %rd26, %rd263;
	ld.shared.u32 	%r3199, [%rd264];
	add.s32 	%r2773, %r71, %r173;
	mul.wide.u32 	%rd265, %r2773, 4;
	add.s64 	%rd266, %rd26, %rd265;
	ld.shared.u32 	%r3200, [%rd266];
LBB0_29:                                // %L24814
                                        //   in Loop: Header=BB0_18 Depth=2
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2806, %r2809}, {%r289, %r286}, {%r3197}, {%r2769, %r2769};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2815, %r2818}, {%r289, %r286}, {%r3198}, {%r2769, %r2769};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2824, %r2827}, {%r289, %r286}, {%r3199}, {%r2769, %r2769};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2833, %r2836}, {%r289, %r286}, {%r3200}, {%r2769, %r2769};
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2802, %r326;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2804, %r2802, %r2806;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2807, %r323, %r2809, %r2804;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2811, %r326;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2813, %r2811, %r2815;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2816, %r323, %r2818, %r2813;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2820, %r326;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2822, %r2820, %r2824;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2825, %r323, %r2827, %r2822;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2829, %r326;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2831, %r2829, %r2833;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2834, %r323, %r2836, %r2831;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2838, %r326, %r2809;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2841, %r323, %r2806, %r2838;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2845, %r326, %r2818;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2848, %r323, %r2815, %r2845;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2852, %r326, %r2827;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2855, %r323, %r2824, %r2852;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2859, %r326, %r2836;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2862, %r323, %r2833, %r2859;
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2907, %r2911}, {%r356, %r350, %r353, %r347}, {%r2841, %r2807}, {%r2769, %r2769};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2915, %r2919}, {%r356, %r350, %r353, %r347}, {%r2848, %r2816}, {%r2769, %r2769};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2923, %r2927}, {%r356, %r350, %r353, %r347}, {%r2855, %r2825}, {%r2769, %r2769};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2931, %r2935}, {%r356, %r350, %r353, %r347}, {%r2862, %r2834}, {%r2769, %r2769};
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2906, %r2907, %r2907, %r3196;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r3206, %r2911, %r2911, %r2906;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2914, %r2915, %r2915, %r3195;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r3205, %r2919, %r2919, %r2914;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2922, %r2923, %r2923, %r3194;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r3204, %r2927, %r2927, %r2922;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2930, %r2931, %r2931, %r3193;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r3203, %r2935, %r2935, %r2930;
	// end inline asm
	add.s32 	%r3201, %r3191, 1;
	setp.ne.s32 	%p69, %r3201, 40;
	@%p69 bra 	LBB0_33;
// %bb.30:                              // %L24997
                                        //   in Loop: Header=BB0_18 Depth=2
	@%p26 bra 	LBB0_32;
// %bb.31:                              // %L25062
                                        //   in Loop: Header=BB0_18 Depth=2
	mul.lo.s32 	%r2938, %r3172, 193536;
	add.s32 	%r2939, %r73, %r2938;
	add.s32 	%r2940, %r2939, %r72;
	add.s32 	%r2941, %r2940, %r44;
	mul.wide.u32 	%rd267, %r2941, 4;
	add.s64 	%rd268, %rd4, %rd267;
	st.global.u32 	[%rd268], %r3206;
	add.s32 	%r2942, %r2939, %r74;
	add.s32 	%r2943, %r2942, %r44;
	mul.wide.u32 	%rd269, %r2943, 4;
	add.s64 	%rd270, %rd4, %rd269;
	st.global.u32 	[%rd270], %r3205;
	cvt.u64.u32 	%rd271, %r44;
	cvt.u64.u32 	%rd272, %r72;
	cvt.u64.u32 	%rd273, %r73;
	cvt.u64.u32 	%rd274, %r2938;
	add.s64 	%rd275, %rd274, %rd273;
	add.s64 	%rd276, %rd275, %rd272;
	add.s64 	%rd277, %rd276, %rd271;
	shl.b64 	%rd278, %rd277, 2;
	add.s64 	%rd279, %rd4, %rd278;
	st.global.u32 	[%rd279+387072], %r3204;
	cvt.u64.u32 	%rd280, %r74;
	add.s64 	%rd281, %rd275, %rd280;
	add.s64 	%rd282, %rd281, %rd271;
	shl.b64 	%rd283, %rd282, 2;
	add.s64 	%rd284, %rd4, %rd283;
	st.global.u32 	[%rd284+387072], %r3203;
LBB0_32:                                // %L25575
                                        //   in Loop: Header=BB0_18 Depth=2
	add.s32 	%r3172, %r3172, 1;
	mov.u32 	%r3201, 0;
	mov.u32 	%r3203, %r3201;
	mov.u32 	%r3204, %r3201;
	mov.u32 	%r3205, %r3201;
	mov.u32 	%r3206, %r3201;
LBB0_33:                                // %L25576
                                        //   in Loop: Header=BB0_18 Depth=2
	mov.u32 	%r2945, 0;
	mov.u32 	%r3207, %r2945;
	mov.u32 	%r3208, %r2945;
	mov.u32 	%r3209, %r2945;
	mov.u32 	%r3210, %r2945;
	@%p50 bra 	LBB0_47;
	bra.uni 	LBB0_34;
LBB0_47:                                // %oksrem9466
                                        //   in Loop: Header=BB0_18 Depth=2
	add.s32 	%r2946, %r71, %r174;
	mul.wide.s32 	%rd285, %r2946, 4;
	add.s64 	%rd287, %rd26, %rd285;
	ld.shared.u32 	%r3210, [%rd287];
	add.s32 	%r2947, %r71, %r175;
	mul.wide.u32 	%rd288, %r2947, 4;
	add.s64 	%rd289, %rd26, %rd288;
	ld.shared.u32 	%r3209, [%rd289];
	add.s32 	%r2948, %r71, %r176;
	mul.wide.s32 	%rd290, %r2948, 4;
	add.s64 	%rd291, %rd26, %rd290;
	ld.shared.u32 	%r3208, [%rd291];
	add.s32 	%r2949, %r71, %r177;
	mul.wide.u32 	%rd292, %r2949, 4;
	add.s64 	%rd293, %rd26, %rd292;
	ld.shared.u32 	%r3207, [%rd293];
LBB0_34:                                // %L26779
                                        //   in Loop: Header=BB0_18 Depth=2
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2982, %r2985}, {%r289, %r286}, {%r3210}, {%r2945, %r2945};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2991, %r2994}, {%r289, %r286}, {%r3209}, {%r2945, %r2945};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r3000, %r3003}, {%r289, %r286}, {%r3208}, {%r2945, %r2945};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r3009, %r3012}, {%r289, %r286}, {%r3207}, {%r2945, %r2945};
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2978, %r326;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2980, %r2978, %r2982;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2983, %r323, %r2985, %r2980;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2987, %r326;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2989, %r2987, %r2991;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2992, %r323, %r2994, %r2989;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2996, %r326;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2998, %r2996, %r3000;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r3001, %r323, %r3003, %r2998;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r3005, %r326;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r3007, %r3005, %r3009;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r3010, %r323, %r3012, %r3007;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r3014, %r326, %r2985;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r3017, %r323, %r2982, %r3014;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r3021, %r326, %r2994;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r3024, %r323, %r2991, %r3021;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r3028, %r326, %r3003;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r3031, %r323, %r3000, %r3028;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r3035, %r326, %r3012;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r3038, %r323, %r3009, %r3035;
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r3083, %r3087}, {%r356, %r350, %r353, %r347}, {%r3017, %r2983}, {%r2945, %r2945};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r3091, %r3095}, {%r356, %r350, %r353, %r347}, {%r3024, %r2992}, {%r2945, %r2945};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r3099, %r3103}, {%r356, %r350, %r353, %r347}, {%r3031, %r3001}, {%r2945, %r2945};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r3107, %r3111}, {%r356, %r350, %r353, %r347}, {%r3038, %r3010}, {%r2945, %r2945};
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r3082, %r3083, %r3083, %r3206;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r3176, %r3087, %r3087, %r3082;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r3090, %r3091, %r3091, %r3205;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r3175, %r3095, %r3095, %r3090;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r3098, %r3099, %r3099, %r3204;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r3174, %r3103, %r3103, %r3098;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r3106, %r3107, %r3107, %r3203;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r3173, %r3111, %r3111, %r3106;
	// end inline asm
	add.s32 	%r3171, %r3201, 1;
	setp.ne.s32 	%p72, %r3171, 40;
	@%p72 bra 	LBB0_38;
// %bb.35:                              // %L26962
                                        //   in Loop: Header=BB0_18 Depth=2
	@%p26 bra 	LBB0_37;
// %bb.36:                              // %L27027
                                        //   in Loop: Header=BB0_18 Depth=2
	mul.lo.s32 	%r3114, %r3172, 193536;
	add.s32 	%r3115, %r73, %r3114;
	add.s32 	%r3116, %r3115, %r72;
	add.s32 	%r3117, %r3116, %r44;
	mul.wide.u32 	%rd294, %r3117, 4;
	add.s64 	%rd295, %rd4, %rd294;
	st.global.u32 	[%rd295], %r3176;
	add.s32 	%r3118, %r3115, %r74;
	add.s32 	%r3119, %r3118, %r44;
	mul.wide.u32 	%rd296, %r3119, 4;
	add.s64 	%rd297, %rd4, %rd296;
	st.global.u32 	[%rd297], %r3175;
	cvt.u64.u32 	%rd298, %r44;
	cvt.u64.u32 	%rd299, %r72;
	cvt.u64.u32 	%rd300, %r73;
	cvt.u64.u32 	%rd301, %r3114;
	add.s64 	%rd302, %rd301, %rd300;
	add.s64 	%rd303, %rd302, %rd299;
	add.s64 	%rd304, %rd303, %rd298;
	shl.b64 	%rd305, %rd304, 2;
	add.s64 	%rd306, %rd4, %rd305;
	st.global.u32 	[%rd306+387072], %r3174;
	cvt.u64.u32 	%rd307, %r74;
	add.s64 	%rd308, %rd302, %rd307;
	add.s64 	%rd309, %rd308, %rd298;
	shl.b64 	%rd310, %rd309, 2;
	add.s64 	%rd311, %rd4, %rd310;
	st.global.u32 	[%rd311+387072], %r3173;
	bra.uni 	LBB0_37;
LBB0_40:                                // %guard_pass10761
	@%p26 bra 	LBB0_42;
// %bb.41:                              // %L27658
	mul.lo.s32 	%r3121, %r3172, 193536;
	add.s32 	%r3122, %r73, %r3121;
	add.s32 	%r3123, %r3122, %r72;
	add.s32 	%r3124, %r3123, %r44;
	mul.wide.u32 	%rd312, %r3124, 4;
	add.s64 	%rd313, %rd4, %rd312;
	st.global.u32 	[%rd313], %r3176;
	add.s32 	%r3125, %r3122, %r74;
	add.s32 	%r3126, %r3125, %r44;
	mul.wide.u32 	%rd314, %r3126, 4;
	add.s64 	%rd315, %rd4, %rd314;
	st.global.u32 	[%rd315], %r3175;
	cvt.u64.u32 	%rd316, %r44;
	cvt.u64.u32 	%rd317, %r72;
	cvt.u64.u32 	%rd318, %r73;
	cvt.u64.u32 	%rd319, %r3121;
	add.s64 	%rd320, %rd319, %rd318;
	add.s64 	%rd321, %rd320, %rd317;
	add.s64 	%rd322, %rd321, %rd316;
	shl.b64 	%rd323, %rd322, 2;
	add.s64 	%rd324, %rd4, %rd323;
	st.global.u32 	[%rd324+387072], %r3174;
	cvt.u64.u32 	%rd325, %r74;
	add.s64 	%rd326, %rd320, %rd325;
	add.s64 	%rd327, %rd326, %rd316;
	shl.b64 	%rd328, %rd327, 2;
	add.s64 	%rd329, %rd4, %rd328;
	st.global.u32 	[%rd329+387072], %r3173;
LBB0_42:                                // %L28171
	mov.u32 	%r3127, 0;
	st.global.u32 	[%rd5], %r3127;
	ret;
LBB0_1:                                 // %L9
	ld.param.u64 	%rd11, [_Z15julia_frb_1221013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_0];
	mov.u64 	%rd16, exception12155;
	cvta.global.u64 	%rd17, %rd16;
	{ // callseq 4, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd17;
	call.uni 
	gpu_report_exception, 
	(
	param0
	);
	} // callseq 4
	{ // callseq 5, 0
	.reg .b32 temp_param_reg;
	.param .align 8 .b8 param0[8];
	st.param.b64 	[param0+0], %rd11;
	call.uni 
	gpu_signal_exception, 
	(
	param0
	);
	} // callseq 5
	// begin inline asm
	exit;
	// end inline asm
                                        // -- End function
}
