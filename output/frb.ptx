// PTX CompilerJob of kernel #frb(CuDeviceVector{Int4x8, 1}, CuDeviceVector{Int32, 1}, CuDeviceVector{Float16x2, 1}, CuDeviceVector{Float16x2, 1}, CuDeviceVector{Int32, 1}) for sm_86, minthreads=768, blocks_per_sm=1, always_inline=false

//
// Generated by LLVM NVPTX Back-End
//

.version 7.1
.target sm_86
.address_size 64

	// .globl	_Z14julia_frb_547913CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE // -- Begin function _Z14julia_frb_547913CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE
.extern .func gpu_report_exception
(
	.param .b64 gpu_report_exception_param_0
)
;
.extern .func gpu_signal_exception
(
	.param .align 8 .b8 gpu_signal_exception_param_0[8]
)
;
.extern .shared .align 32 .b8 shmem[];
.global .align 1 .b8 exception1[10] = {101, 120, 99, 101, 112, 116, 105, 111, 110, 0};
                                        // @_Z14julia_frb_547913CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE
.visible .entry _Z14julia_frb_547913CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE(
	.param .align 8 .b8 _Z14julia_frb_547913CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_0[8],
	.param .align 8 .b8 _Z14julia_frb_547913CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_1[32],
	.param .align 8 .b8 _Z14julia_frb_547913CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_2[32],
	.param .align 8 .b8 _Z14julia_frb_547913CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_3[32],
	.param .align 8 .b8 _Z14julia_frb_547913CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_4[32],
	.param .align 8 .b8 _Z14julia_frb_547913CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_5[32]
)
.reqntid 768, 1, 1
.minnctapersm 1
{
	.reg .pred 	%p<57>;
	.reg .b16 	%rs<434>;
	.reg .f32 	%f<172>;
	.reg .b32 	%r<2520>;
	.reg .b64 	%rd<174>;

// %bb.0:                               // %conversion
	// begin inline asm
	mov.u32 %r199, %dynamic_smem_size;
	// end inline asm
	setp.gt.u32 	%p1, %r199, 76895;
	@%p1 bra 	LBB0_2;
	bra.uni 	LBB0_1;
LBB0_2:                                 // %L11
	ld.param.u64 	%rd13, [_Z14julia_frb_547913CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_5];
	ld.param.u64 	%rd9, [_Z14julia_frb_547913CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_2];
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %tid.y;
	shl.b32 	%r3, %r2, 5;
	or.b32  	%r224, %r3, %r1;
	mov.u32 	%r4, %ctaid.x;
	mad.lo.s32 	%r225, %r4, 768, %r224;
	mul.wide.u32 	%rd19, %r225, 4;
	add.s64 	%rd4, %rd13, %rd19;
	mov.u32 	%r226, 1;
	st.global.u32 	[%rd4], %r226;
	and.b32  	%r5, %r1, 3;
	shr.u32 	%r6, %r1, 2;
	mul.lo.s32 	%r227, %r6, %r5;
	cvt.rn.f32.s32 	%f1, %r227;
	mul.f32 	%f2, %f1, 0f3E800000;
	add.f32 	%f3, %f2, %f2;
	mov.b32 	%r228, %f3;
	and.b32  	%r229, %r228, -2147483648;
	or.b32  	%r230, %r229, 1056964608;
	mov.b32 	%f4, %r230;
	add.f32 	%f5, %f3, %f4;
	cvt.rzi.f32.f32 	%f6, %f5;
	abs.f32 	%f7, %f3;
	setp.gt.f32 	%p2, %f7, 0f4B000000;
	selp.f32 	%f8, %f3, %f6, %p2;
	cvt.rzi.f32.f32 	%f9, %f3;
	setp.lt.f32 	%p3, %f7, 0f3F000000;
	selp.f32 	%f10, %f9, %f8, %p3;
	cvt.rzi.s32.f32 	%r231, %f10;
	fma.rn.f32 	%f11, %f10, 0fBF000000, %f2;
	mul.f32 	%f12, %f11, 0f34222169;
	fma.rn.f32 	%f13, %f11, 0f40490FDA, %f12;
	mul.f32 	%f14, %f13, %f13;
	fma.rn.f32 	%f15, %f14, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f16, %f15, %f14, 0f3D2AAABB;
	fma.rn.f32 	%f17, %f16, %f14, 0fBEFFFFFF;
	fma.rn.f32 	%f18, %f17, %f14, 0f3F800000;
	fma.rn.f32 	%f19, %f14, %f13, 0f00000000;
	fma.rn.f32 	%f20, %f14, 0fB94D4153, 0f3C0885E4;
	fma.rn.f32 	%f21, %f20, %f14, 0fBE2AAAA8;
	fma.rn.f32 	%f22, %f21, %f19, %f13;
	and.b32  	%r232, %r231, 1;
	setp.eq.b32 	%p4, %r232, 1;
	selp.f32 	%f23, %f18, %f22, %p4;
	selp.f32 	%f24, %f22, %f18, %p4;
	and.b32  	%r233, %r231, 2;
	setp.eq.s32 	%p5, %r233, 0;
	neg.f32 	%f25, %f23;
	selp.f32 	%f26, %f23, %f25, %p5;
	add.s32 	%r234, %r231, 1;
	and.b32  	%r235, %r234, 2;
	setp.eq.s32 	%p6, %r235, 0;
	mov.f32 	%f27, 0f00000000;
	sub.f32 	%f28, %f27, %f24;
	selp.f32 	%f29, %f24, %f28, %p6;
	cvt.rzi.f32.f32 	%f30, %f2;
	setp.eq.f32 	%p7, %f30, %f2;
	mul.f32 	%f31, %f2, 0f00000000;
	selp.f32 	%f32, %f31, %f26, %p7;
	abs.f32 	%f33, %f2;
	setp.gt.f32 	%p8, %f33, 0f4B800000;
	add.f32 	%f34, %f32, 0f3F800000;
	selp.f32 	%f35, %f34, %f29, %p8;
	mov.b32 	%r202, %f35;
	mov.b32 	%r205, %f32;
	xor.b32  	%r201, %r205, -2147483648;
	shl.b32 	%r9, %r1, 1;
	and.b32  	%r236, %r9, 6;
	mul.lo.s32 	%r237, %r6, %r236;
	cvt.rn.f32.s32 	%f36, %r237;
	div.rn.f32 	%f37, %f36, 0f41C00000;
	add.f32 	%f38, %f37, %f37;
	mov.b32 	%r238, %f38;
	and.b32  	%r239, %r238, -2147483648;
	or.b32  	%r240, %r239, 1056964608;
	mov.b32 	%f39, %r240;
	add.f32 	%f40, %f38, %f39;
	cvt.rzi.f32.f32 	%f41, %f40;
	abs.f32 	%f42, %f38;
	setp.gt.f32 	%p9, %f42, 0f4B000000;
	selp.f32 	%f43, %f38, %f41, %p9;
	cvt.rzi.f32.f32 	%f44, %f38;
	setp.lt.f32 	%p10, %f42, 0f3F000000;
	selp.f32 	%f45, %f44, %f43, %p10;
	cvt.rzi.s32.f32 	%r241, %f45;
	fma.rn.f32 	%f46, %f45, 0fBF000000, %f37;
	mul.f32 	%f47, %f46, 0f34222169;
	fma.rn.f32 	%f48, %f46, 0f40490FDA, %f47;
	mul.f32 	%f49, %f48, %f48;
	fma.rn.f32 	%f50, %f49, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f51, %f50, %f49, 0f3D2AAABB;
	fma.rn.f32 	%f52, %f51, %f49, 0fBEFFFFFF;
	fma.rn.f32 	%f53, %f52, %f49, 0f3F800000;
	fma.rn.f32 	%f54, %f49, %f48, 0f00000000;
	fma.rn.f32 	%f55, %f49, 0fB94D4153, 0f3C0885E4;
	fma.rn.f32 	%f56, %f55, %f49, 0fBE2AAAA8;
	fma.rn.f32 	%f57, %f56, %f54, %f48;
	and.b32  	%r242, %r241, 1;
	setp.eq.b32 	%p11, %r242, 1;
	selp.f32 	%f58, %f53, %f57, %p11;
	selp.f32 	%f59, %f57, %f53, %p11;
	and.b32  	%r243, %r241, 2;
	setp.eq.s32 	%p12, %r243, 0;
	neg.f32 	%f60, %f58;
	selp.f32 	%f61, %f58, %f60, %p12;
	add.s32 	%r244, %r241, 1;
	and.b32  	%r245, %r244, 2;
	setp.eq.s32 	%p13, %r245, 0;
	sub.f32 	%f62, %f27, %f59;
	selp.f32 	%f63, %f59, %f62, %p13;
	cvt.rzi.f32.f32 	%f64, %f37;
	setp.eq.f32 	%p14, %f64, %f37;
	mul.f32 	%f65, %f37, 0f00000000;
	selp.f32 	%f66, %f65, %f61, %p14;
	abs.f32 	%f67, %f37;
	setp.gt.f32 	%p15, %f67, 0f4B800000;
	add.f32 	%f68, %f66, 0f3F800000;
	selp.f32 	%f69, %f68, %f63, %p15;
	add.s32 	%r246, %r237, %r6;
	cvt.rn.f32.s32 	%f70, %r246;
	div.rn.f32 	%f71, %f70, 0f41C00000;
	add.f32 	%f72, %f71, %f71;
	mov.b32 	%r247, %f72;
	and.b32  	%r248, %r247, -2147483648;
	or.b32  	%r249, %r248, 1056964608;
	mov.b32 	%f73, %r249;
	add.f32 	%f74, %f72, %f73;
	cvt.rzi.f32.f32 	%f75, %f74;
	abs.f32 	%f76, %f72;
	setp.gt.f32 	%p16, %f76, 0f4B000000;
	selp.f32 	%f77, %f72, %f75, %p16;
	cvt.rzi.f32.f32 	%f78, %f72;
	setp.lt.f32 	%p17, %f76, 0f3F000000;
	selp.f32 	%f79, %f78, %f77, %p17;
	cvt.rzi.s32.f32 	%r250, %f79;
	fma.rn.f32 	%f80, %f79, 0fBF000000, %f71;
	mul.f32 	%f81, %f80, 0f34222169;
	fma.rn.f32 	%f82, %f80, 0f40490FDA, %f81;
	mul.f32 	%f83, %f82, %f82;
	fma.rn.f32 	%f84, %f83, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f85, %f84, %f83, 0f3D2AAABB;
	fma.rn.f32 	%f86, %f85, %f83, 0fBEFFFFFF;
	fma.rn.f32 	%f87, %f86, %f83, 0f3F800000;
	fma.rn.f32 	%f88, %f83, %f82, 0f00000000;
	fma.rn.f32 	%f89, %f83, 0fB94D4153, 0f3C0885E4;
	fma.rn.f32 	%f90, %f89, %f83, 0fBE2AAAA8;
	fma.rn.f32 	%f91, %f90, %f88, %f82;
	and.b32  	%r251, %r250, 1;
	setp.eq.b32 	%p18, %r251, 1;
	selp.f32 	%f92, %f87, %f91, %p18;
	selp.f32 	%f93, %f91, %f87, %p18;
	and.b32  	%r252, %r250, 2;
	setp.eq.s32 	%p19, %r252, 0;
	neg.f32 	%f94, %f92;
	selp.f32 	%f95, %f92, %f94, %p19;
	add.s32 	%r253, %r250, 1;
	and.b32  	%r254, %r253, 2;
	setp.eq.s32 	%p20, %r254, 0;
	sub.f32 	%f96, %f27, %f93;
	selp.f32 	%f97, %f93, %f96, %p20;
	cvt.rzi.f32.f32 	%f98, %f71;
	setp.eq.f32 	%p21, %f98, %f71;
	mul.f32 	%f99, %f71, 0f00000000;
	selp.f32 	%f100, %f99, %f95, %p21;
	abs.f32 	%f101, %f71;
	setp.gt.f32 	%p22, %f101, 0f4B800000;
	add.f32 	%f102, %f100, 0f3F800000;
	selp.f32 	%f103, %f102, %f97, %p22;
	mov.b32 	%r207, %f69;
	mov.b32 	%r208, %f103;
	mov.b32 	%r210, %f66;
	mov.b32 	%r211, %f100;
	shl.b32 	%r255, %r1, 4;
	and.b32  	%r256, %r255, 48;
	mul.lo.s32 	%r257, %r6, %r256;
	cvt.rn.f32.s32 	%f104, %r257;
	div.rn.f32 	%f105, %f104, 0f41C00000;
	add.f32 	%f106, %f105, %f105;
	mov.b32 	%r258, %f106;
	and.b32  	%r259, %r258, -2147483648;
	or.b32  	%r260, %r259, 1056964608;
	mov.b32 	%f107, %r260;
	add.f32 	%f108, %f106, %f107;
	cvt.rzi.f32.f32 	%f109, %f108;
	abs.f32 	%f110, %f106;
	setp.gt.f32 	%p23, %f110, 0f4B000000;
	selp.f32 	%f111, %f106, %f109, %p23;
	cvt.rzi.f32.f32 	%f112, %f106;
	setp.lt.f32 	%p24, %f110, 0f3F000000;
	selp.f32 	%f113, %f112, %f111, %p24;
	cvt.rzi.s32.f32 	%r261, %f113;
	fma.rn.f32 	%f114, %f113, 0fBF000000, %f105;
	mul.f32 	%f115, %f114, 0f34222169;
	fma.rn.f32 	%f116, %f114, 0f40490FDA, %f115;
	mul.f32 	%f117, %f116, %f116;
	fma.rn.f32 	%f118, %f117, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f119, %f118, %f117, 0f3D2AAABB;
	fma.rn.f32 	%f120, %f119, %f117, 0fBEFFFFFF;
	fma.rn.f32 	%f121, %f120, %f117, 0f3F800000;
	fma.rn.f32 	%f122, %f117, %f116, 0f00000000;
	fma.rn.f32 	%f123, %f117, 0fB94D4153, 0f3C0885E4;
	fma.rn.f32 	%f124, %f123, %f117, 0fBE2AAAA8;
	fma.rn.f32 	%f125, %f124, %f122, %f116;
	and.b32  	%r262, %r261, 1;
	setp.eq.b32 	%p25, %r262, 1;
	selp.f32 	%f126, %f121, %f125, %p25;
	selp.f32 	%f127, %f125, %f121, %p25;
	and.b32  	%r263, %r261, 2;
	setp.eq.s32 	%p26, %r263, 0;
	neg.f32 	%f128, %f126;
	selp.f32 	%f129, %f126, %f128, %p26;
	add.s32 	%r264, %r261, 1;
	and.b32  	%r265, %r264, 2;
	setp.eq.s32 	%p27, %r265, 0;
	sub.f32 	%f130, %f27, %f127;
	selp.f32 	%f131, %f127, %f130, %p27;
	cvt.rzi.f32.f32 	%f132, %f105;
	setp.eq.f32 	%p28, %f132, %f105;
	mul.f32 	%f133, %f105, 0f00000000;
	selp.f32 	%f134, %f133, %f129, %p28;
	abs.f32 	%f135, %f105;
	setp.gt.f32 	%p29, %f135, 0f4B800000;
	add.f32 	%f136, %f134, 0f3F800000;
	selp.f32 	%f137, %f136, %f131, %p29;
	shl.b32 	%r266, %r6, 3;
	add.s32 	%r267, %r257, %r266;
	cvt.rn.f32.s32 	%f138, %r267;
	div.rn.f32 	%f139, %f138, 0f41C00000;
	add.f32 	%f140, %f139, %f139;
	mov.b32 	%r268, %f140;
	and.b32  	%r269, %r268, -2147483648;
	or.b32  	%r270, %r269, 1056964608;
	mov.b32 	%f141, %r270;
	add.f32 	%f142, %f140, %f141;
	cvt.rzi.f32.f32 	%f143, %f142;
	abs.f32 	%f144, %f140;
	setp.gt.f32 	%p30, %f144, 0f4B000000;
	selp.f32 	%f145, %f140, %f143, %p30;
	cvt.rzi.f32.f32 	%f146, %f140;
	setp.lt.f32 	%p31, %f144, 0f3F000000;
	selp.f32 	%f147, %f146, %f145, %p31;
	cvt.rzi.s32.f32 	%r271, %f147;
	fma.rn.f32 	%f148, %f147, 0fBF000000, %f139;
	mul.f32 	%f149, %f148, 0f34222169;
	fma.rn.f32 	%f150, %f148, 0f40490FDA, %f149;
	mul.f32 	%f151, %f150, %f150;
	fma.rn.f32 	%f152, %f151, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f153, %f152, %f151, 0f3D2AAABB;
	fma.rn.f32 	%f154, %f153, %f151, 0fBEFFFFFF;
	fma.rn.f32 	%f155, %f154, %f151, 0f3F800000;
	fma.rn.f32 	%f156, %f151, %f150, 0f00000000;
	fma.rn.f32 	%f157, %f151, 0fB94D4153, 0f3C0885E4;
	fma.rn.f32 	%f158, %f157, %f151, 0fBE2AAAA8;
	fma.rn.f32 	%f159, %f158, %f156, %f150;
	and.b32  	%r272, %r271, 1;
	setp.eq.b32 	%p32, %r272, 1;
	selp.f32 	%f160, %f155, %f159, %p32;
	selp.f32 	%f161, %f159, %f155, %p32;
	and.b32  	%r273, %r271, 2;
	setp.eq.s32 	%p33, %r273, 0;
	neg.f32 	%f162, %f160;
	selp.f32 	%f163, %f160, %f162, %p33;
	add.s32 	%r274, %r271, 1;
	and.b32  	%r275, %r274, 2;
	setp.eq.s32 	%p34, %r275, 0;
	sub.f32 	%f164, %f27, %f161;
	selp.f32 	%f165, %f161, %f164, %p34;
	cvt.rzi.f32.f32 	%f166, %f139;
	setp.eq.f32 	%p35, %f166, %f139;
	mul.f32 	%f167, %f139, 0f00000000;
	selp.f32 	%f168, %f167, %f163, %p35;
	abs.f32 	%f169, %f139;
	setp.gt.f32 	%p36, %f169, 0f4B800000;
	add.f32 	%f170, %f168, 0f3F800000;
	selp.f32 	%f171, %f170, %f165, %p36;
	mov.b32 	%r213, %f137;
	mov.b32 	%r214, %f171;
	mov.b32 	%r219, %f134;
	xor.b32  	%r216, %r219, -2147483648;
	mov.b32 	%r220, %f168;
	xor.b32  	%r217, %r220, -2147483648;
	cvt.u16.u32 	%rs1, %r1;
	and.b16  	%rs2, %rs1, 255;
	mul.lo.s16 	%rs3, %rs2, 171;
	shr.u16 	%rs4, %rs3, 12;
	mul.lo.s16 	%rs5, %rs4, 24;
	sub.s16 	%rs6, %rs1, %rs5;
	cvt.u32.u16 	%r276, %rs6;
	and.b32  	%r16, %r276, 255;
	mad.lo.s32 	%r277, %r16, 24, %r2;
	and.b32  	%r278, %r277, 511;
	mul.wide.u32 	%rd20, %r278, 4;
	add.s64 	%rd21, %rd9, %rd20;
	setp.lt.u32 	%p37, %r1, 24;
	@%p37 bra 	LBB0_4;
// %bb.3:                               // %L11.L833_crit_edge
	cvt.u16.u32 	%rs19, %r2;
	and.b16  	%rs20, %rs19, 255;
	mul.lo.s16 	%rs21, %rs20, 171;
	shr.u16 	%rs22, %rs21, 10;
	mul.lo.s16 	%rs23, %rs22, -6;
	add.s16 	%rs24, %rs23, %rs19;
	cvt.u32.u16 	%r294, %rs24;
	and.b32  	%r2462, %r294, 255;
	cvt.u16.u32 	%rs25, %r6;
	mul.lo.s16 	%rs26, %rs25, 171;
	shr.u16 	%rs27, %rs26, 10;
	mul.lo.s16 	%rs28, %rs27, 6;
	sub.s16 	%rs29, %rs25, %rs28;
	cvt.u32.u16 	%r295, %rs29;
	and.b32  	%r2461, %r295, 255;
	cvt.u32.u16 	%r2460, %rs22;
	mul.wide.u16 	%r2459, %rs22, 6;
	mov.u32 	%r2463, 0;
	mov.u32 	%r2464, %r2463;
	bra.uni 	LBB0_5;
LBB0_4:                                 // %L513
	ld.param.u64 	%rd2, [_Z14julia_frb_547913CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_3];
	mul.lo.s32 	%r279, %r5, 144;
	mad.lo.s32 	%r280, %r4, 576, %r279;
	cvt.u16.u32 	%rs7, %r2;
	and.b16  	%rs8, %rs7, 255;
	mul.lo.s16 	%rs9, %rs8, 171;
	shr.u16 	%rs10, %rs9, 10;
	mul.lo.s16 	%rs11, %rs10, -6;
	add.s16 	%rs12, %rs11, %rs7;
	cvt.u32.u16 	%r282, %rs12;
	and.b32  	%r2462, %r282, 255;
	or.b32  	%r283, %r280, %r2462;
	cvt.u32.u16 	%r2460, %rs10;
	mul.wide.u16 	%r2459, %rs10, 6;
	add.s32 	%r284, %r283, %r2459;
	cvt.u16.u32 	%rs13, %r6;
	mul.lo.s16 	%rs14, %rs13, 171;
	shr.u16 	%rs15, %rs14, 10;
	mul.lo.s16 	%rs16, %rs15, 6;
	sub.s16 	%rs17, %rs13, %rs16;
	cvt.u32.u16 	%r285, %rs17;
	and.b32  	%r2461, %r285, 255;
	and.b16  	%rs18, %rs17, 255;
	mul.wide.u16 	%r286, %rs18, 24;
	add.s32 	%r287, %r284, %r286;
	mul.wide.u32 	%rd22, %r287, 4;
	add.s64 	%rd23, %rd2, %rd22;
	ld.global.u32 	%r2463, [%rd23];
	add.s32 	%r288, %r280, 147456;
	or.b32  	%r289, %r288, %r2462;
	add.s32 	%r290, %r289, %r2459;
	add.s32 	%r291, %r290, %r286;
	mul.wide.u32 	%rd24, %r291, 4;
	add.s64 	%rd25, %rd2, %rd24;
	ld.global.u32 	%r2464, [%rd25];
LBB0_5:                                 // %L833
	ld.param.u64 	%rd1, [_Z14julia_frb_547913CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_1];
	ld.param.u64 	%rd3, [_Z14julia_frb_547913CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_4];
	// begin inline asm
	cvt.rn.f16x2.f32 %r200, %r202, %r201;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r203, %r205, %r202;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r206, %r208, %r207;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r209, %r211, %r210;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r212, %r214, %r213;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r215, %r217, %r216;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r218, %r220, %r219;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r221, %r214, %r213;
	// end inline asm
	ld.global.u32 	%r17, [%rd21];
	mov.u32 	%r2458, 0;
	shl.b32 	%r297, %r1, 2;
	shl.b32 	%r298, %r1, 11;
	or.b32  	%r299, %r298, %r297;
	and.b32  	%r300, %r298, 32768;
	and.b32  	%r301, %r299, 32828;
	shl.b32 	%r302, %r4, 7;
	or.b32  	%r34, %r301, %r302;
	or.b32  	%r303, %r300, %r297;
	or.b32  	%r304, %r302, %r303;
	or.b32  	%r35, %r304, 65;
	shr.u32 	%r36, %r1, 4;
	and.b32  	%r305, %r9, 30;
	or.b32  	%r306, %r305, %r36;
	mul.lo.s32 	%r37, %r306, 257;
	or.b32  	%r307, %r36, %r9;
	or.b32  	%r308, %r307, 32;
	mul.lo.s32 	%r38, %r308, 257;
	and.b32  	%r309, %r3, 224;
	shr.u32 	%r310, %r2, 3;
	add.s32 	%r313, %r2, 504;
	bfe.u32 	%r314, %r313, 3, 6;
	mad.lo.s32 	%r40, %r314, 257, %r309;
	mul.lo.s32 	%r41, %r2462, 33;
	mul.lo.s32 	%r42, %r5, 4806;
	mul.lo.s32 	%r43, %r2461, 801;
	mul.lo.s32 	%r44, %r2460, 198;
	bfe.u32 	%r315, %r1, 1, 1;
	mul.lo.s32 	%r316, %r315, 2056;
	mul.lo.s32 	%r317, %r36, 257;
	add.s32 	%r318, %r317, %r316;
	bfe.u32 	%r319, %r1, 3, 1;
	mul.lo.s32 	%r320, %r319, 514;
	add.s32 	%r321, %r318, %r320;
	add.s32 	%r322, %r321, %r2462;
	and.b32  	%r323, %r1, 1;
	mul.lo.s32 	%r324, %r323, 4112;
	add.s32 	%r325, %r322, %r324;
	and.b32  	%r326, %r6, 1;
	mul.lo.s32 	%r327, %r326, 1028;
	add.s32 	%r328, %r325, %r327;
	add.s32 	%r45, %r328, %r2459;
	mul.wide.u32 	%rd26, %r45, 4;
	mov.u64 	%rd27, shmem;
	add.s64 	%rd5, %rd27, %rd26;
	cvt.u64.u32 	%rd28, %r2459;
	cvt.u64.u32 	%rd29, %r327;
	cvt.u64.u32 	%rd30, %r324;
	cvt.u64.u32 	%rd31, %r2462;
	cvt.u64.u32 	%rd32, %r320;
	cvt.u64.u32 	%rd33, %r317;
	cvt.u64.u32 	%rd34, %r316;
	add.s64 	%rd35, %rd34, %rd33;
	add.s64 	%rd36, %rd35, %rd32;
	add.s64 	%rd37, %rd36, %rd31;
	add.s64 	%rd38, %rd37, %rd30;
	add.s64 	%rd39, %rd38, %rd29;
	add.s64 	%rd40, %rd39, %rd28;
	shl.b64 	%rd41, %rd40, 2;
	add.s64 	%rd6, %rd27, %rd41;
	bfe.u32 	%r329, %r2, 3, 1;
	mul.lo.s32 	%r46, %r329, 2056;
	and.b32  	%r330, %r2, 1;
	mul.lo.s32 	%r47, %r330, 257;
	shr.u32 	%r331, %r2, 1;
	bfe.u32 	%r332, %r2, 1, 1;
	mul.lo.s32 	%r48, %r332, 514;
	shr.u32 	%r333, %r2, 4;
	mul.lo.s32 	%r49, %r333, 4112;
	bfe.u32 	%r334, %r2, 2, 1;
	mul.lo.s32 	%r50, %r334, 1028;
	and.b32  	%r335, %r331, 4;
	shl.b32 	%r336, %r2, 3;
	and.b32  	%r337, %r336, 16;
	shl.b32 	%r338, %r2, 1;
	and.b32  	%r339, %r338, 8;
	cvt.u16.u32 	%rs30, %r2;
	shr.u16 	%rs31, %rs30, 8;
	shl.b16 	%rs32, %rs30, 8;
	or.b16  	%rs33, %rs32, %rs31;
	shl.b16 	%rs34, %rs33, 4;
	shl.b16 	%rs35, %rs30, 4;
	and.b16  	%rs36, %rs35, 3840;
	or.b16  	%rs37, %rs36, %rs34;
	and.b16  	%rs38, %rs37, 13107;
	shl.b16 	%rs39, %rs38, 2;
	and.b16  	%rs40, %rs37, -13108;
	shr.u16 	%rs41, %rs40, 2;
	or.b16  	%rs42, %rs41, %rs39;
	and.b16  	%rs43, %rs42, 21504;
	shl.b16 	%rs44, %rs43, 1;
	and.b16  	%rs45, %rs42, -22528;
	shr.u16 	%rs46, %rs45, 1;
	or.b16  	%rs47, %rs46, %rs44;
	shr.u16 	%rs48, %rs47, 10;
	mul.wide.u16 	%r51, %rs48, 32;
	shl.b32 	%r52, %r4, 11;
	or.b32  	%r340, %r3, %r335;
	or.b32  	%r341, %r337, %r340;
	or.b32  	%r342, %r341, %r310;
	and.b32  	%r343, %r342, 54;
	or.b32  	%r344, %r339, %r343;
	shl.b32 	%r53, %r344, 5;
	or.b32  	%r54, %r53, 32;
	cvt.u64.u32 	%rd42, %r44;
	cvt.u64.u32 	%rd43, %r43;
	cvt.u64.u32 	%rd44, %r41;
	cvt.u64.u32 	%rd45, %r42;
	add.s64 	%rd46, %rd45, %rd44;
	add.s64 	%rd47, %rd46, %rd43;
	add.s64 	%rd48, %rd47, %rd42;
	shl.b64 	%rd49, %rd48, 2;
	add.s64 	%rd7, %rd27, %rd49;
	setp.eq.s32 	%p38, %r36, 1;
	mov.u32 	%r2465, %r2458;
	mov.u32 	%r2503, %r2458;
	mov.u32 	%r2504, %r2458;
	mov.u32 	%r2505, %r2458;
	mov.u32 	%r2506, %r2458;
	mov.u32 	%r2507, %r2458;
	mov.u32 	%r2508, %r2458;
	bra.uni 	LBB0_6;
LBB0_14:                                // %L60488
                                        //   in Loop: Header=BB0_6 Depth=1
	add.s32 	%r170, %r2465, 48;
	setp.ne.s32 	%p56, %r2465, 2016;
	mov.u32 	%r2465, %r170;
	@%p56 bra 	LBB0_6;
	bra.uni 	LBB0_15;
LBB0_6:                                 // %L836
                                        // =>This Loop Header: Depth=1
                                        //     Child Loop BB0_8 Depth 2
                                        //       Child Loop BB0_9 Depth 3
	mul.hi.u32 	%r538, %r2465, -1431655765;
	shr.u32 	%r539, %r538, 5;
	mul.lo.s32 	%r62, %r539, 48;
	add.s32 	%r540, %r2, %r62;
	cvt.u16.u32 	%rs49, %r540;
	mul.hi.s16 	%rs50, %rs49, 16257;
	shr.u16 	%rs51, %rs50, 15;
	shr.s16 	%rs52, %rs50, 9;
	add.s16 	%rs53, %rs52, %rs51;
	mul.lo.s16 	%rs54, %rs53, 2064;
	sub.s16 	%rs55, %rs49, %rs54;
	cvt.u32.u16 	%r541, %rs55;
	shl.b32 	%r542, %r541, 16;
	or.b32  	%r543, %r34, %r542;
	mul.wide.s32 	%rd50, %r543, 4;
	add.s64 	%rd51, %rd1, %rd50;
	ld.global.v4.u32 	{%r544, %r545, %r546, %r547}, [%rd51];
	or.b32  	%r548, %r35, %r542;
	add.s32 	%r549, %r548, -1;
	mul.wide.s32 	%rd52, %r549, 4;
	add.s64 	%rd53, %rd1, %rd52;
	ld.global.v4.u32 	{%r550, %r551, %r552, %r553}, [%rd53];
	add.s16 	%rs56, %rs49, 24;
	mul.hi.s16 	%rs57, %rs56, 16257;
	shr.u16 	%rs58, %rs57, 15;
	shr.s16 	%rs59, %rs57, 9;
	add.s16 	%rs60, %rs59, %rs58;
	mul.lo.s16 	%rs61, %rs60, 2064;
	sub.s16 	%rs62, %rs56, %rs61;
	cvt.u32.u16 	%r554, %rs62;
	shl.b32 	%r555, %r554, 16;
	or.b32  	%r556, %r34, %r555;
	mul.wide.s32 	%rd54, %r556, 4;
	add.s64 	%rd55, %rd1, %rd54;
	ld.global.v4.u32 	{%r557, %r558, %r559, %r560}, [%rd55];
	or.b32  	%r561, %r35, %r555;
	add.s32 	%r562, %r561, -1;
	mul.wide.s32 	%rd56, %r562, 4;
	add.s64 	%rd57, %rd1, %rd56;
	ld.global.v4.u32 	{%r563, %r564, %r565, %r566}, [%rd57];
	selp.b32 	%r567, %r544, %r546, %p38;
	shfl.sync.bfly.b32	%r568, %r567, 16, 31, -1;
	selp.b32 	%r347, %r568, %r544, %p38;
	selp.b32 	%r352, %r546, %r568, %p38;
	selp.b32 	%r569, %r545, %r547, %p38;
	shfl.sync.bfly.b32	%r570, %r569, 16, 31, -1;
	selp.b32 	%r355, %r570, %r545, %p38;
	selp.b32 	%r360, %r547, %r570, %p38;
	selp.b32 	%r571, %r550, %r552, %p38;
	shfl.sync.bfly.b32	%r572, %r571, 16, 31, -1;
	selp.b32 	%r363, %r572, %r550, %p38;
	selp.b32 	%r368, %r552, %r572, %p38;
	selp.b32 	%r573, %r551, %r553, %p38;
	shfl.sync.bfly.b32	%r574, %r573, 16, 31, -1;
	selp.b32 	%r371, %r574, %r551, %p38;
	selp.b32 	%r376, %r553, %r574, %p38;
	selp.b32 	%r575, %r557, %r559, %p38;
	shfl.sync.bfly.b32	%r576, %r575, 16, 31, -1;
	selp.b32 	%r379, %r576, %r557, %p38;
	selp.b32 	%r384, %r559, %r576, %p38;
	selp.b32 	%r577, %r558, %r560, %p38;
	shfl.sync.bfly.b32	%r578, %r577, 16, 31, -1;
	selp.b32 	%r387, %r578, %r558, %p38;
	selp.b32 	%r392, %r560, %r578, %p38;
	selp.b32 	%r579, %r563, %r565, %p38;
	shfl.sync.bfly.b32	%r580, %r579, 16, 31, -1;
	selp.b32 	%r395, %r580, %r563, %p38;
	selp.b32 	%r400, %r565, %r580, %p38;
	selp.b32 	%r581, %r564, %r566, %p38;
	shfl.sync.bfly.b32	%r582, %r581, 16, 31, -1;
	selp.b32 	%r403, %r582, %r564, %p38;
	selp.b32 	%r408, %r566, %r582, %p38;
	shl.b32 	%r348, %r352, 4;
	mov.u32 	%r346, 252645135;
	// begin inline asm
	lop3.b32 %r410, %r346, %r347, %r348, 202;
	// end inline asm
	shr.u32 	%r351, %r347, 4;
	// begin inline asm
	lop3.b32 %r426, %r346, %r351, %r352, 202;
	// end inline asm
	shl.b32 	%r356, %r360, 4;
	// begin inline asm
	lop3.b32 %r418, %r346, %r355, %r356, 202;
	// end inline asm
	shr.u32 	%r359, %r355, 4;
	// begin inline asm
	lop3.b32 %r434, %r346, %r359, %r360, 202;
	// end inline asm
	shl.b32 	%r364, %r368, 4;
	// begin inline asm
	lop3.b32 %r442, %r346, %r363, %r364, 202;
	// end inline asm
	shr.u32 	%r367, %r363, 4;
	// begin inline asm
	lop3.b32 %r458, %r346, %r367, %r368, 202;
	// end inline asm
	shl.b32 	%r372, %r376, 4;
	// begin inline asm
	lop3.b32 %r450, %r346, %r371, %r372, 202;
	// end inline asm
	shr.u32 	%r375, %r371, 4;
	// begin inline asm
	lop3.b32 %r466, %r346, %r375, %r376, 202;
	// end inline asm
	shl.b32 	%r380, %r384, 4;
	// begin inline asm
	lop3.b32 %r411, %r346, %r379, %r380, 202;
	// end inline asm
	shr.u32 	%r383, %r379, 4;
	// begin inline asm
	lop3.b32 %r427, %r346, %r383, %r384, 202;
	// end inline asm
	shl.b32 	%r388, %r392, 4;
	// begin inline asm
	lop3.b32 %r419, %r346, %r387, %r388, 202;
	// end inline asm
	shr.u32 	%r391, %r387, 4;
	// begin inline asm
	lop3.b32 %r435, %r346, %r391, %r392, 202;
	// end inline asm
	shl.b32 	%r396, %r400, 4;
	// begin inline asm
	lop3.b32 %r443, %r346, %r395, %r396, 202;
	// end inline asm
	shr.u32 	%r399, %r395, 4;
	// begin inline asm
	lop3.b32 %r459, %r346, %r399, %r400, 202;
	// end inline asm
	shl.b32 	%r404, %r408, 4;
	// begin inline asm
	lop3.b32 %r451, %r346, %r403, %r404, 202;
	// end inline asm
	shr.u32 	%r407, %r403, 4;
	// begin inline asm
	lop3.b32 %r467, %r346, %r407, %r408, 202;
	// end inline asm
	mov.u32 	%r412, 25152;
	// begin inline asm
	prmt.b32 %r474, %r410, %r411, %r412;
	// end inline asm
	mov.u32 	%r416, 29521;
	// begin inline asm
	prmt.b32 %r506, %r410, %r411, %r416;
	// end inline asm
	// begin inline asm
	prmt.b32 %r482, %r418, %r419, %r412;
	// end inline asm
	// begin inline asm
	prmt.b32 %r514, %r418, %r419, %r416;
	// end inline asm
	// begin inline asm
	prmt.b32 %r475, %r426, %r427, %r412;
	// end inline asm
	// begin inline asm
	prmt.b32 %r507, %r426, %r427, %r416;
	// end inline asm
	// begin inline asm
	prmt.b32 %r483, %r434, %r435, %r412;
	// end inline asm
	// begin inline asm
	prmt.b32 %r515, %r434, %r435, %r416;
	// end inline asm
	// begin inline asm
	prmt.b32 %r490, %r442, %r443, %r412;
	// end inline asm
	// begin inline asm
	prmt.b32 %r522, %r442, %r443, %r416;
	// end inline asm
	// begin inline asm
	prmt.b32 %r498, %r450, %r451, %r412;
	// end inline asm
	// begin inline asm
	prmt.b32 %r530, %r450, %r451, %r416;
	// end inline asm
	// begin inline asm
	prmt.b32 %r491, %r458, %r459, %r412;
	// end inline asm
	// begin inline asm
	prmt.b32 %r523, %r458, %r459, %r416;
	// end inline asm
	// begin inline asm
	prmt.b32 %r499, %r466, %r467, %r412;
	// end inline asm
	// begin inline asm
	prmt.b32 %r531, %r466, %r467, %r416;
	// end inline asm
	mov.u32 	%r532, 21520;
	// begin inline asm
	prmt.b32 %r473, %r474, %r475, %r532;
	// end inline asm
	mov.u32 	%r536, 30258;
	// begin inline asm
	prmt.b32 %r477, %r474, %r475, %r536;
	// end inline asm
	// begin inline asm
	prmt.b32 %r481, %r482, %r483, %r532;
	// end inline asm
	// begin inline asm
	prmt.b32 %r485, %r482, %r483, %r536;
	// end inline asm
	// begin inline asm
	prmt.b32 %r489, %r490, %r491, %r532;
	// end inline asm
	// begin inline asm
	prmt.b32 %r493, %r490, %r491, %r536;
	// end inline asm
	// begin inline asm
	prmt.b32 %r497, %r498, %r499, %r532;
	// end inline asm
	// begin inline asm
	prmt.b32 %r501, %r498, %r499, %r536;
	// end inline asm
	// begin inline asm
	prmt.b32 %r505, %r506, %r507, %r532;
	// end inline asm
	// begin inline asm
	prmt.b32 %r509, %r506, %r507, %r536;
	// end inline asm
	// begin inline asm
	prmt.b32 %r513, %r514, %r515, %r532;
	// end inline asm
	// begin inline asm
	prmt.b32 %r517, %r514, %r515, %r536;
	// end inline asm
	// begin inline asm
	prmt.b32 %r521, %r522, %r523, %r532;
	// end inline asm
	// begin inline asm
	prmt.b32 %r525, %r522, %r523, %r536;
	// end inline asm
	// begin inline asm
	prmt.b32 %r529, %r530, %r531, %r532;
	// end inline asm
	// begin inline asm
	prmt.b32 %r533, %r530, %r531, %r536;
	// end inline asm
	mul.hi.s16 	%rs63, %rs49, 10923;
	shr.u16 	%rs64, %rs63, 15;
	shr.s16 	%rs65, %rs63, 2;
	add.s16 	%rs66, %rs65, %rs64;
	mul.lo.s16 	%rs67, %rs66, 24;
	sub.s16 	%rs68, %rs49, %rs67;
	cvt.s32.s16 	%r583, %rs68;
	add.s32 	%r584, %r37, %r583;
	mul.wide.s32 	%rd58, %r584, 4;
	add.s64 	%rd60, %rd27, %rd58;
	st.shared.u32 	[%rd60], %r473;
	st.shared.u32 	[%rd60+512], %r481;
	st.shared.u32 	[%rd60+256], %r477;
	st.shared.u32 	[%rd60+768], %r485;
	add.s32 	%r585, %r38, %r583;
	mul.wide.s32 	%rd61, %r585, 4;
	add.s64 	%rd62, %rd27, %rd61;
	st.shared.u32 	[%rd62], %r489;
	st.shared.u32 	[%rd62+512], %r497;
	st.shared.u32 	[%rd62+256], %r493;
	st.shared.u32 	[%rd62+768], %r501;
	st.shared.u32 	[%rd60+128], %r505;
	st.shared.u32 	[%rd60+640], %r513;
	st.shared.u32 	[%rd60+384], %r509;
	st.shared.u32 	[%rd60+896], %r517;
	st.shared.u32 	[%rd62+128], %r521;
	st.shared.u32 	[%rd62+640], %r529;
	st.shared.u32 	[%rd62+384], %r525;
	st.shared.u32 	[%rd62+896], %r533;
	bar.sync 	0;
	add.s32 	%r586, %r62, %r16;
	cvt.u16.u32 	%rs69, %r586;
	mul.hi.s16 	%rs70, %rs69, 10923;
	shr.u16 	%rs71, %rs70, 15;
	shr.s16 	%rs72, %rs70, 2;
	add.s16 	%rs73, %rs72, %rs71;
	mul.lo.s16 	%rs74, %rs73, 24;
	sub.s16 	%rs75, %rs69, %rs74;
	cvt.s32.s16 	%r587, %rs75;
	add.s32 	%r588, %r40, %r587;
	mul.wide.s32 	%rd63, %r588, 4;
	add.s64 	%rd64, %rd27, %rd63;
	ld.shared.u32 	%r589, [%rd64];
	bar.sync 	0;
	shfl.sync.idx.b32	%r590, %r17, 0, 31, -1;
	shfl.sync.idx.b32	%r591, %r17, 1, 31, -1;
	shfl.sync.idx.b32	%r592, %r17, 2, 31, -1;
	shfl.sync.idx.b32	%r593, %r17, 3, 31, -1;
	shfl.sync.idx.b32	%r594, %r17, 4, 31, -1;
	shfl.sync.idx.b32	%r595, %r17, 5, 31, -1;
	shfl.sync.idx.b32	%r596, %r17, 6, 31, -1;
	shfl.sync.idx.b32	%r597, %r17, 7, 31, -1;
	shfl.sync.idx.b32	%r598, %r17, 8, 31, -1;
	shfl.sync.idx.b32	%r599, %r17, 9, 31, -1;
	shfl.sync.idx.b32	%r600, %r17, 10, 31, -1;
	shfl.sync.idx.b32	%r601, %r17, 11, 31, -1;
	shfl.sync.idx.b32	%r602, %r17, 12, 31, -1;
	shfl.sync.idx.b32	%r603, %r17, 13, 31, -1;
	shfl.sync.idx.b32	%r604, %r17, 14, 31, -1;
	shfl.sync.idx.b32	%r605, %r17, 15, 31, -1;
	shfl.sync.idx.b32	%r606, %r17, 16, 31, -1;
	shfl.sync.idx.b32	%r607, %r17, 17, 31, -1;
	shfl.sync.idx.b32	%r608, %r17, 18, 31, -1;
	shfl.sync.idx.b32	%r609, %r17, 19, 31, -1;
	shfl.sync.idx.b32	%r610, %r17, 20, 31, -1;
	shfl.sync.idx.b32	%r611, %r17, 21, 31, -1;
	shfl.sync.idx.b32	%r612, %r17, 22, 31, -1;
	shfl.sync.idx.b32	%r613, %r17, 23, 31, -1;
	add.s32 	%r614, %r590, %r587;
	mul.wide.s32 	%rd65, %r614, 4;
	add.s64 	%rd66, %rd27, %rd65;
	st.shared.u32 	[%rd66], %r589;
	add.s32 	%r615, %r591, %r587;
	mul.wide.s32 	%rd67, %r615, 4;
	add.s64 	%rd68, %rd27, %rd67;
	st.shared.u32 	[%rd68], %r589;
	add.s32 	%r616, %r592, %r587;
	mul.wide.s32 	%rd69, %r616, 4;
	add.s64 	%rd70, %rd27, %rd69;
	st.shared.u32 	[%rd70], %r589;
	add.s32 	%r617, %r593, %r587;
	mul.wide.s32 	%rd71, %r617, 4;
	add.s64 	%rd72, %rd27, %rd71;
	st.shared.u32 	[%rd72], %r589;
	add.s32 	%r618, %r594, %r587;
	mul.wide.s32 	%rd73, %r618, 4;
	add.s64 	%rd74, %rd27, %rd73;
	st.shared.u32 	[%rd74], %r589;
	add.s32 	%r619, %r595, %r587;
	mul.wide.s32 	%rd75, %r619, 4;
	add.s64 	%rd76, %rd27, %rd75;
	st.shared.u32 	[%rd76], %r589;
	add.s32 	%r620, %r596, %r587;
	mul.wide.s32 	%rd77, %r620, 4;
	add.s64 	%rd78, %rd27, %rd77;
	st.shared.u32 	[%rd78], %r589;
	add.s32 	%r621, %r597, %r587;
	mul.wide.s32 	%rd79, %r621, 4;
	add.s64 	%rd80, %rd27, %rd79;
	st.shared.u32 	[%rd80], %r589;
	add.s32 	%r622, %r598, %r587;
	mul.wide.s32 	%rd81, %r622, 4;
	add.s64 	%rd82, %rd27, %rd81;
	st.shared.u32 	[%rd82], %r589;
	add.s32 	%r623, %r599, %r587;
	mul.wide.s32 	%rd83, %r623, 4;
	add.s64 	%rd84, %rd27, %rd83;
	st.shared.u32 	[%rd84], %r589;
	add.s32 	%r624, %r600, %r587;
	mul.wide.s32 	%rd85, %r624, 4;
	add.s64 	%rd86, %rd27, %rd85;
	st.shared.u32 	[%rd86], %r589;
	add.s32 	%r625, %r601, %r587;
	mul.wide.s32 	%rd87, %r625, 4;
	add.s64 	%rd88, %rd27, %rd87;
	st.shared.u32 	[%rd88], %r589;
	add.s32 	%r626, %r602, %r587;
	mul.wide.s32 	%rd89, %r626, 4;
	add.s64 	%rd90, %rd27, %rd89;
	st.shared.u32 	[%rd90], %r589;
	add.s32 	%r627, %r603, %r587;
	mul.wide.s32 	%rd91, %r627, 4;
	add.s64 	%rd92, %rd27, %rd91;
	st.shared.u32 	[%rd92], %r589;
	add.s32 	%r628, %r604, %r587;
	mul.wide.s32 	%rd93, %r628, 4;
	add.s64 	%rd94, %rd27, %rd93;
	st.shared.u32 	[%rd94], %r589;
	add.s32 	%r629, %r605, %r587;
	mul.wide.s32 	%rd95, %r629, 4;
	add.s64 	%rd96, %rd27, %rd95;
	st.shared.u32 	[%rd96], %r589;
	add.s32 	%r630, %r606, %r587;
	mul.wide.s32 	%rd97, %r630, 4;
	add.s64 	%rd98, %rd27, %rd97;
	st.shared.u32 	[%rd98], %r589;
	add.s32 	%r631, %r607, %r587;
	mul.wide.s32 	%rd99, %r631, 4;
	add.s64 	%rd100, %rd27, %rd99;
	st.shared.u32 	[%rd100], %r589;
	add.s32 	%r632, %r608, %r587;
	mul.wide.s32 	%rd101, %r632, 4;
	add.s64 	%rd102, %rd27, %rd101;
	st.shared.u32 	[%rd102], %r589;
	add.s32 	%r633, %r609, %r587;
	mul.wide.s32 	%rd103, %r633, 4;
	add.s64 	%rd104, %rd27, %rd103;
	st.shared.u32 	[%rd104], %r589;
	add.s32 	%r634, %r610, %r587;
	mul.wide.s32 	%rd105, %r634, 4;
	add.s64 	%rd106, %rd27, %rd105;
	st.shared.u32 	[%rd106], %r589;
	add.s32 	%r635, %r611, %r587;
	mul.wide.s32 	%rd107, %r635, 4;
	add.s64 	%rd108, %rd27, %rd107;
	st.shared.u32 	[%rd108], %r589;
	add.s32 	%r636, %r612, %r587;
	mul.wide.s32 	%rd109, %r636, 4;
	add.s64 	%rd110, %rd27, %rd109;
	st.shared.u32 	[%rd110], %r2458;
	add.s32 	%r637, %r613, %r587;
	mul.wide.s32 	%rd111, %r637, 4;
	add.s64 	%rd112, %rd27, %rd111;
	st.shared.u32 	[%rd112], %r2458;
	bar.sync 	0;
	mov.u32 	%r2472, %r2458;
	mov.u32 	%r2473, %r2458;
	mov.u32 	%r2474, %r2458;
	mov.u32 	%r2475, %r2458;
	mov.u32 	%r2476, %r2458;
	mov.u32 	%r2477, %r2458;
	mov.u32 	%r2478, %r2458;
	mov.u32 	%r2479, %r2458;
	mov.u32 	%r2480, %r2458;
	mov.u32 	%r2481, %r2458;
	mov.u32 	%r2482, %r2458;
	mov.u32 	%r2483, %r2458;
	mov.u32 	%r2484, %r2458;
	mov.u32 	%r2485, %r2458;
	mov.u32 	%r2486, %r2458;
	mov.u32 	%r2487, %r2458;
	mov.u32 	%r2488, %r2458;
	mov.u32 	%r2489, %r2458;
	mov.u32 	%r2490, %r2458;
	mov.u32 	%r2491, %r2458;
	mov.u32 	%r2492, %r2458;
	mov.u32 	%r2493, %r2458;
	mov.u32 	%r2494, %r2458;
	mov.u32 	%r2495, %r2458;
	@%p37 bra 	LBB0_16;
	bra.uni 	LBB0_7;
LBB0_16:                                // %oksrem15862
                                        //   in Loop: Header=BB0_6 Depth=1
	cvt.u16.u32 	%rs76, %r62;
	mul.hi.s16 	%rs77, %rs76, 10923;
	shr.u16 	%rs78, %rs77, 15;
	shr.s16 	%rs79, %rs77, 2;
	add.s16 	%rs80, %rs79, %rs78;
	mul.lo.s16 	%rs81, %rs80, 24;
	sub.s16 	%rs82, %rs76, %rs81;
	cvt.s32.s16 	%r638, %rs82;
	add.s32 	%r639, %r42, %r638;
	add.s32 	%r640, %r639, %r41;
	add.s32 	%r641, %r640, %r43;
	add.s32 	%r642, %r641, %r44;
	mul.wide.s32 	%rd113, %r642, 4;
	add.s64 	%rd115, %rd27, %rd113;
	ld.shared.u32 	%r2472, [%rd115];
	ld.shared.u32 	%r2473, [%rd7+4];
	ld.shared.u32 	%r2474, [%rd7+8];
	ld.shared.u32 	%r2475, [%rd7+12];
	ld.shared.u32 	%r2476, [%rd7+16];
	ld.shared.u32 	%r2477, [%rd7+20];
	ld.shared.u32 	%r2478, [%rd7+24];
	ld.shared.u32 	%r2479, [%rd7+28];
	ld.shared.u32 	%r2480, [%rd7+32];
	ld.shared.u32 	%r2481, [%rd7+36];
	ld.shared.u32 	%r2482, [%rd7+40];
	ld.shared.u32 	%r2483, [%rd7+44];
	ld.shared.u32 	%r2484, [%rd7+48];
	ld.shared.u32 	%r2485, [%rd7+52];
	ld.shared.u32 	%r2486, [%rd7+56];
	ld.shared.u32 	%r2487, [%rd7+60];
	add.s16 	%rs83, %rs76, 16;
	mul.hi.s16 	%rs84, %rs83, 10923;
	shr.u16 	%rs85, %rs84, 15;
	shr.s16 	%rs86, %rs84, 2;
	add.s16 	%rs87, %rs86, %rs85;
	mul.lo.s16 	%rs88, %rs87, 24;
	sub.s16 	%rs89, %rs83, %rs88;
	cvt.s32.s16 	%r643, %rs89;
	add.s32 	%r644, %r42, %r643;
	add.s32 	%r645, %r644, %r41;
	add.s32 	%r646, %r645, %r43;
	add.s32 	%r647, %r646, %r44;
	mul.wide.s32 	%rd116, %r647, 4;
	add.s64 	%rd117, %rd27, %rd116;
	ld.shared.u32 	%r2488, [%rd117];
	add.s16 	%rs90, %rs76, 17;
	mul.hi.s16 	%rs91, %rs90, 10923;
	shr.u16 	%rs92, %rs91, 15;
	shr.s16 	%rs93, %rs91, 2;
	add.s16 	%rs94, %rs93, %rs92;
	mul.lo.s16 	%rs95, %rs94, 24;
	sub.s16 	%rs96, %rs90, %rs95;
	cvt.s32.s16 	%r648, %rs96;
	add.s32 	%r649, %r42, %r648;
	add.s32 	%r650, %r649, %r41;
	add.s32 	%r651, %r650, %r43;
	add.s32 	%r652, %r651, %r44;
	mul.wide.s32 	%rd118, %r652, 4;
	add.s64 	%rd119, %rd27, %rd118;
	ld.shared.u32 	%r2489, [%rd119];
	add.s16 	%rs97, %rs76, 18;
	mul.hi.s16 	%rs98, %rs97, 10923;
	shr.u16 	%rs99, %rs98, 15;
	shr.s16 	%rs100, %rs98, 2;
	add.s16 	%rs101, %rs100, %rs99;
	mul.lo.s16 	%rs102, %rs101, 24;
	sub.s16 	%rs103, %rs97, %rs102;
	cvt.s32.s16 	%r653, %rs103;
	add.s32 	%r654, %r42, %r653;
	add.s32 	%r655, %r654, %r41;
	add.s32 	%r656, %r655, %r43;
	add.s32 	%r657, %r656, %r44;
	mul.wide.s32 	%rd120, %r657, 4;
	add.s64 	%rd121, %rd27, %rd120;
	ld.shared.u32 	%r2490, [%rd121];
	add.s16 	%rs104, %rs76, 19;
	mul.hi.s16 	%rs105, %rs104, 10923;
	shr.u16 	%rs106, %rs105, 15;
	shr.s16 	%rs107, %rs105, 2;
	add.s16 	%rs108, %rs107, %rs106;
	mul.lo.s16 	%rs109, %rs108, 24;
	sub.s16 	%rs110, %rs104, %rs109;
	cvt.s32.s16 	%r658, %rs110;
	add.s32 	%r659, %r42, %r658;
	add.s32 	%r660, %r659, %r41;
	add.s32 	%r661, %r660, %r43;
	add.s32 	%r662, %r661, %r44;
	mul.wide.s32 	%rd122, %r662, 4;
	add.s64 	%rd123, %rd27, %rd122;
	ld.shared.u32 	%r2491, [%rd123];
	add.s16 	%rs111, %rs76, 20;
	mul.hi.s16 	%rs112, %rs111, 10923;
	shr.u16 	%rs113, %rs112, 15;
	shr.s16 	%rs114, %rs112, 2;
	add.s16 	%rs115, %rs114, %rs113;
	mul.lo.s16 	%rs116, %rs115, 24;
	sub.s16 	%rs117, %rs111, %rs116;
	cvt.s32.s16 	%r663, %rs117;
	add.s32 	%r664, %r42, %r663;
	add.s32 	%r665, %r664, %r41;
	add.s32 	%r666, %r665, %r43;
	add.s32 	%r667, %r666, %r44;
	mul.wide.s32 	%rd124, %r667, 4;
	add.s64 	%rd125, %rd27, %rd124;
	ld.shared.u32 	%r2492, [%rd125];
	add.s16 	%rs118, %rs76, 21;
	mul.hi.s16 	%rs119, %rs118, 10923;
	shr.u16 	%rs120, %rs119, 15;
	shr.s16 	%rs121, %rs119, 2;
	add.s16 	%rs122, %rs121, %rs120;
	mul.lo.s16 	%rs123, %rs122, 24;
	sub.s16 	%rs124, %rs118, %rs123;
	cvt.s32.s16 	%r668, %rs124;
	add.s32 	%r669, %r42, %r668;
	add.s32 	%r670, %r669, %r41;
	add.s32 	%r671, %r670, %r43;
	add.s32 	%r672, %r671, %r44;
	mul.wide.s32 	%rd126, %r672, 4;
	add.s64 	%rd127, %rd27, %rd126;
	ld.shared.u32 	%r2493, [%rd127];
	add.s16 	%rs125, %rs76, 22;
	mul.hi.s16 	%rs126, %rs125, 10923;
	shr.u16 	%rs127, %rs126, 15;
	shr.s16 	%rs128, %rs126, 2;
	add.s16 	%rs129, %rs128, %rs127;
	mul.lo.s16 	%rs130, %rs129, 24;
	sub.s16 	%rs131, %rs125, %rs130;
	cvt.s32.s16 	%r673, %rs131;
	add.s32 	%r674, %r42, %r673;
	add.s32 	%r675, %r674, %r41;
	add.s32 	%r676, %r675, %r43;
	add.s32 	%r677, %r676, %r44;
	mul.wide.s32 	%rd128, %r677, 4;
	add.s64 	%rd129, %rd27, %rd128;
	ld.shared.u32 	%r2494, [%rd129];
	add.s16 	%rs132, %rs76, 23;
	mul.hi.s16 	%rs133, %rs132, 10923;
	shr.u16 	%rs134, %rs133, 15;
	shr.s16 	%rs135, %rs133, 2;
	add.s16 	%rs136, %rs135, %rs134;
	mul.lo.s16 	%rs137, %rs136, 24;
	sub.s16 	%rs138, %rs132, %rs137;
	cvt.s32.s16 	%r678, %rs138;
	add.s32 	%r679, %r42, %r678;
	add.s32 	%r680, %r679, %r41;
	add.s32 	%r681, %r680, %r43;
	add.s32 	%r682, %r681, %r44;
	mul.wide.s32 	%rd130, %r682, 4;
	add.s64 	%rd131, %rd27, %rd130;
	ld.shared.u32 	%r2495, [%rd131];
LBB0_7:                                 // %L48625
                                        //   in Loop: Header=BB0_6 Depth=1
	bar.sync 	0;
	xor.b32  	%r87, %r2472, -2004318072;
	shr.u32 	%r88, %r87, 8;
	xor.b32  	%r89, %r2473, -2004318072;
	shr.u32 	%r90, %r89, 8;
	xor.b32  	%r91, %r2474, -2004318072;
	shr.u32 	%r92, %r91, 8;
	xor.b32  	%r93, %r2475, -2004318072;
	shr.u32 	%r94, %r93, 8;
	xor.b32  	%r95, %r2476, -2004318072;
	shr.u32 	%r96, %r95, 8;
	xor.b32  	%r97, %r2477, -2004318072;
	shr.u32 	%r98, %r97, 8;
	xor.b32  	%r99, %r2478, -2004318072;
	shr.u32 	%r100, %r99, 8;
	xor.b32  	%r101, %r2479, -2004318072;
	shr.u32 	%r102, %r101, 8;
	xor.b32  	%r103, %r2480, -2004318072;
	shr.u32 	%r104, %r103, 8;
	xor.b32  	%r105, %r2481, -2004318072;
	shr.u32 	%r106, %r105, 8;
	xor.b32  	%r107, %r2482, -2004318072;
	shr.u32 	%r108, %r107, 8;
	xor.b32  	%r109, %r2483, -2004318072;
	shr.u32 	%r110, %r109, 8;
	xor.b32  	%r111, %r2484, -2004318072;
	shr.u32 	%r112, %r111, 8;
	xor.b32  	%r113, %r2485, -2004318072;
	shr.u32 	%r114, %r113, 8;
	xor.b32  	%r115, %r2486, -2004318072;
	shr.u32 	%r116, %r115, 8;
	xor.b32  	%r117, %r2487, -2004318072;
	shr.u32 	%r118, %r117, 8;
	xor.b32  	%r119, %r2488, -2004318072;
	shr.u32 	%r120, %r119, 8;
	xor.b32  	%r121, %r2489, -2004318072;
	shr.u32 	%r122, %r121, 8;
	xor.b32  	%r123, %r2490, -2004318072;
	shr.u32 	%r124, %r123, 8;
	xor.b32  	%r125, %r2491, -2004318072;
	shr.u32 	%r126, %r125, 8;
	xor.b32  	%r127, %r2492, -2004318072;
	shr.u32 	%r128, %r127, 8;
	xor.b32  	%r129, %r2493, -2004318072;
	shr.u32 	%r130, %r129, 8;
	xor.b32  	%r131, %r2494, -2004318072;
	shr.u32 	%r132, %r131, 8;
	xor.b32  	%r133, %r2495, -2004318072;
	shr.u32 	%r134, %r133, 8;
	add.s32 	%r135, %r62, 1;
	add.s32 	%r136, %r62, 2;
	add.s32 	%r137, %r62, 3;
	mov.u32 	%r2502, %r2458;
	bra.uni 	LBB0_8;
LBB0_13:                                // %L60468
                                        //   in Loop: Header=BB0_8 Depth=2
	setp.ne.s32 	%p55, %r2502, 44;
	bar.sync 	0;
	add.s32 	%r2502, %r2502, 4;
	@%p55 bra 	LBB0_8;
	bra.uni 	LBB0_14;
LBB0_8:                                 // %L48651
                                        //   Parent Loop BB0_6 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB0_9 Depth 3
	mov.u16 	%rs139, 25600;
	// begin inline asm
	mov.b32 %r689, {%rs139, %rs139};
	// end inline asm
	mov.u16 	%rs141, 21504;
	// begin inline asm
	mov.b32 %r700, {%rs141, %rs141};
	// end inline asm
	mov.u32 	%r687, 983055;
	// begin inline asm
	lop3.b32 %r695, %r687, %r87, %r689, 202;
	// end inline asm
	mov.u16 	%rs143, 18432;
	// begin inline asm
	mov.b32 %r693, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r696, %r689, %r693;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r694, %r695, %r696;
	// end inline asm
	mov.u32 	%r698, 15728880;
	// begin inline asm
	lop3.b32 %r706, %r698, %r87, %r700, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r704, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r707, %r700, %r704;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r705, %r706, %r707;
	// end inline asm
	// begin inline asm
	lop3.b32 %r717, %r687, %r88, %r689, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r715, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r718, %r689, %r715;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r716, %r717, %r718;
	// end inline asm
	// begin inline asm
	lop3.b32 %r728, %r698, %r88, %r700, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r726, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r729, %r700, %r726;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r727, %r728, %r729;
	// end inline asm
	// begin inline asm
	mov.b32 %r735, {%rs139, %rs139};
	// end inline asm
	// begin inline asm
	mov.b32 %r746, {%rs141, %rs141};
	// end inline asm
	// begin inline asm
	lop3.b32 %r741, %r687, %r89, %r735, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r739, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r742, %r735, %r739;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r740, %r741, %r742;
	// end inline asm
	// begin inline asm
	lop3.b32 %r752, %r698, %r89, %r746, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r750, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r753, %r746, %r750;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r751, %r752, %r753;
	// end inline asm
	// begin inline asm
	lop3.b32 %r763, %r687, %r90, %r735, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r761, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r764, %r735, %r761;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r762, %r763, %r764;
	// end inline asm
	// begin inline asm
	lop3.b32 %r774, %r698, %r90, %r746, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r772, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r775, %r746, %r772;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r773, %r774, %r775;
	// end inline asm
	// begin inline asm
	mov.b32 %r781, {%rs139, %rs139};
	// end inline asm
	// begin inline asm
	mov.b32 %r792, {%rs141, %rs141};
	// end inline asm
	// begin inline asm
	lop3.b32 %r787, %r687, %r91, %r781, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r785, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r788, %r781, %r785;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r786, %r787, %r788;
	// end inline asm
	// begin inline asm
	lop3.b32 %r798, %r698, %r91, %r792, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r796, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r799, %r792, %r796;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r797, %r798, %r799;
	// end inline asm
	// begin inline asm
	lop3.b32 %r809, %r687, %r92, %r781, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r807, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r810, %r781, %r807;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r808, %r809, %r810;
	// end inline asm
	// begin inline asm
	lop3.b32 %r820, %r698, %r92, %r792, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r818, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r821, %r792, %r818;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r819, %r820, %r821;
	// end inline asm
	// begin inline asm
	mov.b32 %r827, {%rs139, %rs139};
	// end inline asm
	// begin inline asm
	mov.b32 %r838, {%rs141, %rs141};
	// end inline asm
	// begin inline asm
	lop3.b32 %r833, %r687, %r93, %r827, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r831, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r834, %r827, %r831;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r832, %r833, %r834;
	// end inline asm
	// begin inline asm
	lop3.b32 %r844, %r698, %r93, %r838, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r842, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r845, %r838, %r842;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r843, %r844, %r845;
	// end inline asm
	// begin inline asm
	lop3.b32 %r855, %r687, %r94, %r827, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r853, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r856, %r827, %r853;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r854, %r855, %r856;
	// end inline asm
	// begin inline asm
	lop3.b32 %r866, %r698, %r94, %r838, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r864, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r867, %r838, %r864;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r865, %r866, %r867;
	// end inline asm
	// begin inline asm
	mov.b32 %r873, {%rs139, %rs139};
	// end inline asm
	// begin inline asm
	mov.b32 %r884, {%rs141, %rs141};
	// end inline asm
	// begin inline asm
	lop3.b32 %r879, %r687, %r95, %r873, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r877, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r880, %r873, %r877;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r878, %r879, %r880;
	// end inline asm
	// begin inline asm
	lop3.b32 %r890, %r698, %r95, %r884, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r888, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r891, %r884, %r888;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r889, %r890, %r891;
	// end inline asm
	// begin inline asm
	lop3.b32 %r901, %r687, %r96, %r873, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r899, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r902, %r873, %r899;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r900, %r901, %r902;
	// end inline asm
	// begin inline asm
	lop3.b32 %r912, %r698, %r96, %r884, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r910, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r913, %r884, %r910;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r911, %r912, %r913;
	// end inline asm
	// begin inline asm
	mov.b32 %r919, {%rs139, %rs139};
	// end inline asm
	// begin inline asm
	mov.b32 %r930, {%rs141, %rs141};
	// end inline asm
	// begin inline asm
	lop3.b32 %r925, %r687, %r97, %r919, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r923, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r926, %r919, %r923;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r924, %r925, %r926;
	// end inline asm
	// begin inline asm
	lop3.b32 %r936, %r698, %r97, %r930, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r934, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r937, %r930, %r934;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r935, %r936, %r937;
	// end inline asm
	// begin inline asm
	lop3.b32 %r947, %r687, %r98, %r919, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r945, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r948, %r919, %r945;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r946, %r947, %r948;
	// end inline asm
	// begin inline asm
	lop3.b32 %r958, %r698, %r98, %r930, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r956, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r959, %r930, %r956;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r957, %r958, %r959;
	// end inline asm
	// begin inline asm
	mov.b32 %r965, {%rs139, %rs139};
	// end inline asm
	// begin inline asm
	mov.b32 %r976, {%rs141, %rs141};
	// end inline asm
	// begin inline asm
	lop3.b32 %r971, %r687, %r99, %r965, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r969, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r972, %r965, %r969;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r970, %r971, %r972;
	// end inline asm
	// begin inline asm
	lop3.b32 %r982, %r698, %r99, %r976, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r980, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r983, %r976, %r980;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r981, %r982, %r983;
	// end inline asm
	// begin inline asm
	lop3.b32 %r993, %r687, %r100, %r965, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r991, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r994, %r965, %r991;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r992, %r993, %r994;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1004, %r698, %r100, %r976, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1002, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1005, %r976, %r1002;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1003, %r1004, %r1005;
	// end inline asm
	// begin inline asm
	mov.b32 %r1011, {%rs139, %rs139};
	// end inline asm
	// begin inline asm
	mov.b32 %r1022, {%rs141, %rs141};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1017, %r687, %r101, %r1011, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1015, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1018, %r1011, %r1015;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1016, %r1017, %r1018;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1028, %r698, %r101, %r1022, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1026, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1029, %r1022, %r1026;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1027, %r1028, %r1029;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1039, %r687, %r102, %r1011, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1037, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1040, %r1011, %r1037;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1038, %r1039, %r1040;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1050, %r698, %r102, %r1022, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1048, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1051, %r1022, %r1048;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1049, %r1050, %r1051;
	// end inline asm
	// begin inline asm
	mov.b32 %r1057, {%rs139, %rs139};
	// end inline asm
	// begin inline asm
	mov.b32 %r1068, {%rs141, %rs141};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1063, %r687, %r103, %r1057, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1061, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1064, %r1057, %r1061;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1062, %r1063, %r1064;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1074, %r698, %r103, %r1068, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1072, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1075, %r1068, %r1072;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1073, %r1074, %r1075;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1085, %r687, %r104, %r1057, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1083, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1086, %r1057, %r1083;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1084, %r1085, %r1086;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1096, %r698, %r104, %r1068, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1094, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1097, %r1068, %r1094;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1095, %r1096, %r1097;
	// end inline asm
	// begin inline asm
	mov.b32 %r1103, {%rs139, %rs139};
	// end inline asm
	// begin inline asm
	mov.b32 %r1114, {%rs141, %rs141};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1109, %r687, %r105, %r1103, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1107, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1110, %r1103, %r1107;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1108, %r1109, %r1110;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1120, %r698, %r105, %r1114, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1118, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1121, %r1114, %r1118;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1119, %r1120, %r1121;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1131, %r687, %r106, %r1103, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1129, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1132, %r1103, %r1129;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1130, %r1131, %r1132;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1142, %r698, %r106, %r1114, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1140, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1143, %r1114, %r1140;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1141, %r1142, %r1143;
	// end inline asm
	// begin inline asm
	mov.b32 %r1149, {%rs139, %rs139};
	// end inline asm
	// begin inline asm
	mov.b32 %r1160, {%rs141, %rs141};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1155, %r687, %r107, %r1149, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1153, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1156, %r1149, %r1153;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1154, %r1155, %r1156;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1166, %r698, %r107, %r1160, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1164, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1167, %r1160, %r1164;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1165, %r1166, %r1167;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1177, %r687, %r108, %r1149, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1175, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1178, %r1149, %r1175;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1176, %r1177, %r1178;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1188, %r698, %r108, %r1160, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1186, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1189, %r1160, %r1186;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1187, %r1188, %r1189;
	// end inline asm
	// begin inline asm
	mov.b32 %r1195, {%rs139, %rs139};
	// end inline asm
	// begin inline asm
	mov.b32 %r1206, {%rs141, %rs141};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1201, %r687, %r109, %r1195, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1199, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1202, %r1195, %r1199;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1200, %r1201, %r1202;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1212, %r698, %r109, %r1206, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1210, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1213, %r1206, %r1210;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1211, %r1212, %r1213;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1223, %r687, %r110, %r1195, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1221, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1224, %r1195, %r1221;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1222, %r1223, %r1224;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1234, %r698, %r110, %r1206, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1232, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1235, %r1206, %r1232;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1233, %r1234, %r1235;
	// end inline asm
	// begin inline asm
	mov.b32 %r1241, {%rs139, %rs139};
	// end inline asm
	// begin inline asm
	mov.b32 %r1252, {%rs141, %rs141};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1247, %r687, %r111, %r1241, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1245, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1248, %r1241, %r1245;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1246, %r1247, %r1248;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1258, %r698, %r111, %r1252, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1256, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1259, %r1252, %r1256;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1257, %r1258, %r1259;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1269, %r687, %r112, %r1241, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1267, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1270, %r1241, %r1267;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1268, %r1269, %r1270;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1280, %r698, %r112, %r1252, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1278, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1281, %r1252, %r1278;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1279, %r1280, %r1281;
	// end inline asm
	// begin inline asm
	mov.b32 %r1287, {%rs139, %rs139};
	// end inline asm
	// begin inline asm
	mov.b32 %r1298, {%rs141, %rs141};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1293, %r687, %r113, %r1287, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1291, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1294, %r1287, %r1291;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1292, %r1293, %r1294;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1304, %r698, %r113, %r1298, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1302, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1305, %r1298, %r1302;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1303, %r1304, %r1305;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1315, %r687, %r114, %r1287, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1313, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1316, %r1287, %r1313;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1314, %r1315, %r1316;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1326, %r698, %r114, %r1298, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1324, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1327, %r1298, %r1324;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1325, %r1326, %r1327;
	// end inline asm
	// begin inline asm
	mov.b32 %r1333, {%rs139, %rs139};
	// end inline asm
	// begin inline asm
	mov.b32 %r1344, {%rs141, %rs141};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1339, %r687, %r115, %r1333, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1337, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1340, %r1333, %r1337;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1338, %r1339, %r1340;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1350, %r698, %r115, %r1344, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1348, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1351, %r1344, %r1348;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1349, %r1350, %r1351;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1361, %r687, %r116, %r1333, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1359, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1362, %r1333, %r1359;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1360, %r1361, %r1362;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1372, %r698, %r116, %r1344, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1370, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1373, %r1344, %r1370;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1371, %r1372, %r1373;
	// end inline asm
	// begin inline asm
	mov.b32 %r1379, {%rs139, %rs139};
	// end inline asm
	// begin inline asm
	mov.b32 %r1390, {%rs141, %rs141};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1385, %r687, %r117, %r1379, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1383, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1386, %r1379, %r1383;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1384, %r1385, %r1386;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1396, %r698, %r117, %r1390, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1394, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1397, %r1390, %r1394;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1395, %r1396, %r1397;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1407, %r687, %r118, %r1379, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1405, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1408, %r1379, %r1405;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1406, %r1407, %r1408;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1418, %r698, %r118, %r1390, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1416, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1419, %r1390, %r1416;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1417, %r1418, %r1419;
	// end inline asm
	// begin inline asm
	mov.b32 %r1425, {%rs139, %rs139};
	// end inline asm
	// begin inline asm
	mov.b32 %r1436, {%rs141, %rs141};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1431, %r687, %r119, %r1425, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1429, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1432, %r1425, %r1429;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1430, %r1431, %r1432;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1442, %r698, %r119, %r1436, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1440, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1443, %r1436, %r1440;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1441, %r1442, %r1443;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1453, %r687, %r120, %r1425, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1451, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1454, %r1425, %r1451;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1452, %r1453, %r1454;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1464, %r698, %r120, %r1436, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1462, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1465, %r1436, %r1462;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1463, %r1464, %r1465;
	// end inline asm
	// begin inline asm
	mov.b32 %r1471, {%rs139, %rs139};
	// end inline asm
	// begin inline asm
	mov.b32 %r1482, {%rs141, %rs141};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1477, %r687, %r121, %r1471, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1475, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1478, %r1471, %r1475;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1476, %r1477, %r1478;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1488, %r698, %r121, %r1482, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1486, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1489, %r1482, %r1486;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1487, %r1488, %r1489;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1499, %r687, %r122, %r1471, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1497, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1500, %r1471, %r1497;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1498, %r1499, %r1500;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1510, %r698, %r122, %r1482, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1508, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1511, %r1482, %r1508;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1509, %r1510, %r1511;
	// end inline asm
	// begin inline asm
	mov.b32 %r1517, {%rs139, %rs139};
	// end inline asm
	// begin inline asm
	mov.b32 %r1528, {%rs141, %rs141};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1523, %r687, %r123, %r1517, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1521, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1524, %r1517, %r1521;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1522, %r1523, %r1524;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1534, %r698, %r123, %r1528, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1532, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1535, %r1528, %r1532;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1533, %r1534, %r1535;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1545, %r687, %r124, %r1517, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1543, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1546, %r1517, %r1543;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1544, %r1545, %r1546;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1556, %r698, %r124, %r1528, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1554, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1557, %r1528, %r1554;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1555, %r1556, %r1557;
	// end inline asm
	// begin inline asm
	mov.b32 %r1563, {%rs139, %rs139};
	// end inline asm
	// begin inline asm
	mov.b32 %r1574, {%rs141, %rs141};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1569, %r687, %r125, %r1563, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1567, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1570, %r1563, %r1567;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1568, %r1569, %r1570;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1580, %r698, %r125, %r1574, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1578, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1581, %r1574, %r1578;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1579, %r1580, %r1581;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1591, %r687, %r126, %r1563, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1589, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1592, %r1563, %r1589;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1590, %r1591, %r1592;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1602, %r698, %r126, %r1574, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1600, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1603, %r1574, %r1600;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1601, %r1602, %r1603;
	// end inline asm
	// begin inline asm
	mov.b32 %r1609, {%rs139, %rs139};
	// end inline asm
	// begin inline asm
	mov.b32 %r1620, {%rs141, %rs141};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1615, %r687, %r127, %r1609, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1613, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1616, %r1609, %r1613;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1614, %r1615, %r1616;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1626, %r698, %r127, %r1620, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1624, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1627, %r1620, %r1624;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1625, %r1626, %r1627;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1637, %r687, %r128, %r1609, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1635, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1638, %r1609, %r1635;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1636, %r1637, %r1638;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1648, %r698, %r128, %r1620, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1646, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1649, %r1620, %r1646;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1647, %r1648, %r1649;
	// end inline asm
	// begin inline asm
	mov.b32 %r1655, {%rs139, %rs139};
	// end inline asm
	// begin inline asm
	mov.b32 %r1666, {%rs141, %rs141};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1661, %r687, %r129, %r1655, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1659, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1662, %r1655, %r1659;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1660, %r1661, %r1662;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1672, %r698, %r129, %r1666, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1670, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1673, %r1666, %r1670;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1671, %r1672, %r1673;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1683, %r687, %r130, %r1655, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1681, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1684, %r1655, %r1681;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1682, %r1683, %r1684;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1694, %r698, %r130, %r1666, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1692, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1695, %r1666, %r1692;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1693, %r1694, %r1695;
	// end inline asm
	// begin inline asm
	mov.b32 %r1701, {%rs139, %rs139};
	// end inline asm
	// begin inline asm
	mov.b32 %r1712, {%rs141, %rs141};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1707, %r687, %r131, %r1701, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1705, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1708, %r1701, %r1705;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1706, %r1707, %r1708;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1718, %r698, %r131, %r1712, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1716, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1719, %r1712, %r1716;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1717, %r1718, %r1719;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1729, %r687, %r132, %r1701, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1727, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1730, %r1701, %r1727;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1728, %r1729, %r1730;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1740, %r698, %r132, %r1712, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1738, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1741, %r1712, %r1738;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1739, %r1740, %r1741;
	// end inline asm
	// begin inline asm
	mov.b32 %r1747, {%rs139, %rs139};
	// end inline asm
	// begin inline asm
	mov.b32 %r1758, {%rs141, %rs141};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1753, %r687, %r133, %r1747, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1751, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1754, %r1747, %r1751;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1752, %r1753, %r1754;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1764, %r698, %r133, %r1758, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1762, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1765, %r1758, %r1762;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1763, %r1764, %r1765;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1775, %r687, %r134, %r1747, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1773, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1776, %r1747, %r1773;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1774, %r1775, %r1776;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1786, %r698, %r134, %r1758, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1784, {%rs143, %rs143};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1787, %r1758, %r1784;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1785, %r1786, %r1787;
	// end inline asm
	setp.eq.s32 	%p40, %r2502, 0;
	selp.b32 	%r2141, %r694, 0, %p40;
	setp.eq.s32 	%p41, %r2502, 4;
	selp.b32 	%r2142, %r878, %r2141, %p41;
	setp.eq.s32 	%p42, %r2502, 8;
	selp.b32 	%r2143, %r1062, %r2142, %p42;
	setp.eq.s32 	%p43, %r2502, 12;
	selp.b32 	%r2144, %r1246, %r2143, %p43;
	setp.eq.s32 	%p44, %r2502, 16;
	selp.b32 	%r2145, %r1430, %r2144, %p44;
	setp.eq.s32 	%p45, %r2502, 20;
	selp.b32 	%r2146, %r1614, %r2145, %p45;
	setp.eq.s32 	%p46, %r2502, 24;
	selp.b32 	%r2147, %r716, %r2146, %p46;
	setp.eq.s32 	%p47, %r2502, 28;
	selp.b32 	%r2148, %r900, %r2147, %p47;
	setp.eq.s32 	%p48, %r2502, 32;
	selp.b32 	%r2149, %r1084, %r2148, %p48;
	setp.eq.s32 	%p49, %r2502, 36;
	selp.b32 	%r2150, %r1268, %r2149, %p49;
	setp.eq.s32 	%p50, %r2502, 40;
	selp.b32 	%r2151, %r1452, %r2150, %p50;
	setp.eq.s32 	%p51, %r2502, 44;
	selp.b32 	%r1790, %r1636, %r2151, %p51;
	selp.b32 	%r2152, %r705, 0, %p40;
	selp.b32 	%r2153, %r889, %r2152, %p41;
	selp.b32 	%r2154, %r1073, %r2153, %p42;
	selp.b32 	%r2155, %r1257, %r2154, %p43;
	selp.b32 	%r2156, %r1441, %r2155, %p44;
	selp.b32 	%r2157, %r1625, %r2156, %p45;
	selp.b32 	%r2158, %r727, %r2157, %p46;
	selp.b32 	%r2159, %r911, %r2158, %p47;
	selp.b32 	%r2160, %r1095, %r2159, %p48;
	selp.b32 	%r2161, %r1279, %r2160, %p49;
	selp.b32 	%r2162, %r1463, %r2161, %p50;
	selp.b32 	%r1793, %r1647, %r2162, %p51;
	selp.b32 	%r2163, %r740, 0, %p40;
	selp.b32 	%r2164, %r924, %r2163, %p41;
	selp.b32 	%r2165, %r1108, %r2164, %p42;
	selp.b32 	%r2166, %r1292, %r2165, %p43;
	selp.b32 	%r2167, %r1476, %r2166, %p44;
	selp.b32 	%r2168, %r1660, %r2167, %p45;
	selp.b32 	%r2169, %r762, %r2168, %p46;
	selp.b32 	%r2170, %r946, %r2169, %p47;
	selp.b32 	%r2171, %r1130, %r2170, %p48;
	selp.b32 	%r2172, %r1314, %r2171, %p49;
	selp.b32 	%r2173, %r1498, %r2172, %p50;
	selp.b32 	%r1796, %r1682, %r2173, %p51;
	selp.b32 	%r2174, %r751, 0, %p40;
	selp.b32 	%r2175, %r935, %r2174, %p41;
	selp.b32 	%r2176, %r1119, %r2175, %p42;
	selp.b32 	%r2177, %r1303, %r2176, %p43;
	selp.b32 	%r2178, %r1487, %r2177, %p44;
	selp.b32 	%r2179, %r1671, %r2178, %p45;
	selp.b32 	%r2180, %r773, %r2179, %p46;
	selp.b32 	%r2181, %r957, %r2180, %p47;
	selp.b32 	%r2182, %r1141, %r2181, %p48;
	selp.b32 	%r2183, %r1325, %r2182, %p49;
	selp.b32 	%r2184, %r1509, %r2183, %p50;
	selp.b32 	%r1799, %r1693, %r2184, %p51;
	selp.b32 	%r2185, %r786, 0, %p40;
	selp.b32 	%r2186, %r970, %r2185, %p41;
	selp.b32 	%r2187, %r1154, %r2186, %p42;
	selp.b32 	%r2188, %r1338, %r2187, %p43;
	selp.b32 	%r2189, %r1522, %r2188, %p44;
	selp.b32 	%r2190, %r1706, %r2189, %p45;
	selp.b32 	%r2191, %r808, %r2190, %p46;
	selp.b32 	%r2192, %r992, %r2191, %p47;
	selp.b32 	%r2193, %r1176, %r2192, %p48;
	selp.b32 	%r2194, %r1360, %r2193, %p49;
	selp.b32 	%r2195, %r1544, %r2194, %p50;
	selp.b32 	%r1802, %r1728, %r2195, %p51;
	selp.b32 	%r2196, %r797, 0, %p40;
	selp.b32 	%r2197, %r981, %r2196, %p41;
	selp.b32 	%r2198, %r1165, %r2197, %p42;
	selp.b32 	%r2199, %r1349, %r2198, %p43;
	selp.b32 	%r2200, %r1533, %r2199, %p44;
	selp.b32 	%r2201, %r1717, %r2200, %p45;
	selp.b32 	%r2202, %r819, %r2201, %p46;
	selp.b32 	%r2203, %r1003, %r2202, %p47;
	selp.b32 	%r2204, %r1187, %r2203, %p48;
	selp.b32 	%r2205, %r1371, %r2204, %p49;
	selp.b32 	%r2206, %r1555, %r2205, %p50;
	selp.b32 	%r1805, %r1739, %r2206, %p51;
	selp.b32 	%r2207, %r832, 0, %p40;
	selp.b32 	%r2208, %r1016, %r2207, %p41;
	selp.b32 	%r2209, %r1200, %r2208, %p42;
	selp.b32 	%r2210, %r1384, %r2209, %p43;
	selp.b32 	%r2211, %r1568, %r2210, %p44;
	selp.b32 	%r2212, %r1752, %r2211, %p45;
	selp.b32 	%r2213, %r854, %r2212, %p46;
	selp.b32 	%r2214, %r1038, %r2213, %p47;
	selp.b32 	%r2215, %r1222, %r2214, %p48;
	selp.b32 	%r2216, %r1406, %r2215, %p49;
	selp.b32 	%r2217, %r1590, %r2216, %p50;
	selp.b32 	%r1808, %r1774, %r2217, %p51;
	selp.b32 	%r2218, %r843, 0, %p40;
	selp.b32 	%r2219, %r1027, %r2218, %p41;
	selp.b32 	%r2220, %r1211, %r2219, %p42;
	selp.b32 	%r2221, %r1395, %r2220, %p43;
	selp.b32 	%r2222, %r1579, %r2221, %p44;
	selp.b32 	%r2223, %r1763, %r2222, %p45;
	selp.b32 	%r2224, %r865, %r2223, %p46;
	selp.b32 	%r2225, %r1049, %r2224, %p47;
	selp.b32 	%r2226, %r1233, %r2225, %p48;
	selp.b32 	%r2227, %r1417, %r2226, %p49;
	selp.b32 	%r2228, %r1601, %r2227, %p50;
	selp.b32 	%r1811, %r1785, %r2228, %p51;
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r2463;
    mov.b32 {%r2re, %r2im}, %r1790;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1816, {%r0re, %r0im};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r2464;
    mov.b32 {%r2re, %r2im}, %r1793;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1823, {%r0re, %r0im};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r2463;
    mov.b32 {%r2re, %r2im}, %r1796;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1830, {%r0re, %r0im};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r2464;
    mov.b32 {%r2re, %r2im}, %r1799;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1837, {%r0re, %r0im};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r2463;
    mov.b32 {%r2re, %r2im}, %r1802;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1844, {%r0re, %r0im};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r2464;
    mov.b32 {%r2re, %r2im}, %r1805;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1851, {%r0re, %r0im};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r2463;
    mov.b32 {%r2re, %r2im}, %r1808;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1858, {%r0re, %r0im};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1re, %r1im}, %r2464;
    mov.b32 {%r2re, %r2im}, %r1811;
    mul.f16 %retmp, %r1re, %r2re;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    mul.f16 %imtmp, %r1re, %r2im;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1865, {%r0re, %r0im};
}

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1872, %r1875}, {%r203, %r200}, {%r1816}, {%r2458, %r2458};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1881, %r1884}, {%r203, %r200}, {%r1823}, {%r2458, %r2458};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1890, %r1893}, {%r203, %r200}, {%r1830}, {%r2458, %r2458};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1899, %r1902}, {%r203, %r200}, {%r1837}, {%r2458, %r2458};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1908, %r1911}, {%r203, %r200}, {%r1844}, {%r2458, %r2458};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1917, %r1920}, {%r203, %r200}, {%r1851}, {%r2458, %r2458};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1926, %r1929}, {%r203, %r200}, {%r1858}, {%r2458, %r2458};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1935, %r1938}, {%r203, %r200}, {%r1865}, {%r2458, %r2458};
	// end inline asm
	// begin inline asm
	neg.f16x2 %r1871, %r209;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1876, %r1871, %r1872;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2003, %r206, %r1875, %r1876;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r1880, %r209;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1885, %r1880, %r1881;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2013, %r206, %r1884, %r1885;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r1889, %r209;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1894, %r1889, %r1890;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2023, %r206, %r1893, %r1894;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r1898, %r209;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1903, %r1898, %r1899;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2033, %r206, %r1902, %r1903;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r1907, %r209;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1912, %r1907, %r1908;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2043, %r206, %r1911, %r1912;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r1916, %r209;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1921, %r1916, %r1917;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2053, %r206, %r1920, %r1921;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r1925, %r209;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1930, %r1925, %r1926;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2063, %r206, %r1929, %r1930;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r1934, %r209;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1939, %r1934, %r1935;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2073, %r206, %r1938, %r1939;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1946, %r209, %r1875;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2002, %r206, %r1872, %r1946;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1953, %r209, %r1884;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2012, %r206, %r1881, %r1953;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1960, %r209, %r1893;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2022, %r206, %r1890, %r1960;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1967, %r209, %r1902;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2032, %r206, %r1899, %r1967;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1974, %r209, %r1911;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2042, %r206, %r1908, %r1974;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1981, %r209, %r1920;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2052, %r206, %r1917, %r1981;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1988, %r209, %r1929;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2062, %r206, %r1926, %r1988;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1995, %r209, %r1938;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2072, %r206, %r1935, %r1995;
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2077, %r2078}, {%r221, %r215, %r218, %r212}, {%r2002, %r2003}, {%r2458, %r2458};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2085, %r2086}, {%r221, %r215, %r218, %r212}, {%r2012, %r2013}, {%r2458, %r2458};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2093, %r2094}, {%r221, %r215, %r218, %r212}, {%r2022, %r2023}, {%r2458, %r2458};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2101, %r2102}, {%r221, %r215, %r218, %r212}, {%r2032, %r2033}, {%r2458, %r2458};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2109, %r2110}, {%r221, %r215, %r218, %r212}, {%r2042, %r2043}, {%r2458, %r2458};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2117, %r2118}, {%r221, %r215, %r218, %r212}, {%r2052, %r2053}, {%r2458, %r2458};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2125, %r2126}, {%r221, %r215, %r218, %r212}, {%r2062, %r2063}, {%r2458, %r2458};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2133, %r2134}, {%r221, %r215, %r218, %r212}, {%r2072, %r2073}, {%r2458, %r2458};
	// end inline asm
	// begin inline asm
	prmt.b32 %r2076, %r2077, %r2078, %r532;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2080, %r2077, %r2078, %r536;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2084, %r2085, %r2086, %r532;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2088, %r2085, %r2086, %r536;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2092, %r2093, %r2094, %r532;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2096, %r2093, %r2094, %r536;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2100, %r2101, %r2102, %r532;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2104, %r2101, %r2102, %r536;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2108, %r2109, %r2110, %r532;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2112, %r2109, %r2110, %r536;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2116, %r2117, %r2118, %r532;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2120, %r2117, %r2118, %r536;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2124, %r2125, %r2126, %r532;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2128, %r2125, %r2126, %r536;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2132, %r2133, %r2134, %r532;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2136, %r2133, %r2134, %r536;
	// end inline asm
	st.shared.u32 	[%rd5], %r2076;
	st.shared.u32 	[%rd6+33024], %r2080;
	st.shared.u32 	[%rd6+128], %r2084;
	st.shared.u32 	[%rd6+33152], %r2088;
	shr.u32 	%r2229, %r2502, 2;
	cvt.u16.u32 	%rs427, %r2229;
	and.b16  	%rs428, %rs427, 255;
	mul.lo.s16 	%rs429, %rs428, 171;
	shr.u16 	%rs430, %rs429, 11;
	mul.lo.s16 	%rs431, %rs430, 12;
	sub.s16 	%rs432, %rs427, %rs431;
	shl.b16 	%rs433, %rs432, 2;
	cvt.u32.u16 	%r2230, %rs433;
	and.b32  	%r2231, %r2230, 252;
	add.s32 	%r2232, %r135, %r2231;
	shr.s32 	%r2233, %r2232, 31;
	shr.u32 	%r2234, %r2233, 30;
	add.s32 	%r2235, %r2232, %r2234;
	and.b32  	%r2236, %r2235, 67108860;
	sub.s32 	%r2237, %r2232, %r2236;
	shl.b32 	%r2238, %r2237, 6;
	add.s32 	%r2239, %r45, %r2238;
	mul.wide.s32 	%rd132, %r2239, 4;
	add.s64 	%rd134, %rd27, %rd132;
	st.shared.u32 	[%rd134], %r2092;
	add.s32 	%r2240, %r2239, 8256;
	mul.wide.u32 	%rd135, %r2240, 4;
	add.s64 	%rd136, %rd27, %rd135;
	st.shared.u32 	[%rd136], %r2096;
	add.s32 	%r2241, %r2239, 32;
	mul.wide.s32 	%rd137, %r2241, 4;
	add.s64 	%rd138, %rd27, %rd137;
	st.shared.u32 	[%rd138], %r2100;
	add.s32 	%r2242, %r2239, 8288;
	mul.wide.u32 	%rd139, %r2242, 4;
	add.s64 	%rd140, %rd27, %rd139;
	st.shared.u32 	[%rd140], %r2104;
	add.s32 	%r2243, %r136, %r2231;
	shr.s32 	%r2244, %r2243, 31;
	shr.u32 	%r2245, %r2244, 30;
	add.s32 	%r2246, %r2243, %r2245;
	and.b32  	%r2247, %r2246, 67108860;
	sub.s32 	%r2248, %r2243, %r2247;
	shl.b32 	%r2249, %r2248, 6;
	add.s32 	%r2250, %r45, %r2249;
	mul.wide.s32 	%rd141, %r2250, 4;
	add.s64 	%rd142, %rd27, %rd141;
	st.shared.u32 	[%rd142], %r2108;
	add.s32 	%r2251, %r2250, 8256;
	mul.wide.u32 	%rd143, %r2251, 4;
	add.s64 	%rd144, %rd27, %rd143;
	st.shared.u32 	[%rd144], %r2112;
	add.s32 	%r2252, %r2250, 32;
	mul.wide.s32 	%rd145, %r2252, 4;
	add.s64 	%rd146, %rd27, %rd145;
	st.shared.u32 	[%rd146], %r2116;
	add.s32 	%r2253, %r2250, 8288;
	mul.wide.u32 	%rd147, %r2253, 4;
	add.s64 	%rd148, %rd27, %rd147;
	st.shared.u32 	[%rd148], %r2120;
	add.s32 	%r2254, %r137, %r2231;
	shr.s32 	%r2255, %r2254, 31;
	shr.u32 	%r2256, %r2255, 30;
	add.s32 	%r2257, %r2254, %r2256;
	and.b32  	%r2258, %r2257, 67108860;
	sub.s32 	%r2259, %r2254, %r2258;
	shl.b32 	%r2260, %r2259, 6;
	add.s32 	%r2261, %r45, %r2260;
	mul.wide.s32 	%rd149, %r2261, 4;
	add.s64 	%rd150, %rd27, %rd149;
	st.shared.u32 	[%rd150], %r2124;
	add.s32 	%r2262, %r2261, 8256;
	mul.wide.u32 	%rd151, %r2262, 4;
	add.s64 	%rd152, %rd27, %rd151;
	st.shared.u32 	[%rd152], %r2128;
	add.s32 	%r2263, %r2261, 32;
	mul.wide.s32 	%rd153, %r2263, 4;
	add.s64 	%rd154, %rd27, %rd153;
	st.shared.u32 	[%rd154], %r2132;
	add.s32 	%r2264, %r2261, 8288;
	mul.wide.u32 	%rd155, %r2264, 4;
	add.s64 	%rd156, %rd27, %rd155;
	st.shared.u32 	[%rd156], %r2136;
	bar.sync 	0;
	mov.u32 	%r2509, %r2458;
	bra.uni 	LBB0_9;
LBB0_10:                                // %L59336
                                        //   in Loop: Header=BB0_9 Depth=3
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2315, %r2318}, {%r203, %r200}, {%r2513}, {%r2458, %r2458};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2324, %r2327}, {%r203, %r200}, {%r2512}, {%r2458, %r2458};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2333, %r2336}, {%r203, %r200}, {%r2511}, {%r2458, %r2458};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2342, %r2345}, {%r203, %r200}, {%r2510}, {%r2458, %r2458};
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2311, %r209;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2313, %r2311, %r2315;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2316, %r206, %r2318, %r2313;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2320, %r209;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2322, %r2320, %r2324;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2325, %r206, %r2327, %r2322;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2329, %r209;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2331, %r2329, %r2333;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2334, %r206, %r2336, %r2331;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2338, %r209;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2340, %r2338, %r2342;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2343, %r206, %r2345, %r2340;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2347, %r209, %r2318;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2350, %r206, %r2315, %r2347;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2354, %r209, %r2327;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2357, %r206, %r2324, %r2354;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2361, %r209, %r2336;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2364, %r206, %r2333, %r2361;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2368, %r209, %r2345;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2371, %r206, %r2342, %r2368;
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2416, %r2420}, {%r221, %r215, %r218, %r212}, {%r2350, %r2316}, {%r2458, %r2458};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2424, %r2428}, {%r221, %r215, %r218, %r212}, {%r2357, %r2325}, {%r2458, %r2458};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2432, %r2436}, {%r221, %r215, %r218, %r212}, {%r2364, %r2334}, {%r2458, %r2458};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2440, %r2444}, {%r221, %r215, %r218, %r212}, {%r2371, %r2343}, {%r2458, %r2458};
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2415, %r2416, %r2416, %r2508;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2508, %r2420, %r2420, %r2415;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2423, %r2424, %r2424, %r2507;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2507, %r2428, %r2428, %r2423;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2431, %r2432, %r2432, %r2506;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2506, %r2436, %r2436, %r2431;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2439, %r2440, %r2440, %r2505;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2505, %r2444, %r2444, %r2439;
	// end inline asm
	add.s32 	%r2503, %r2503, 1;
	setp.ne.s32 	%p53, %r2503, 40;
	@%p53 bra 	LBB0_12;
	bra.uni 	LBB0_11;
LBB0_12:                                // %L60449
                                        //   in Loop: Header=BB0_9 Depth=3
	add.s32 	%r2509, %r2509, 1;
	setp.ne.s32 	%p54, %r2509, 4;
	@%p54 bra 	LBB0_9;
	bra.uni 	LBB0_13;
LBB0_9:                                 // %L55561
                                        //   Parent Loop BB0_6 Depth=1
                                        //     Parent Loop BB0_8 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	mov.u32 	%r2510, %r2458;
	mov.u32 	%r2511, %r2458;
	mov.u32 	%r2512, %r2458;
	mov.u32 	%r2513, %r2458;
	@%p37 bra 	LBB0_17;
	bra.uni 	LBB0_10;
LBB0_17:                                // %oksrem19783
                                        //   in Loop: Header=BB0_9 Depth=3
	or.b32  	%r2266, %r2509, %r62;
	add.s32 	%r2267, %r2266, %r2502;
	shr.s32 	%r2268, %r2267, 31;
	shr.u32 	%r2269, %r2268, 30;
	add.s32 	%r2270, %r2267, %r2269;
	and.b32  	%r2271, %r2270, 67108860;
	sub.s32 	%r2272, %r2267, %r2271;
	shl.b32 	%r2273, %r2272, 6;
	add.s32 	%r2274, %r46, %r2273;
	add.s32 	%r2275, %r2274, %r47;
	add.s32 	%r2276, %r2275, %r48;
	add.s32 	%r2277, %r2276, %r2461;
	add.s32 	%r2278, %r2277, %r49;
	add.s32 	%r2279, %r2278, %r50;
	mul.wide.s32 	%rd157, %r2279, 4;
	add.s64 	%rd159, %rd27, %rd157;
	ld.shared.u32 	%r2513, [%rd159];
	add.s32 	%r2280, %r2279, 8256;
	mul.wide.u32 	%rd160, %r2280, 4;
	add.s64 	%rd161, %rd27, %rd160;
	ld.shared.u32 	%r2512, [%rd161];
	add.s32 	%r2281, %r2279, 32;
	mul.wide.s32 	%rd162, %r2281, 4;
	add.s64 	%rd163, %rd27, %rd162;
	ld.shared.u32 	%r2511, [%rd163];
	add.s32 	%r2282, %r2279, 8288;
	mul.wide.u32 	%rd164, %r2282, 4;
	add.s64 	%rd165, %rd27, %rd164;
	ld.shared.u32 	%r2510, [%rd165];
	bra.uni 	LBB0_10;
LBB0_11:                                // %L59520
                                        //   in Loop: Header=BB0_9 Depth=3
	shl.b32 	%r2448, %r2504, 20;
	or.b32  	%r2449, %r1, %r2448;
	or.b32  	%r2450, %r51, %r2449;
	or.b32  	%r2451, %r2450, %r52;
	mul.wide.u32 	%rd166, %r2451, 4;
	add.s64 	%rd167, %rd3, %rd166;
	st.global.u32 	[%rd167], %r2508;
	or.b32  	%r2452, %r52, %r2449;
	or.b32  	%r2453, %r2452, %r54;
	mul.wide.u32 	%rd168, %r2453, 4;
	add.s64 	%rd169, %rd3, %rd168;
	st.global.u32 	[%rd169], %r2507;
	or.b32  	%r2454, %r2451, 524288;
	mul.wide.u32 	%rd170, %r2454, 4;
	add.s64 	%rd171, %rd3, %rd170;
	st.global.u32 	[%rd171], %r2506;
	or.b32  	%r2455, %r2452, %r53;
	or.b32  	%r2456, %r2455, 524320;
	mul.wide.u32 	%rd172, %r2456, 4;
	add.s64 	%rd173, %rd3, %rd172;
	st.global.u32 	[%rd173], %r2505;
	add.s32 	%r2504, %r2504, 1;
	mov.u32 	%r2503, 0;
	mov.u32 	%r2505, %r2503;
	mov.u32 	%r2506, %r2503;
	mov.u32 	%r2507, %r2503;
	mov.u32 	%r2508, %r2503;
	bra.uni 	LBB0_12;
LBB0_15:                                // %L60507
	mov.u32 	%r2457, 0;
	st.global.u32 	[%rd4], %r2457;
	ret;
LBB0_1:                                 // %L9
	ld.param.u64 	%rd8, [_Z14julia_frb_547913CuDeviceArrayI6Int4x8Li1ELi1EES_I5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_0];
	mov.u64 	%rd17, exception1;
	cvta.global.u64 	%rd18, %rd17;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd18;
	call.uni 
	gpu_report_exception, 
	(
	param0
	);
	} // callseq 0
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .align 8 .b8 param0[8];
	st.param.b64 	[param0+0], %rd8;
	call.uni 
	gpu_signal_exception, 
	(
	param0
	);
	} // callseq 1
	// begin inline asm
	exit;
	// end inline asm
                                        // -- End function
}
