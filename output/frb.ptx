CHORD FRB beamformer
Compiling kernel...
// PTX CompilerJob of kernel #frb(CuDeviceVector{Int32, 1}, CuDeviceVector{Float16x2, 1}, CuDeviceVector{Int4x8, 1}, CuDeviceVector{Float16x2, 1}, CuDeviceVector{Int32, 1}, CuDeviceVector{Int4x8, 1}, CuDeviceVector{Int4x8, 1}, CuDeviceVector{Float16x2, 1}) for sm_86, minthreads=768, blocks_per_sm=1

//
// Generated by LLVM NVPTX Back-End
//

.version 7.1
.target sm_86
.address_size 64

	// .globl	_Z15julia_frb_1059013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE // -- Begin function _Z15julia_frb_1059013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE
.extern .func julia_unreachable_13471
(
	.param .align 8 .b8 julia_unreachable_13471_param_0[8]
)
;
.extern .func julia__throw_boundserror_13476
(
	.param .align 8 .b8 julia__throw_boundserror_13476_param_0[8]
)
;
.extern .func julia__throw_boundserror_13473
(
	.param .align 8 .b8 julia__throw_boundserror_13473_param_0[8]
)
;
                                        // @_Z15julia_frb_1059013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE
.visible .entry _Z15julia_frb_1059013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE(
	.param .align 8 .b8 _Z15julia_frb_1059013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_0[8],
	.param .align 8 .b8 _Z15julia_frb_1059013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_1[32],
	.param .align 8 .b8 _Z15julia_frb_1059013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_2[32],
	.param .align 8 .b8 _Z15julia_frb_1059013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_3[32],
	.param .align 8 .b8 _Z15julia_frb_1059013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_4[32],
	.param .align 8 .b8 _Z15julia_frb_1059013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_5[32],
	.param .align 8 .b8 _Z15julia_frb_1059013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_6[32],
	.param .align 8 .b8 _Z15julia_frb_1059013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_7[32],
	.param .align 8 .b8 _Z15julia_frb_1059013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_8[32]
)
.reqntid 768, 1, 1
.minnctapersm 1
{
	.reg .pred 	%p<62>;
	.reg .b16 	%rs<365>;
	.reg .f32 	%f<172>;
	.reg .b32 	%r<2426>;
	.reg .b64 	%rd<279>;

// %bb.0:                               // %conversion
	ld.param.u64 	%rd33, [_Z15julia_frb_1059013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_0];
	mov.u32 	%r129, %ctaid.x;
	setp.eq.s32 	%p1, %r129, 0;
	@%p1 bra 	LBB0_2;
	bra.uni 	LBB0_1;
LBB0_2:                                 // %L25
	ld.param.u64 	%rd7, [_Z15julia_frb_1059013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_6+16];
	setp.gt.s64 	%p2, %rd7, 16447;
	@%p2 bra 	LBB0_4;
	bra.uni 	LBB0_3;
LBB0_4:                                 // %L92
	ld.param.u64 	%rd9, [_Z15julia_frb_1059013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_7+16];
	setp.gt.s64 	%p3, %rd9, 19223;
	@%p3 bra 	LBB0_6;
	bra.uni 	LBB0_5;
LBB0_6:                                 // %L159
	ld.param.u64 	%rd11, [_Z15julia_frb_1059013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_8+16];
	setp.gt.s64 	%p4, %rd11, 16511;
	@%p4 bra 	LBB0_8;
	bra.uni 	LBB0_7;
LBB0_8:                                 // %L197
	mov.u32 	%r1, %tid.x;
	setp.lt.u32 	%p5, %r1, 32;
	@%p5 bra 	LBB0_19;
	bra.uni 	LBB0_9;
LBB0_19:                                // %oksrem
	mov.u32 	%r73, %tid.y;
	setp.gt.u32 	%p6, %r73, 23;
	@%p6 bra 	LBB0_10;
// %bb.20:                              // %oksrem16
	ld.param.u64 	%rd1, [_Z15julia_frb_1059013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_1];
	ld.param.u64 	%rd3, [_Z15julia_frb_1059013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_3];
	ld.param.u64 	%rd5, [_Z15julia_frb_1059013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_5];
	ld.param.u64 	%rd6, [_Z15julia_frb_1059013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_6];
	ld.param.u64 	%rd8, [_Z15julia_frb_1059013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_7];
	cvt.u16.u32 	%rs1, %r73;
	and.b16  	%rs4, %rs1, 255;
	mul.lo.s16 	%rs5, %rs4, 171;
	shr.u16 	%rs6, %rs5, 12;
	mul.lo.s16 	%rs7, %rs6, 24;
	sub.s16 	%rs8, %rs1, %rs7;
	cvt.u32.u16 	%r155, %rs8;
	and.b32  	%r74, %r155, 255;
	and.b16  	%rs9, %rs8, 255;
	mul.wide.u16 	%r75, %rs9, 32;
	or.b32  	%r156, %r75, %r1;
	mul.wide.u32 	%rd34, %r156, 4;
	add.s64 	%rd31, %rd5, %rd34;
	mov.u32 	%r157, 1;
	st.global.u32 	[%rd31], %r157;
	and.b32  	%r76, %r1, 3;
	shr.u32 	%r77, %r1, 2;
	mul.lo.s32 	%r158, %r77, %r76;
	cvt.rn.f32.s32 	%f1, %r158;
	mul.f32 	%f2, %f1, 0f3E800000;
	add.f32 	%f3, %f2, %f2;
	mov.b32 	%r159, %f3;
	and.b32  	%r160, %r159, -2147483648;
	or.b32  	%r161, %r160, 1056964608;
	mov.b32 	%f4, %r161;
	add.f32 	%f5, %f3, %f4;
	cvt.rzi.f32.f32 	%f6, %f5;
	abs.f32 	%f7, %f3;
	setp.gt.f32 	%p7, %f7, 0f4B000000;
	selp.f32 	%f8, %f3, %f6, %p7;
	cvt.rzi.f32.f32 	%f9, %f3;
	setp.lt.f32 	%p8, %f7, 0f3F000000;
	selp.f32 	%f10, %f9, %f8, %p8;
	cvt.rzi.s32.f32 	%r162, %f10;
	fma.rn.f32 	%f11, %f10, 0fBF000000, %f2;
	mul.f32 	%f12, %f11, 0f34222169;
	fma.rn.f32 	%f13, %f11, 0f40490FDA, %f12;
	mul.f32 	%f14, %f13, %f13;
	fma.rn.f32 	%f15, %f14, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f16, %f15, %f14, 0f3D2AAABB;
	fma.rn.f32 	%f17, %f16, %f14, 0fBEFFFFFF;
	fma.rn.f32 	%f18, %f17, %f14, 0f3F800000;
	fma.rn.f32 	%f19, %f14, %f13, 0f00000000;
	fma.rn.f32 	%f20, %f14, 0fB94D4153, 0f3C0885E4;
	fma.rn.f32 	%f21, %f20, %f14, 0fBE2AAAA8;
	fma.rn.f32 	%f22, %f21, %f19, %f13;
	and.b32  	%r163, %r162, 1;
	setp.eq.b32 	%p9, %r163, 1;
	selp.f32 	%f23, %f18, %f22, %p9;
	selp.f32 	%f24, %f22, %f18, %p9;
	and.b32  	%r164, %r162, 2;
	setp.eq.s32 	%p10, %r164, 0;
	neg.f32 	%f25, %f23;
	selp.f32 	%f26, %f23, %f25, %p10;
	add.s32 	%r165, %r162, 1;
	and.b32  	%r166, %r165, 2;
	setp.eq.s32 	%p11, %r166, 0;
	mov.f32 	%f27, 0f00000000;
	sub.f32 	%f28, %f27, %f24;
	selp.f32 	%f29, %f24, %f28, %p11;
	cvt.rzi.f32.f32 	%f30, %f2;
	setp.eq.f32 	%p12, %f30, %f2;
	mul.f32 	%f31, %f2, 0f00000000;
	selp.f32 	%f32, %f31, %f26, %p12;
	abs.f32 	%f33, %f2;
	setp.gt.f32 	%p13, %f33, 0f4B800000;
	add.f32 	%f34, %f32, 0f3F800000;
	selp.f32 	%f35, %f34, %f29, %p13;
	mov.b32 	%r132, %f35;
	mov.b32 	%r135, %f32;
	shl.b32 	%r80, %r1, 1;
	and.b32  	%r167, %r80, 6;
	mul.lo.s32 	%r168, %r77, %r167;
	cvt.rn.f32.s32 	%f36, %r168;
	div.rn.f32 	%f37, %f36, 0f41C00000;
	add.f32 	%f38, %f37, %f37;
	mov.b32 	%r169, %f38;
	and.b32  	%r170, %r169, -2147483648;
	or.b32  	%r171, %r170, 1056964608;
	mov.b32 	%f39, %r171;
	add.f32 	%f40, %f38, %f39;
	cvt.rzi.f32.f32 	%f41, %f40;
	abs.f32 	%f42, %f38;
	setp.gt.f32 	%p14, %f42, 0f4B000000;
	selp.f32 	%f43, %f38, %f41, %p14;
	cvt.rzi.f32.f32 	%f44, %f38;
	setp.lt.f32 	%p15, %f42, 0f3F000000;
	selp.f32 	%f45, %f44, %f43, %p15;
	cvt.rzi.s32.f32 	%r172, %f45;
	fma.rn.f32 	%f46, %f45, 0fBF000000, %f37;
	mul.f32 	%f47, %f46, 0f34222169;
	fma.rn.f32 	%f48, %f46, 0f40490FDA, %f47;
	mul.f32 	%f49, %f48, %f48;
	fma.rn.f32 	%f50, %f49, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f51, %f50, %f49, 0f3D2AAABB;
	fma.rn.f32 	%f52, %f51, %f49, 0fBEFFFFFF;
	fma.rn.f32 	%f53, %f52, %f49, 0f3F800000;
	fma.rn.f32 	%f54, %f49, %f48, 0f00000000;
	fma.rn.f32 	%f55, %f49, 0fB94D4153, 0f3C0885E4;
	fma.rn.f32 	%f56, %f55, %f49, 0fBE2AAAA8;
	fma.rn.f32 	%f57, %f56, %f54, %f48;
	and.b32  	%r173, %r172, 1;
	setp.eq.b32 	%p16, %r173, 1;
	selp.f32 	%f58, %f53, %f57, %p16;
	selp.f32 	%f59, %f57, %f53, %p16;
	and.b32  	%r174, %r172, 2;
	setp.eq.s32 	%p17, %r174, 0;
	neg.f32 	%f60, %f58;
	selp.f32 	%f61, %f58, %f60, %p17;
	add.s32 	%r175, %r172, 1;
	and.b32  	%r176, %r175, 2;
	setp.eq.s32 	%p18, %r176, 0;
	sub.f32 	%f62, %f27, %f59;
	selp.f32 	%f63, %f59, %f62, %p18;
	cvt.rzi.f32.f32 	%f64, %f37;
	setp.eq.f32 	%p19, %f64, %f37;
	mul.f32 	%f65, %f37, 0f00000000;
	selp.f32 	%f66, %f65, %f61, %p19;
	abs.f32 	%f67, %f37;
	setp.gt.f32 	%p20, %f67, 0f4B800000;
	add.f32 	%f68, %f66, 0f3F800000;
	selp.f32 	%f69, %f68, %f63, %p20;
	add.s32 	%r177, %r168, %r77;
	cvt.rn.f32.s32 	%f70, %r177;
	div.rn.f32 	%f71, %f70, 0f41C00000;
	add.f32 	%f72, %f71, %f71;
	mov.b32 	%r178, %f72;
	and.b32  	%r179, %r178, -2147483648;
	or.b32  	%r180, %r179, 1056964608;
	mov.b32 	%f73, %r180;
	add.f32 	%f74, %f72, %f73;
	cvt.rzi.f32.f32 	%f75, %f74;
	abs.f32 	%f76, %f72;
	setp.gt.f32 	%p21, %f76, 0f4B000000;
	selp.f32 	%f77, %f72, %f75, %p21;
	cvt.rzi.f32.f32 	%f78, %f72;
	setp.lt.f32 	%p22, %f76, 0f3F000000;
	selp.f32 	%f79, %f78, %f77, %p22;
	cvt.rzi.s32.f32 	%r181, %f79;
	fma.rn.f32 	%f80, %f79, 0fBF000000, %f71;
	mul.f32 	%f81, %f80, 0f34222169;
	fma.rn.f32 	%f82, %f80, 0f40490FDA, %f81;
	mul.f32 	%f83, %f82, %f82;
	fma.rn.f32 	%f84, %f83, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f85, %f84, %f83, 0f3D2AAABB;
	fma.rn.f32 	%f86, %f85, %f83, 0fBEFFFFFF;
	fma.rn.f32 	%f87, %f86, %f83, 0f3F800000;
	fma.rn.f32 	%f88, %f83, %f82, 0f00000000;
	fma.rn.f32 	%f89, %f83, 0fB94D4153, 0f3C0885E4;
	fma.rn.f32 	%f90, %f89, %f83, 0fBE2AAAA8;
	fma.rn.f32 	%f91, %f90, %f88, %f82;
	and.b32  	%r182, %r181, 1;
	setp.eq.b32 	%p23, %r182, 1;
	selp.f32 	%f92, %f87, %f91, %p23;
	selp.f32 	%f93, %f91, %f87, %p23;
	and.b32  	%r183, %r181, 2;
	setp.eq.s32 	%p24, %r183, 0;
	neg.f32 	%f94, %f92;
	selp.f32 	%f95, %f92, %f94, %p24;
	add.s32 	%r184, %r181, 1;
	and.b32  	%r185, %r184, 2;
	setp.eq.s32 	%p25, %r185, 0;
	sub.f32 	%f96, %f27, %f93;
	selp.f32 	%f97, %f93, %f96, %p25;
	cvt.rzi.f32.f32 	%f98, %f71;
	setp.eq.f32 	%p26, %f98, %f71;
	mul.f32 	%f99, %f71, 0f00000000;
	selp.f32 	%f100, %f99, %f95, %p26;
	abs.f32 	%f101, %f71;
	setp.gt.f32 	%p27, %f101, 0f4B800000;
	add.f32 	%f102, %f100, 0f3F800000;
	selp.f32 	%f103, %f102, %f97, %p27;
	shl.b32 	%r83, %r1, 4;
	and.b32  	%r186, %r83, 48;
	mul.lo.s32 	%r187, %r77, %r186;
	cvt.rn.f32.s32 	%f104, %r187;
	div.rn.f32 	%f105, %f104, 0f41C00000;
	add.f32 	%f106, %f105, %f105;
	mov.b32 	%r188, %f106;
	and.b32  	%r189, %r188, -2147483648;
	or.b32  	%r190, %r189, 1056964608;
	mov.b32 	%f107, %r190;
	add.f32 	%f108, %f106, %f107;
	cvt.rzi.f32.f32 	%f109, %f108;
	abs.f32 	%f110, %f106;
	setp.gt.f32 	%p28, %f110, 0f4B000000;
	selp.f32 	%f111, %f106, %f109, %p28;
	cvt.rzi.f32.f32 	%f112, %f106;
	setp.lt.f32 	%p29, %f110, 0f3F000000;
	selp.f32 	%f113, %f112, %f111, %p29;
	cvt.rzi.s32.f32 	%r191, %f113;
	fma.rn.f32 	%f114, %f113, 0fBF000000, %f105;
	mul.f32 	%f115, %f114, 0f34222169;
	fma.rn.f32 	%f116, %f114, 0f40490FDA, %f115;
	mul.f32 	%f117, %f116, %f116;
	fma.rn.f32 	%f118, %f117, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f119, %f118, %f117, 0f3D2AAABB;
	fma.rn.f32 	%f120, %f119, %f117, 0fBEFFFFFF;
	fma.rn.f32 	%f121, %f120, %f117, 0f3F800000;
	fma.rn.f32 	%f122, %f117, %f116, 0f00000000;
	fma.rn.f32 	%f123, %f117, 0fB94D4153, 0f3C0885E4;
	fma.rn.f32 	%f124, %f123, %f117, 0fBE2AAAA8;
	fma.rn.f32 	%f125, %f124, %f122, %f116;
	and.b32  	%r192, %r191, 1;
	setp.eq.b32 	%p30, %r192, 1;
	selp.f32 	%f126, %f121, %f125, %p30;
	selp.f32 	%f127, %f125, %f121, %p30;
	and.b32  	%r193, %r191, 2;
	setp.eq.s32 	%p31, %r193, 0;
	neg.f32 	%f128, %f126;
	selp.f32 	%f129, %f126, %f128, %p31;
	add.s32 	%r194, %r191, 1;
	and.b32  	%r195, %r194, 2;
	setp.eq.s32 	%p32, %r195, 0;
	sub.f32 	%f130, %f27, %f127;
	selp.f32 	%f131, %f127, %f130, %p32;
	cvt.rzi.f32.f32 	%f132, %f105;
	setp.eq.f32 	%p33, %f132, %f105;
	mul.f32 	%f133, %f105, 0f00000000;
	selp.f32 	%f134, %f133, %f129, %p33;
	abs.f32 	%f135, %f105;
	setp.gt.f32 	%p34, %f135, 0f4B800000;
	add.f32 	%f136, %f134, 0f3F800000;
	selp.f32 	%f137, %f136, %f131, %p34;
	shl.b32 	%r196, %r77, 3;
	add.s32 	%r197, %r187, %r196;
	cvt.rn.f32.s32 	%f138, %r197;
	div.rn.f32 	%f139, %f138, 0f41C00000;
	add.f32 	%f140, %f139, %f139;
	mov.b32 	%r198, %f140;
	and.b32  	%r199, %r198, -2147483648;
	or.b32  	%r200, %r199, 1056964608;
	mov.b32 	%f141, %r200;
	add.f32 	%f142, %f140, %f141;
	cvt.rzi.f32.f32 	%f143, %f142;
	abs.f32 	%f144, %f140;
	setp.gt.f32 	%p35, %f144, 0f4B000000;
	selp.f32 	%f145, %f140, %f143, %p35;
	cvt.rzi.f32.f32 	%f146, %f140;
	setp.lt.f32 	%p36, %f144, 0f3F000000;
	selp.f32 	%f147, %f146, %f145, %p36;
	cvt.rzi.s32.f32 	%r201, %f147;
	fma.rn.f32 	%f148, %f147, 0fBF000000, %f139;
	mul.f32 	%f149, %f148, 0f34222169;
	fma.rn.f32 	%f150, %f148, 0f40490FDA, %f149;
	mul.f32 	%f151, %f150, %f150;
	fma.rn.f32 	%f152, %f151, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f153, %f152, %f151, 0f3D2AAABB;
	fma.rn.f32 	%f154, %f153, %f151, 0fBEFFFFFF;
	fma.rn.f32 	%f155, %f154, %f151, 0f3F800000;
	fma.rn.f32 	%f156, %f151, %f150, 0f00000000;
	fma.rn.f32 	%f157, %f151, 0fB94D4153, 0f3C0885E4;
	fma.rn.f32 	%f158, %f157, %f151, 0fBE2AAAA8;
	fma.rn.f32 	%f159, %f158, %f156, %f150;
	and.b32  	%r202, %r201, 1;
	setp.eq.b32 	%p37, %r202, 1;
	selp.f32 	%f160, %f155, %f159, %p37;
	selp.f32 	%f161, %f159, %f155, %p37;
	and.b32  	%r203, %r201, 2;
	setp.eq.s32 	%p38, %r203, 0;
	neg.f32 	%f162, %f160;
	selp.f32 	%f163, %f160, %f162, %p38;
	add.s32 	%r204, %r201, 1;
	and.b32  	%r205, %r204, 2;
	setp.eq.s32 	%p39, %r205, 0;
	sub.f32 	%f164, %f27, %f161;
	selp.f32 	%f165, %f161, %f164, %p39;
	cvt.rzi.f32.f32 	%f166, %f139;
	setp.eq.f32 	%p40, %f166, %f139;
	mul.f32 	%f167, %f139, 0f00000000;
	selp.f32 	%f168, %f167, %f163, %p40;
	abs.f32 	%f169, %f139;
	setp.gt.f32 	%p41, %f169, 0f4B800000;
	add.f32 	%f170, %f168, 0f3F800000;
	selp.f32 	%f171, %f170, %f165, %p41;
	mov.b32 	%r143, %f137;
	mov.b32 	%r144, %f171;
	mov.b32 	%r149, %f134;
	mov.b32 	%r150, %f168;
	cvt.u16.u32 	%rs10, %r1;
	and.b16  	%rs11, %rs10, 255;
	mul.lo.s16 	%rs12, %rs11, 171;
	shr.u16 	%rs13, %rs12, 12;
	mul.lo.s16 	%rs14, %rs13, 24;
	sub.s16 	%rs15, %rs10, %rs14;
	cvt.u32.u16 	%r206, %rs15;
	and.b32  	%r88, %r206, 255;
	mad.lo.s32 	%r207, %r88, 24, %r74;
	and.b32  	%r208, %r207, 511;
	mul.wide.u32 	%rd35, %r208, 4;
	add.s64 	%rd36, %rd1, %rd35;
	ld.global.u32 	%r89, [%rd36];
	setp.gt.u32 	%p42, %r1, 23;
	mov.u32 	%r154, 0;
	mov.u32 	%r92, %r154;
	mov.u32 	%r93, %r154;
	@%p42 bra 	LBB0_22;
// %bb.21:                              // %pass101
	ld.param.u64 	%rd2, [_Z15julia_frb_1059013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_2];
	shr.u16 	%rs18, %rs5, 10;
	mul.wide.u16 	%r209, %rs18, 6;
	cvt.u16.u32 	%rs19, %r77;
	mul.lo.s16 	%rs20, %rs19, 171;
	shr.u16 	%rs21, %rs20, 10;
	mul.lo.s16 	%rs22, %rs21, 6;
	sub.s16 	%rs23, %rs19, %rs22;
	mul.lo.s16 	%rs24, %rs23, 24;
	cvt.u32.u16 	%r210, %rs24;
	and.b32  	%r211, %r210, 248;
	add.s32 	%r212, %r209, %r211;
	mul.lo.s16 	%rs25, %rs18, 6;
	sub.s16 	%rs26, %rs1, %rs25;
	cvt.u32.u16 	%r213, %rs26;
	and.b32  	%r214, %r213, 255;
	add.s32 	%r215, %r212, %r214;
	mul.lo.s32 	%r216, %r76, 144;
	add.s32 	%r217, %r215, %r216;
	mul.wide.u32 	%rd37, %r217, 4;
	add.s64 	%rd38, %rd2, %rd37;
	ld.global.u32 	%r92, [%rd38];
	cvt.u64.u32 	%rd39, %r216;
	cvt.u64.u16 	%rd40, %rs26;
	and.b64  	%rd41, %rd40, 255;
	cvt.u64.u16 	%rd42, %rs24;
	and.b64  	%rd43, %rd42, 248;
	cvt.u64.u32 	%rd44, %r209;
	add.s64 	%rd45, %rd44, %rd43;
	add.s64 	%rd46, %rd45, %rd41;
	add.s64 	%rd47, %rd46, %rd39;
	shl.b64 	%rd48, %rd47, 2;
	add.s64 	%rd49, %rd2, %rd48;
	ld.global.u32 	%r93, [%rd49+2304];
LBB0_22:                                // %pass218
	xor.b32  	%r131, %r135, -2147483648;
	mov.b32 	%r137, %f69;
	mov.b32 	%r138, %f103;
	mov.b32 	%r140, %f66;
	mov.b32 	%r141, %f100;
	xor.b32  	%r146, %r149, -2147483648;
	xor.b32  	%r147, %r150, -2147483648;
	ld.param.u64 	%rd10, [_Z15julia_frb_1059013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_8];
	setp.lt.u32 	%p43, %r1, 24;
	shl.b32 	%r410, %r74, 10;
	and.b32  	%r411, %r83, 240;
	or.b32  	%r412, %r411, %r410;
	shl.b32 	%r413, %r1, 5;
	and.b32  	%r414, %r413, 512;
	or.b32  	%r415, %r414, %r412;
	cvt.u64.u32 	%rd50, %r415;
	add.s64 	%rd51, %rd3, %rd50;
	ld.global.v4.u32 	{%r416, %r417, %r418, %r419}, [%rd51];
	ld.global.v4.u32 	{%r420, %r421, %r422, %r423}, [%rd51+256];
	add.s32 	%r424, %r74, 24;
	cvt.u16.u32 	%rs27, %r424;
	and.b16  	%rs28, %rs27, 255;
	mul.lo.s16 	%rs29, %rs28, 171;
	shr.u16 	%rs30, %rs29, 13;
	mul.lo.s16 	%rs31, %rs30, 48;
	sub.s16 	%rs32, %rs27, %rs31;
	and.b16  	%rs33, %rs32, 255;
	mul.wide.u16 	%r425, %rs33, 1024;
	or.b32  	%r426, %r411, %r425;
	or.b32  	%r427, %r414, %r426;
	cvt.u64.u32 	%rd52, %r427;
	add.s64 	%rd53, %rd3, %rd52;
	ld.global.v4.u32 	{%r428, %r429, %r430, %r431}, [%rd53];
	ld.global.v4.u32 	{%r432, %r433, %r434, %r435}, [%rd53+256];
	shr.u32 	%r94, %r1, 4;
	setp.eq.s32 	%p44, %r94, 1;
	selp.b32 	%r436, %r416, %r418, %p44;
	shfl.sync.bfly.b32	%r437, %r436, 16, 31, -1;
	selp.b32 	%r220, %r437, %r416, %p44;
	selp.b32 	%r225, %r418, %r437, %p44;
	selp.b32 	%r438, %r417, %r419, %p44;
	shfl.sync.bfly.b32	%r439, %r438, 16, 31, -1;
	selp.b32 	%r228, %r439, %r417, %p44;
	selp.b32 	%r233, %r419, %r439, %p44;
	selp.b32 	%r440, %r420, %r422, %p44;
	shfl.sync.bfly.b32	%r441, %r440, 16, 31, -1;
	selp.b32 	%r236, %r441, %r420, %p44;
	selp.b32 	%r241, %r422, %r441, %p44;
	selp.b32 	%r442, %r421, %r423, %p44;
	shfl.sync.bfly.b32	%r443, %r442, 16, 31, -1;
	selp.b32 	%r244, %r443, %r421, %p44;
	selp.b32 	%r249, %r423, %r443, %p44;
	selp.b32 	%r444, %r428, %r430, %p44;
	shfl.sync.bfly.b32	%r445, %r444, 16, 31, -1;
	selp.b32 	%r252, %r445, %r428, %p44;
	selp.b32 	%r257, %r430, %r445, %p44;
	selp.b32 	%r446, %r429, %r431, %p44;
	shfl.sync.bfly.b32	%r447, %r446, 16, 31, -1;
	selp.b32 	%r260, %r447, %r429, %p44;
	selp.b32 	%r265, %r431, %r447, %p44;
	selp.b32 	%r448, %r432, %r434, %p44;
	shfl.sync.bfly.b32	%r449, %r448, 16, 31, -1;
	selp.b32 	%r268, %r449, %r432, %p44;
	selp.b32 	%r273, %r434, %r449, %p44;
	selp.b32 	%r450, %r433, %r435, %p44;
	shfl.sync.bfly.b32	%r451, %r450, 16, 31, -1;
	selp.b32 	%r276, %r451, %r433, %p44;
	selp.b32 	%r281, %r435, %r451, %p44;
	shl.b32 	%r221, %r225, 4;
	mov.u32 	%r219, 252645135;
	// begin inline asm
	lop3.b32 %r283, %r219, %r220, %r221, 202;
	// end inline asm
	shr.u32 	%r224, %r220, 4;
	// begin inline asm
	lop3.b32 %r299, %r219, %r224, %r225, 202;
	// end inline asm
	shl.b32 	%r229, %r233, 4;
	// begin inline asm
	lop3.b32 %r291, %r219, %r228, %r229, 202;
	// end inline asm
	shr.u32 	%r232, %r228, 4;
	// begin inline asm
	lop3.b32 %r307, %r219, %r232, %r233, 202;
	// end inline asm
	shl.b32 	%r237, %r241, 4;
	// begin inline asm
	lop3.b32 %r315, %r219, %r236, %r237, 202;
	// end inline asm
	shr.u32 	%r240, %r236, 4;
	// begin inline asm
	lop3.b32 %r331, %r219, %r240, %r241, 202;
	// end inline asm
	shl.b32 	%r245, %r249, 4;
	// begin inline asm
	lop3.b32 %r323, %r219, %r244, %r245, 202;
	// end inline asm
	shr.u32 	%r248, %r244, 4;
	// begin inline asm
	lop3.b32 %r339, %r219, %r248, %r249, 202;
	// end inline asm
	shl.b32 	%r253, %r257, 4;
	// begin inline asm
	lop3.b32 %r284, %r219, %r252, %r253, 202;
	// end inline asm
	shr.u32 	%r256, %r252, 4;
	// begin inline asm
	lop3.b32 %r300, %r219, %r256, %r257, 202;
	// end inline asm
	shl.b32 	%r261, %r265, 4;
	// begin inline asm
	lop3.b32 %r292, %r219, %r260, %r261, 202;
	// end inline asm
	shr.u32 	%r264, %r260, 4;
	// begin inline asm
	lop3.b32 %r308, %r219, %r264, %r265, 202;
	// end inline asm
	shl.b32 	%r269, %r273, 4;
	// begin inline asm
	lop3.b32 %r316, %r219, %r268, %r269, 202;
	// end inline asm
	shr.u32 	%r272, %r268, 4;
	// begin inline asm
	lop3.b32 %r332, %r219, %r272, %r273, 202;
	// end inline asm
	shl.b32 	%r277, %r281, 4;
	// begin inline asm
	lop3.b32 %r324, %r219, %r276, %r277, 202;
	// end inline asm
	shr.u32 	%r280, %r276, 4;
	// begin inline asm
	lop3.b32 %r340, %r219, %r280, %r281, 202;
	// end inline asm
	mov.u32 	%r285, 25152;
	// begin inline asm
	prmt.b32 %r347, %r283, %r284, %r285;
	// end inline asm
	mov.u32 	%r289, 29521;
	// begin inline asm
	prmt.b32 %r379, %r283, %r284, %r289;
	// end inline asm
	// begin inline asm
	prmt.b32 %r355, %r291, %r292, %r285;
	// end inline asm
	// begin inline asm
	prmt.b32 %r387, %r291, %r292, %r289;
	// end inline asm
	// begin inline asm
	prmt.b32 %r348, %r299, %r300, %r285;
	// end inline asm
	// begin inline asm
	prmt.b32 %r380, %r299, %r300, %r289;
	// end inline asm
	// begin inline asm
	prmt.b32 %r356, %r307, %r308, %r285;
	// end inline asm
	// begin inline asm
	prmt.b32 %r388, %r307, %r308, %r289;
	// end inline asm
	// begin inline asm
	prmt.b32 %r363, %r315, %r316, %r285;
	// end inline asm
	// begin inline asm
	prmt.b32 %r395, %r315, %r316, %r289;
	// end inline asm
	// begin inline asm
	prmt.b32 %r371, %r323, %r324, %r285;
	// end inline asm
	// begin inline asm
	prmt.b32 %r403, %r323, %r324, %r289;
	// end inline asm
	// begin inline asm
	prmt.b32 %r364, %r331, %r332, %r285;
	// end inline asm
	// begin inline asm
	prmt.b32 %r396, %r331, %r332, %r289;
	// end inline asm
	// begin inline asm
	prmt.b32 %r372, %r339, %r340, %r285;
	// end inline asm
	// begin inline asm
	prmt.b32 %r404, %r339, %r340, %r289;
	// end inline asm
	mov.u32 	%r405, 21520;
	// begin inline asm
	prmt.b32 %r346, %r347, %r348, %r405;
	// end inline asm
	mov.u32 	%r409, 30258;
	// begin inline asm
	prmt.b32 %r350, %r347, %r348, %r409;
	// end inline asm
	// begin inline asm
	prmt.b32 %r354, %r355, %r356, %r405;
	// end inline asm
	// begin inline asm
	prmt.b32 %r358, %r355, %r356, %r409;
	// end inline asm
	// begin inline asm
	prmt.b32 %r362, %r363, %r364, %r405;
	// end inline asm
	// begin inline asm
	prmt.b32 %r366, %r363, %r364, %r409;
	// end inline asm
	// begin inline asm
	prmt.b32 %r370, %r371, %r372, %r405;
	// end inline asm
	// begin inline asm
	prmt.b32 %r374, %r371, %r372, %r409;
	// end inline asm
	// begin inline asm
	prmt.b32 %r378, %r379, %r380, %r405;
	// end inline asm
	// begin inline asm
	prmt.b32 %r382, %r379, %r380, %r409;
	// end inline asm
	// begin inline asm
	prmt.b32 %r386, %r387, %r388, %r405;
	// end inline asm
	// begin inline asm
	prmt.b32 %r390, %r387, %r388, %r409;
	// end inline asm
	// begin inline asm
	prmt.b32 %r394, %r395, %r396, %r405;
	// end inline asm
	// begin inline asm
	prmt.b32 %r398, %r395, %r396, %r409;
	// end inline asm
	// begin inline asm
	prmt.b32 %r402, %r403, %r404, %r405;
	// end inline asm
	// begin inline asm
	prmt.b32 %r406, %r403, %r404, %r409;
	// end inline asm
	and.b32  	%r452, %r80, 30;
	or.b32  	%r453, %r94, %r452;
	mul.lo.s32 	%r454, %r453, 257;
	cvt.u64.u32 	%rd54, %r454;
	cvt.u64.u32 	%rd55, %r74;
	add.s64 	%rd56, %rd55, %rd54;
	shl.b64 	%rd57, %rd56, 2;
	add.s64 	%rd58, %rd57, %rd6;
	st.global.u32 	[%rd58], %r346;
	st.global.u32 	[%rd58+512], %r354;
	st.global.u32 	[%rd58+256], %r350;
	st.global.u32 	[%rd58+768], %r358;
	or.b32  	%r455, %r453, 32;
	mul.lo.s32 	%r456, %r455, 257;
	cvt.u64.u32 	%rd59, %r456;
	add.s64 	%rd60, %rd55, %rd59;
	shl.b64 	%rd61, %rd60, 2;
	add.s64 	%rd62, %rd61, %rd6;
	st.global.u32 	[%rd62], %r362;
	st.global.u32 	[%rd62+512], %r370;
	st.global.u32 	[%rd62+256], %r366;
	st.global.u32 	[%rd62+768], %r374;
	st.global.u32 	[%rd58+128], %r378;
	st.global.u32 	[%rd58+640], %r386;
	st.global.u32 	[%rd58+384], %r382;
	st.global.u32 	[%rd58+896], %r390;
	st.global.u32 	[%rd62+128], %r394;
	st.global.u32 	[%rd62+640], %r402;
	st.global.u32 	[%rd62+384], %r398;
	st.global.u32 	[%rd62+896], %r406;
	bar.sync 	0;
	and.b32  	%r457, %r75, 224;
	shr.u32 	%r95, %r74, 3;
	mul.lo.s32 	%r458, %r95, 257;
	cvt.u64.u32 	%rd63, %r458;
	cvt.u64.u32 	%rd64, %r457;
	cvt.u64.u32 	%rd32, %r88;
	add.s64 	%rd65, %rd32, %rd64;
	add.s64 	%rd66, %rd65, %rd63;
	shl.b64 	%rd67, %rd66, 2;
	add.s64 	%rd68, %rd67, %rd6;
	ld.global.u32 	%r459, [%rd68];
	shr.u32 	%r460, %r424, 3;
	mul.lo.s32 	%r461, %r460, 257;
	cvt.u64.u32 	%rd69, %r461;
	add.s64 	%rd70, %rd65, %rd69;
	shl.b64 	%rd71, %rd70, 2;
	add.s64 	%rd72, %rd71, %rd6;
	ld.global.u32 	%r462, [%rd72];
	add.s32 	%r463, %r74, 48;
	shr.u32 	%r464, %r463, 3;
	mul.lo.s32 	%r465, %r464, 257;
	cvt.u64.u32 	%rd73, %r465;
	add.s64 	%rd74, %rd65, %rd73;
	shl.b64 	%rd75, %rd74, 2;
	add.s64 	%rd76, %rd75, %rd6;
	ld.global.u32 	%r466, [%rd76];
	add.s32 	%r467, %r74, 72;
	shr.u32 	%r468, %r467, 3;
	mul.lo.s32 	%r469, %r468, 257;
	cvt.u64.u32 	%rd77, %r469;
	add.s64 	%rd78, %rd65, %rd77;
	shl.b64 	%rd79, %rd78, 2;
	add.s64 	%rd80, %rd79, %rd6;
	ld.global.u32 	%r470, [%rd80];
	add.s32 	%r471, %r458, 3084;
	cvt.u64.u32 	%rd81, %r471;
	add.s64 	%rd82, %rd65, %rd81;
	shl.b64 	%rd83, %rd82, 2;
	add.s64 	%rd84, %rd83, %rd6;
	ld.global.u32 	%r472, [%rd84];
	add.s32 	%r473, %r74, 120;
	shr.u32 	%r474, %r473, 3;
	mul.lo.s32 	%r475, %r474, 257;
	cvt.u64.u32 	%rd85, %r475;
	add.s64 	%rd86, %rd65, %rd85;
	shl.b64 	%rd87, %rd86, 2;
	add.s64 	%rd88, %rd87, %rd6;
	ld.global.u32 	%r476, [%rd88];
	add.s32 	%r477, %r74, 144;
	shr.u32 	%r478, %r477, 3;
	mul.lo.s32 	%r479, %r478, 257;
	cvt.u64.u32 	%rd89, %r479;
	add.s64 	%rd90, %rd65, %rd89;
	shl.b64 	%rd91, %rd90, 2;
	add.s64 	%rd92, %rd91, %rd6;
	ld.global.u32 	%r480, [%rd92];
	add.s32 	%r481, %r74, 168;
	shr.u32 	%r482, %r481, 3;
	mul.lo.s32 	%r483, %r482, 257;
	cvt.u64.u32 	%rd93, %r483;
	add.s64 	%rd94, %rd65, %rd93;
	shl.b64 	%rd95, %rd94, 2;
	add.s64 	%rd96, %rd95, %rd6;
	ld.global.u32 	%r484, [%rd96];
	add.s32 	%r485, %r458, 6168;
	cvt.u64.u32 	%rd97, %r485;
	add.s64 	%rd98, %rd65, %rd97;
	shl.b64 	%rd99, %rd98, 2;
	add.s64 	%rd100, %rd99, %rd6;
	ld.global.u32 	%r486, [%rd100];
	add.s32 	%r487, %r74, 216;
	shr.u32 	%r488, %r487, 3;
	mul.lo.s32 	%r489, %r488, 257;
	cvt.u64.u32 	%rd101, %r489;
	add.s64 	%rd102, %rd65, %rd101;
	shl.b64 	%rd103, %rd102, 2;
	add.s64 	%rd104, %rd103, %rd6;
	ld.global.u32 	%r490, [%rd104];
	add.s32 	%r491, %r74, 240;
	shr.u32 	%r492, %r491, 3;
	mul.lo.s32 	%r493, %r492, 257;
	cvt.u64.u32 	%rd105, %r493;
	add.s64 	%rd106, %rd65, %rd105;
	shl.b64 	%rd107, %rd106, 2;
	add.s64 	%rd108, %rd107, %rd6;
	ld.global.u32 	%r494, [%rd108];
	add.s32 	%r495, %r74, 264;
	shr.u32 	%r496, %r495, 3;
	mul.lo.s32 	%r497, %r496, 257;
	cvt.u64.u32 	%rd109, %r497;
	add.s64 	%rd110, %rd65, %rd109;
	shl.b64 	%rd111, %rd110, 2;
	add.s64 	%rd112, %rd111, %rd6;
	ld.global.u32 	%r498, [%rd112];
	add.s32 	%r499, %r458, 9252;
	cvt.u64.u32 	%rd113, %r499;
	add.s64 	%rd114, %rd65, %rd113;
	shl.b64 	%rd115, %rd114, 2;
	add.s64 	%rd116, %rd115, %rd6;
	ld.global.u32 	%r500, [%rd116];
	add.s32 	%r501, %r74, 312;
	shr.u32 	%r502, %r501, 3;
	mul.lo.s32 	%r503, %r502, 257;
	cvt.u64.u32 	%rd117, %r503;
	add.s64 	%rd118, %rd65, %rd117;
	shl.b64 	%rd119, %rd118, 2;
	add.s64 	%rd120, %rd119, %rd6;
	ld.global.u32 	%r504, [%rd120];
	add.s32 	%r505, %r74, 336;
	shr.u32 	%r506, %r505, 3;
	mul.lo.s32 	%r507, %r506, 257;
	cvt.u64.u32 	%rd121, %r507;
	add.s64 	%rd122, %rd65, %rd121;
	shl.b64 	%rd123, %rd122, 2;
	add.s64 	%rd124, %rd123, %rd6;
	ld.global.u32 	%r508, [%rd124];
	add.s32 	%r509, %r74, 360;
	shr.u32 	%r510, %r509, 3;
	mul.lo.s32 	%r511, %r510, 257;
	cvt.u64.u32 	%rd125, %r511;
	add.s64 	%rd126, %rd65, %rd125;
	shl.b64 	%rd127, %rd126, 2;
	add.s64 	%rd128, %rd127, %rd6;
	ld.global.u32 	%r512, [%rd128];
	add.s32 	%r513, %r458, 12336;
	cvt.u64.u32 	%rd129, %r513;
	add.s64 	%rd130, %rd65, %rd129;
	shl.b64 	%rd131, %rd130, 2;
	add.s64 	%rd132, %rd131, %rd6;
	ld.global.u32 	%r514, [%rd132];
	add.s32 	%r515, %r74, 408;
	shr.u32 	%r516, %r515, 3;
	mul.lo.s32 	%r517, %r516, 257;
	cvt.u64.u32 	%rd133, %r517;
	add.s64 	%rd134, %rd65, %rd133;
	shl.b64 	%rd135, %rd134, 2;
	add.s64 	%rd136, %rd135, %rd6;
	ld.global.u32 	%r518, [%rd136];
	add.s32 	%r519, %r74, 432;
	shr.u32 	%r520, %r519, 3;
	mul.lo.s32 	%r521, %r520, 257;
	cvt.u64.u32 	%rd137, %r521;
	add.s64 	%rd138, %rd65, %rd137;
	shl.b64 	%rd139, %rd138, 2;
	add.s64 	%rd140, %rd139, %rd6;
	ld.global.u32 	%r522, [%rd140];
	add.s32 	%r523, %r74, 456;
	shr.u32 	%r524, %r523, 3;
	mul.lo.s32 	%r525, %r524, 257;
	cvt.u64.u32 	%rd141, %r525;
	add.s64 	%rd142, %rd65, %rd141;
	shl.b64 	%rd143, %rd142, 2;
	add.s64 	%rd144, %rd143, %rd6;
	ld.global.u32 	%r526, [%rd144];
	add.s32 	%r527, %r458, 15420;
	cvt.u64.u32 	%rd145, %r527;
	add.s64 	%rd146, %rd65, %rd145;
	shl.b64 	%rd147, %rd146, 2;
	add.s64 	%rd148, %rd147, %rd6;
	ld.global.u32 	%r528, [%rd148];
	add.s32 	%r529, %r74, 504;
	bfe.u32 	%r530, %r529, 3, 6;
	mul.lo.s32 	%r531, %r530, 257;
	cvt.u64.u32 	%rd149, %r531;
	add.s64 	%rd150, %rd65, %rd149;
	shl.b64 	%rd151, %rd150, 2;
	add.s64 	%rd152, %rd151, %rd6;
	ld.global.u32 	%r532, [%rd152];
	bar.sync 	0;
	shfl.sync.idx.b32	%r533, %r89, 0, 31, -1;
	shfl.sync.idx.b32	%r534, %r89, 1, 31, -1;
	shfl.sync.idx.b32	%r535, %r89, 2, 31, -1;
	shfl.sync.idx.b32	%r536, %r89, 3, 31, -1;
	shfl.sync.idx.b32	%r537, %r89, 4, 31, -1;
	shfl.sync.idx.b32	%r538, %r89, 5, 31, -1;
	shfl.sync.idx.b32	%r539, %r89, 6, 31, -1;
	shfl.sync.idx.b32	%r540, %r89, 7, 31, -1;
	shfl.sync.idx.b32	%r541, %r89, 8, 31, -1;
	shfl.sync.idx.b32	%r542, %r89, 9, 31, -1;
	shfl.sync.idx.b32	%r543, %r89, 10, 31, -1;
	shfl.sync.idx.b32	%r544, %r89, 11, 31, -1;
	shfl.sync.idx.b32	%r545, %r89, 12, 31, -1;
	shfl.sync.idx.b32	%r546, %r89, 13, 31, -1;
	shfl.sync.idx.b32	%r547, %r89, 14, 31, -1;
	shfl.sync.idx.b32	%r548, %r89, 15, 31, -1;
	shfl.sync.idx.b32	%r549, %r89, 16, 31, -1;
	shfl.sync.idx.b32	%r550, %r89, 17, 31, -1;
	shfl.sync.idx.b32	%r551, %r89, 18, 31, -1;
	shfl.sync.idx.b32	%r552, %r89, 19, 31, -1;
	shfl.sync.idx.b32	%r553, %r89, 20, 31, -1;
	shfl.sync.idx.b32	%r554, %r89, 21, 31, -1;
	shfl.sync.idx.b32	%r555, %r89, 22, 31, -1;
	shfl.sync.idx.b32	%r556, %r89, 23, 31, -1;
	add.s32 	%r557, %r533, %r88;
	add.s32 	%r558, %r557, 1;
	mul.wide.s32 	%rd153, %r558, 4;
	add.s64 	%rd154, %rd8, %rd153;
	st.global.u32 	[%rd154+-4], %r459;
	add.s32 	%r559, %r534, %r88;
	add.s32 	%r560, %r559, 1;
	mul.wide.s32 	%rd155, %r560, 4;
	add.s64 	%rd156, %rd8, %rd155;
	st.global.u32 	[%rd156+-4], %r462;
	add.s32 	%r561, %r535, %r88;
	add.s32 	%r562, %r561, 1;
	mul.wide.s32 	%rd157, %r562, 4;
	add.s64 	%rd158, %rd8, %rd157;
	st.global.u32 	[%rd158+-4], %r466;
	add.s32 	%r563, %r536, %r88;
	add.s32 	%r564, %r563, 1;
	mul.wide.s32 	%rd159, %r564, 4;
	add.s64 	%rd160, %rd8, %rd159;
	st.global.u32 	[%rd160+-4], %r470;
	add.s32 	%r565, %r537, %r88;
	add.s32 	%r566, %r565, 1;
	mul.wide.s32 	%rd161, %r566, 4;
	add.s64 	%rd162, %rd8, %rd161;
	st.global.u32 	[%rd162+-4], %r472;
	add.s32 	%r567, %r538, %r88;
	add.s32 	%r568, %r567, 1;
	mul.wide.s32 	%rd163, %r568, 4;
	add.s64 	%rd164, %rd8, %rd163;
	st.global.u32 	[%rd164+-4], %r476;
	add.s32 	%r569, %r539, %r88;
	add.s32 	%r570, %r569, 1;
	mul.wide.s32 	%rd165, %r570, 4;
	add.s64 	%rd166, %rd8, %rd165;
	st.global.u32 	[%rd166+-4], %r480;
	add.s32 	%r571, %r540, %r88;
	add.s32 	%r572, %r571, 1;
	mul.wide.s32 	%rd167, %r572, 4;
	add.s64 	%rd168, %rd8, %rd167;
	st.global.u32 	[%rd168+-4], %r484;
	add.s32 	%r573, %r541, %r88;
	add.s32 	%r574, %r573, 1;
	mul.wide.s32 	%rd169, %r574, 4;
	add.s64 	%rd170, %rd8, %rd169;
	st.global.u32 	[%rd170+-4], %r486;
	add.s32 	%r575, %r542, %r88;
	add.s32 	%r576, %r575, 1;
	mul.wide.s32 	%rd171, %r576, 4;
	add.s64 	%rd172, %rd8, %rd171;
	st.global.u32 	[%rd172+-4], %r490;
	add.s32 	%r577, %r543, %r88;
	add.s32 	%r578, %r577, 1;
	mul.wide.s32 	%rd173, %r578, 4;
	add.s64 	%rd174, %rd8, %rd173;
	st.global.u32 	[%rd174+-4], %r494;
	add.s32 	%r579, %r544, %r88;
	add.s32 	%r580, %r579, 1;
	mul.wide.s32 	%rd175, %r580, 4;
	add.s64 	%rd176, %rd8, %rd175;
	st.global.u32 	[%rd176+-4], %r498;
	add.s32 	%r581, %r545, %r88;
	add.s32 	%r582, %r581, 1;
	mul.wide.s32 	%rd177, %r582, 4;
	add.s64 	%rd178, %rd8, %rd177;
	st.global.u32 	[%rd178+-4], %r500;
	add.s32 	%r583, %r546, %r88;
	add.s32 	%r584, %r583, 1;
	mul.wide.s32 	%rd179, %r584, 4;
	add.s64 	%rd180, %rd8, %rd179;
	st.global.u32 	[%rd180+-4], %r504;
	add.s32 	%r585, %r547, %r88;
	add.s32 	%r586, %r585, 1;
	mul.wide.s32 	%rd181, %r586, 4;
	add.s64 	%rd182, %rd8, %rd181;
	st.global.u32 	[%rd182+-4], %r508;
	add.s32 	%r587, %r548, %r88;
	add.s32 	%r588, %r587, 1;
	mul.wide.s32 	%rd183, %r588, 4;
	add.s64 	%rd184, %rd8, %rd183;
	st.global.u32 	[%rd184+-4], %r512;
	add.s32 	%r589, %r549, %r88;
	add.s32 	%r590, %r589, 1;
	mul.wide.s32 	%rd185, %r590, 4;
	add.s64 	%rd186, %rd8, %rd185;
	st.global.u32 	[%rd186+-4], %r514;
	add.s32 	%r591, %r550, %r88;
	add.s32 	%r592, %r591, 1;
	mul.wide.s32 	%rd187, %r592, 4;
	add.s64 	%rd188, %rd8, %rd187;
	st.global.u32 	[%rd188+-4], %r518;
	add.s32 	%r593, %r551, %r88;
	add.s32 	%r594, %r593, 1;
	mul.wide.s32 	%rd189, %r594, 4;
	add.s64 	%rd190, %rd8, %rd189;
	st.global.u32 	[%rd190+-4], %r522;
	add.s32 	%r595, %r552, %r88;
	add.s32 	%r596, %r595, 1;
	mul.wide.s32 	%rd191, %r596, 4;
	add.s64 	%rd192, %rd8, %rd191;
	st.global.u32 	[%rd192+-4], %r526;
	add.s32 	%r597, %r553, %r88;
	add.s32 	%r598, %r597, 1;
	mul.wide.s32 	%rd193, %r598, 4;
	add.s64 	%rd194, %rd8, %rd193;
	st.global.u32 	[%rd194+-4], %r528;
	add.s32 	%r599, %r554, %r88;
	add.s32 	%r600, %r599, 1;
	mul.wide.s32 	%rd195, %r600, 4;
	add.s64 	%rd196, %rd8, %rd195;
	st.global.u32 	[%rd196+-4], %r532;
	add.s32 	%r601, %r555, %r88;
	add.s32 	%r602, %r601, 1;
	mul.wide.s32 	%rd197, %r602, 4;
	add.s64 	%rd198, %rd8, %rd197;
	st.global.u32 	[%rd198+-4], %r154;
	add.s32 	%r604, %r556, %r88;
	add.s32 	%r605, %r604, 1;
	mul.wide.s32 	%rd199, %r605, 4;
	add.s64 	%rd200, %rd8, %rd199;
	st.global.u32 	[%rd200+-4], %r154;
	bar.sync 	0;
	shr.u16 	%rs3, %rs5, 10;
	cvt.u32.u16 	%r96, %rs3;
	@%p43 bra 	LBB0_11;
// %bb.23:                              // %oksrem2223.L12928_crit_edge
	mul.lo.s16 	%rs48, %rs3, 6;
	sub.s16 	%rs49, %rs1, %rs48;
	cvt.u32.u16 	%r637, %rs49;
	and.b32  	%r3, %r637, 255;
	cvt.u16.u32 	%rs50, %r77;
	mul.lo.s16 	%rs51, %rs50, 171;
	shr.u16 	%rs52, %rs51, 10;
	mul.lo.s16 	%rs53, %rs52, 6;
	sub.s16 	%rs54, %rs50, %rs53;
	cvt.u32.u16 	%r638, %rs54;
	and.b32  	%r2391, %r638, 255;
	mov.u32 	%r4, -2004318072;
	mov.u32 	%r5, %r4;
	mov.u32 	%r6, %r4;
	mov.u32 	%r7, %r4;
	mov.u32 	%r8, %r4;
	mov.u32 	%r9, %r4;
	mov.u32 	%r10, %r4;
	mov.u32 	%r11, %r4;
	mov.u32 	%r12, %r4;
	mov.u32 	%r13, %r4;
	mov.u32 	%r14, %r4;
	mov.u32 	%r15, %r4;
	mov.u32 	%r16, %r4;
	mov.u32 	%r17, %r4;
	mov.u32 	%r18, %r4;
	mov.u32 	%r19, %r4;
	mov.u32 	%r20, %r4;
	mov.u32 	%r21, %r4;
	mov.u32 	%r22, %r4;
	mov.u32 	%r23, %r4;
	mov.u32 	%r24, %r4;
	mov.u32 	%r25, %r4;
	mov.u32 	%r26, %r4;
	mov.u32 	%r27, %r4;
	bra.uni 	LBB0_12;
LBB0_11:                                // %pass2272
	mul.lo.s32 	%r606, %r96, 198;
	mul.lo.s16 	%rs36, %rs3, -6;
	add.s16 	%rs37, %rs36, %rs1;
	cvt.u32.u16 	%r607, %rs37;
	and.b32  	%r3, %r607, 255;
	and.b16  	%rs38, %rs37, 255;
	mul.wide.u16 	%r608, %rs38, 33;
	mul.lo.s32 	%r609, %r76, 4806;
	cvt.u16.u32 	%rs39, %r77;
	mul.lo.s16 	%rs40, %rs39, 171;
	shr.u16 	%rs41, %rs40, 10;
	mul.lo.s16 	%rs42, %rs41, 6;
	sub.s16 	%rs43, %rs39, %rs42;
	cvt.u32.u16 	%r610, %rs43;
	and.b32  	%r2391, %r610, 255;
	and.b16  	%rs44, %rs43, 255;
	mul.wide.u16 	%r611, %rs44, 801;
	cvt.u64.u32 	%rd201, %r611;
	cvt.u64.u32 	%rd202, %r609;
	cvt.u64.u32 	%rd203, %r608;
	cvt.u64.u32 	%rd204, %r606;
	add.s64 	%rd205, %rd204, %rd203;
	add.s64 	%rd206, %rd205, %rd202;
	add.s64 	%rd207, %rd206, %rd201;
	shl.b64 	%rd208, %rd207, 2;
	add.s64 	%rd209, %rd208, %rd8;
	ld.global.u32 	%r612, [%rd209];
	ld.global.u32 	%r613, [%rd209+4];
	ld.global.u32 	%r614, [%rd209+8];
	ld.global.u32 	%r615, [%rd209+12];
	ld.global.u32 	%r616, [%rd209+16];
	ld.global.u32 	%r617, [%rd209+20];
	ld.global.u32 	%r618, [%rd209+24];
	ld.global.u32 	%r619, [%rd209+28];
	ld.global.u32 	%r620, [%rd209+32];
	ld.global.u32 	%r621, [%rd209+36];
	ld.global.u32 	%r622, [%rd209+40];
	ld.global.u32 	%r623, [%rd209+44];
	ld.global.u32 	%r624, [%rd209+48];
	ld.global.u32 	%r625, [%rd209+52];
	ld.global.u32 	%r626, [%rd209+56];
	ld.global.u32 	%r627, [%rd209+60];
	ld.global.u32 	%r628, [%rd209+64];
	ld.global.u32 	%r629, [%rd209+68];
	ld.global.u32 	%r630, [%rd209+72];
	ld.global.u32 	%r631, [%rd209+76];
	ld.global.u32 	%r632, [%rd209+80];
	ld.global.u32 	%r633, [%rd209+84];
	ld.global.u32 	%r634, [%rd209+88];
	ld.global.u32 	%r635, [%rd209+92];
	xor.b32  	%r4, %r612, -2004318072;
	xor.b32  	%r5, %r613, -2004318072;
	xor.b32  	%r6, %r614, -2004318072;
	xor.b32  	%r7, %r615, -2004318072;
	xor.b32  	%r8, %r616, -2004318072;
	xor.b32  	%r9, %r617, -2004318072;
	xor.b32  	%r10, %r618, -2004318072;
	xor.b32  	%r11, %r619, -2004318072;
	xor.b32  	%r12, %r620, -2004318072;
	xor.b32  	%r13, %r621, -2004318072;
	xor.b32  	%r14, %r622, -2004318072;
	xor.b32  	%r15, %r623, -2004318072;
	xor.b32  	%r16, %r624, -2004318072;
	xor.b32  	%r17, %r625, -2004318072;
	xor.b32  	%r18, %r626, -2004318072;
	xor.b32  	%r19, %r627, -2004318072;
	xor.b32  	%r20, %r628, -2004318072;
	xor.b32  	%r21, %r629, -2004318072;
	xor.b32  	%r22, %r630, -2004318072;
	xor.b32  	%r23, %r631, -2004318072;
	xor.b32  	%r24, %r632, -2004318072;
	xor.b32  	%r25, %r633, -2004318072;
	xor.b32  	%r26, %r634, -2004318072;
	xor.b32  	%r27, %r635, -2004318072;
LBB0_12:                                // %L12928
	ld.param.u64 	%rd4, [_Z15julia_frb_1059013CuDeviceArrayI5Int32Li1ELi1EES_I9Float16x2Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_IS0_Li1ELi1EES_IS2_Li1ELi1EES_IS2_Li1ELi1EES_IS1_Li1ELi1EE_param_4];
	// begin inline asm
	cvt.rn.f16x2.f32 %r130, %r132, %r131;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r133, %r135, %r132;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r136, %r138, %r137;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r139, %r141, %r140;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r142, %r144, %r143;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r145, %r147, %r146;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r148, %r150, %r149;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r151, %r144, %r143;
	// end inline asm
	bar.sync 	0;
	shr.u32 	%r28, %r4, 8;
	shr.u32 	%r29, %r5, 8;
	shr.u32 	%r30, %r6, 8;
	shr.u32 	%r31, %r7, 8;
	shr.u32 	%r32, %r8, 8;
	shr.u32 	%r33, %r9, 8;
	shr.u32 	%r34, %r10, 8;
	shr.u32 	%r35, %r11, 8;
	shr.u32 	%r36, %r12, 8;
	shr.u32 	%r37, %r13, 8;
	shr.u32 	%r38, %r14, 8;
	shr.u32 	%r39, %r15, 8;
	shr.u32 	%r40, %r16, 8;
	shr.u32 	%r41, %r17, 8;
	shr.u32 	%r42, %r18, 8;
	shr.u32 	%r43, %r19, 8;
	shr.u32 	%r44, %r20, 8;
	shr.u32 	%r45, %r21, 8;
	shr.u32 	%r46, %r22, 8;
	shr.u32 	%r47, %r23, 8;
	shr.u32 	%r48, %r24, 8;
	shr.u32 	%r49, %r25, 8;
	shr.u32 	%r50, %r26, 8;
	shr.u32 	%r51, %r27, 8;
	mul.lo.s32 	%r52, %r96, 6;
	add.s32 	%r640, %r3, %r52;
	bfe.u32 	%r641, %r1, 3, 1;
	mul.lo.s32 	%r53, %r641, 514;
	add.s32 	%r642, %r640, %r53;
	and.b32  	%r643, %r1, 1;
	mul.lo.s32 	%r54, %r643, 4112;
	add.s32 	%r644, %r642, %r54;
	bfe.u32 	%r645, %r1, 1, 1;
	mul.lo.s32 	%r55, %r645, 2056;
	add.s32 	%r646, %r644, %r55;
	and.b32  	%r647, %r77, 1;
	mul.lo.s32 	%r56, %r647, 1028;
	add.s32 	%r648, %r646, %r56;
	mul.lo.s32 	%r57, %r94, 257;
	add.s32 	%r649, %r648, %r57;
	cvt.u64.u32 	%rd12, %r649;
	and.b32  	%r650, %r95, 1;
	and.b32  	%r651, %r74, 1;
	bfe.u32 	%r652, %r74, 1, 1;
	bfe.u32 	%r653, %r74, 2, 1;
	shr.u32 	%r654, %r74, 4;
	cvt.u16.u32 	%rs55, %r74;
	shl.b16 	%rs56, %rs55, 1;
	and.b16  	%rs57, %rs56, 254;
	mul.lo.s16 	%rs58, %rs57, 171;
	shr.u16 	%rs59, %rs58, 13;
	mul.lo.s16 	%rs60, %rs59, 48;
	sub.s16 	%rs61, %rs56, %rs60;
	and.b16  	%rs62, %rs61, 254;
	mul.wide.u16 	%r58, %rs62, 24;
	or.b16  	%rs63, %rs56, 1;
	and.b16  	%rs64, %rs63, 255;
	mul.lo.s16 	%rs65, %rs64, 171;
	shr.u16 	%rs66, %rs65, 13;
	mul.lo.s16 	%rs67, %rs66, 48;
	sub.s16 	%rs68, %rs63, %rs67;
	and.b16  	%rs69, %rs68, 255;
	mul.wide.u16 	%r59, %rs69, 24;
	add.s32 	%r655, %r649, 64;
	cvt.u64.u32 	%rd13, %r655;
	add.s32 	%r656, %r649, 8320;
	cvt.u64.u32 	%rd14, %r656;
	add.s32 	%r657, %r649, 96;
	cvt.u64.u32 	%rd15, %r657;
	add.s32 	%r658, %r649, 8352;
	cvt.u64.u32 	%rd16, %r658;
	add.s32 	%r659, %r649, 128;
	cvt.u64.u32 	%rd17, %r659;
	add.s32 	%r660, %r649, 8384;
	cvt.u64.u32 	%rd18, %r660;
	add.s32 	%r661, %r649, 160;
	cvt.u64.u32 	%rd19, %r661;
	add.s32 	%r662, %r649, 8416;
	cvt.u64.u32 	%rd20, %r662;
	add.s32 	%r663, %r649, 192;
	cvt.u64.u32 	%rd21, %r663;
	add.s32 	%r664, %r649, 8448;
	cvt.u64.u32 	%rd22, %r664;
	add.s32 	%r665, %r649, 224;
	cvt.u64.u32 	%rd23, %r665;
	add.s32 	%r666, %r649, 8480;
	cvt.u64.u32 	%rd24, %r666;
	mad.lo.s32 	%r667, %r651, 4112, %r2391;
	mad.lo.s32 	%r668, %r652, 2056, %r667;
	mad.lo.s32 	%r669, %r653, 1028, %r668;
	mad.lo.s32 	%r670, %r650, 514, %r669;
	mad.lo.s32 	%r671, %r654, 257, %r670;
	add.s32 	%r672, %r671, 8289;
	mul.wide.u32 	%rd210, %r672, 4;
	add.s64 	%rd211, %rd210, %rd10;
	add.s64 	%rd25, %rd211, -4;
	add.s32 	%r673, %r671, 33;
	mul.wide.u32 	%rd212, %r673, 4;
	add.s64 	%rd213, %rd212, %rd10;
	add.s64 	%rd26, %rd213, -4;
	add.s32 	%r674, %r671, 8257;
	mul.wide.u32 	%rd214, %r674, 4;
	add.s64 	%rd215, %rd214, %rd10;
	add.s64 	%rd27, %rd215, -4;
	add.s32 	%r675, %r671, 1;
	mul.wide.u32 	%rd216, %r675, 4;
	add.s64 	%rd217, %rd216, %rd10;
	add.s64 	%rd28, %rd217, -4;
	mov.u32 	%r639, 0;
	mov.u16 	%rs347, 25600;
	mov.u16 	%rs349, 21504;
	shl.b64 	%rd219, %rd12, 2;
	add.s64 	%rd220, %rd10, %rd219;
	shl.b64 	%rd236, %rd13, 2;
	add.s64 	%rd237, %rd10, %rd236;
	shl.b64 	%rd238, %rd14, 2;
	add.s64 	%rd239, %rd10, %rd238;
	shl.b64 	%rd240, %rd15, 2;
	add.s64 	%rd241, %rd10, %rd240;
	shl.b64 	%rd242, %rd16, 2;
	add.s64 	%rd243, %rd10, %rd242;
	shl.b64 	%rd244, %rd17, 2;
	add.s64 	%rd245, %rd10, %rd244;
	shl.b64 	%rd246, %rd18, 2;
	add.s64 	%rd247, %rd10, %rd246;
	shl.b64 	%rd248, %rd19, 2;
	add.s64 	%rd249, %rd10, %rd248;
	shl.b64 	%rd250, %rd20, 2;
	add.s64 	%rd251, %rd10, %rd250;
	shl.b64 	%rd252, %rd21, 2;
	add.s64 	%rd253, %rd10, %rd252;
	shl.b64 	%rd254, %rd22, 2;
	add.s64 	%rd255, %rd10, %rd254;
	shl.b64 	%rd256, %rd23, 2;
	add.s64 	%rd257, %rd10, %rd256;
	shl.b64 	%rd258, %rd24, 2;
	add.s64 	%rd259, %rd10, %rd258;
	mov.u32 	%r62, %r639;
	mov.u32 	%r61, %r639;
	bra.uni 	LBB0_13;
LBB0_17:                                // %L21981
                                        //   in Loop: Header=BB0_13 Depth=1
	bar.sync 	0;
	add.s32 	%r61, %r61, 4;
	@%p56 bra 	LBB0_18;
LBB0_13:                                // %L12954
                                        // =>This Loop Header: Depth=1
                                        //     Child Loop BB0_14 Depth 2
	// begin inline asm
	mov.b32 %r681, {%rs347, %rs347};
	// end inline asm
	// begin inline asm
	mov.b32 %r692, {%rs349, %rs349};
	// end inline asm
	mov.u32 	%r679, 983055;
	// begin inline asm
	lop3.b32 %r687, %r679, %r4, %r681, 202;
	// end inline asm
	mov.u16 	%rs74, 18432;
	// begin inline asm
	mov.b32 %r685, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r688, %r681, %r685;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r686, %r687, %r688;
	// end inline asm
	mov.u32 	%r690, 15728880;
	// begin inline asm
	lop3.b32 %r698, %r690, %r4, %r692, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r696, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r699, %r692, %r696;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r697, %r698, %r699;
	// end inline asm
	// begin inline asm
	lop3.b32 %r709, %r679, %r28, %r681, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r707, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r710, %r681, %r707;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r708, %r709, %r710;
	// end inline asm
	// begin inline asm
	lop3.b32 %r720, %r690, %r28, %r692, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r718, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r721, %r692, %r718;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r719, %r720, %r721;
	// end inline asm
	// begin inline asm
	mov.b32 %r727, {%rs347, %rs347};
	// end inline asm
	// begin inline asm
	mov.b32 %r738, {%rs349, %rs349};
	// end inline asm
	// begin inline asm
	lop3.b32 %r733, %r679, %r5, %r727, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r731, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r734, %r727, %r731;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r732, %r733, %r734;
	// end inline asm
	// begin inline asm
	lop3.b32 %r744, %r690, %r5, %r738, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r742, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r745, %r738, %r742;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r743, %r744, %r745;
	// end inline asm
	// begin inline asm
	lop3.b32 %r755, %r679, %r29, %r727, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r753, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r756, %r727, %r753;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r754, %r755, %r756;
	// end inline asm
	// begin inline asm
	lop3.b32 %r766, %r690, %r29, %r738, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r764, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r767, %r738, %r764;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r765, %r766, %r767;
	// end inline asm
	// begin inline asm
	mov.b32 %r773, {%rs347, %rs347};
	// end inline asm
	// begin inline asm
	mov.b32 %r784, {%rs349, %rs349};
	// end inline asm
	// begin inline asm
	lop3.b32 %r779, %r679, %r6, %r773, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r777, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r780, %r773, %r777;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r778, %r779, %r780;
	// end inline asm
	// begin inline asm
	lop3.b32 %r790, %r690, %r6, %r784, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r788, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r791, %r784, %r788;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r789, %r790, %r791;
	// end inline asm
	// begin inline asm
	lop3.b32 %r801, %r679, %r30, %r773, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r799, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r802, %r773, %r799;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r800, %r801, %r802;
	// end inline asm
	// begin inline asm
	lop3.b32 %r812, %r690, %r30, %r784, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r810, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r813, %r784, %r810;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r811, %r812, %r813;
	// end inline asm
	// begin inline asm
	mov.b32 %r819, {%rs347, %rs347};
	// end inline asm
	// begin inline asm
	mov.b32 %r830, {%rs349, %rs349};
	// end inline asm
	// begin inline asm
	lop3.b32 %r825, %r679, %r7, %r819, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r823, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r826, %r819, %r823;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r824, %r825, %r826;
	// end inline asm
	// begin inline asm
	lop3.b32 %r836, %r690, %r7, %r830, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r834, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r837, %r830, %r834;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r835, %r836, %r837;
	// end inline asm
	// begin inline asm
	lop3.b32 %r847, %r679, %r31, %r819, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r845, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r848, %r819, %r845;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r846, %r847, %r848;
	// end inline asm
	// begin inline asm
	lop3.b32 %r858, %r690, %r31, %r830, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r856, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r859, %r830, %r856;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r857, %r858, %r859;
	// end inline asm
	// begin inline asm
	mov.b32 %r865, {%rs347, %rs347};
	// end inline asm
	// begin inline asm
	mov.b32 %r876, {%rs349, %rs349};
	// end inline asm
	// begin inline asm
	lop3.b32 %r871, %r679, %r8, %r865, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r869, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r872, %r865, %r869;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r870, %r871, %r872;
	// end inline asm
	// begin inline asm
	lop3.b32 %r882, %r690, %r8, %r876, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r880, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r883, %r876, %r880;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r881, %r882, %r883;
	// end inline asm
	// begin inline asm
	lop3.b32 %r893, %r679, %r32, %r865, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r891, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r894, %r865, %r891;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r892, %r893, %r894;
	// end inline asm
	// begin inline asm
	lop3.b32 %r904, %r690, %r32, %r876, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r902, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r905, %r876, %r902;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r903, %r904, %r905;
	// end inline asm
	// begin inline asm
	mov.b32 %r911, {%rs347, %rs347};
	// end inline asm
	// begin inline asm
	mov.b32 %r922, {%rs349, %rs349};
	// end inline asm
	// begin inline asm
	lop3.b32 %r917, %r679, %r9, %r911, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r915, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r918, %r911, %r915;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r916, %r917, %r918;
	// end inline asm
	// begin inline asm
	lop3.b32 %r928, %r690, %r9, %r922, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r926, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r929, %r922, %r926;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r927, %r928, %r929;
	// end inline asm
	// begin inline asm
	lop3.b32 %r939, %r679, %r33, %r911, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r937, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r940, %r911, %r937;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r938, %r939, %r940;
	// end inline asm
	// begin inline asm
	lop3.b32 %r950, %r690, %r33, %r922, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r948, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r951, %r922, %r948;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r949, %r950, %r951;
	// end inline asm
	// begin inline asm
	mov.b32 %r957, {%rs347, %rs347};
	// end inline asm
	// begin inline asm
	mov.b32 %r968, {%rs349, %rs349};
	// end inline asm
	// begin inline asm
	lop3.b32 %r963, %r679, %r10, %r957, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r961, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r964, %r957, %r961;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r962, %r963, %r964;
	// end inline asm
	// begin inline asm
	lop3.b32 %r974, %r690, %r10, %r968, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r972, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r975, %r968, %r972;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r973, %r974, %r975;
	// end inline asm
	// begin inline asm
	lop3.b32 %r985, %r679, %r34, %r957, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r983, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r986, %r957, %r983;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r984, %r985, %r986;
	// end inline asm
	// begin inline asm
	lop3.b32 %r996, %r690, %r34, %r968, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r994, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r997, %r968, %r994;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r995, %r996, %r997;
	// end inline asm
	// begin inline asm
	mov.b32 %r1003, {%rs347, %rs347};
	// end inline asm
	// begin inline asm
	mov.b32 %r1014, {%rs349, %rs349};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1009, %r679, %r11, %r1003, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1007, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1010, %r1003, %r1007;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1008, %r1009, %r1010;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1020, %r690, %r11, %r1014, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1018, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1021, %r1014, %r1018;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1019, %r1020, %r1021;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1031, %r679, %r35, %r1003, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1029, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1032, %r1003, %r1029;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1030, %r1031, %r1032;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1042, %r690, %r35, %r1014, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1040, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1043, %r1014, %r1040;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1041, %r1042, %r1043;
	// end inline asm
	// begin inline asm
	mov.b32 %r1049, {%rs347, %rs347};
	// end inline asm
	// begin inline asm
	mov.b32 %r1060, {%rs349, %rs349};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1055, %r679, %r12, %r1049, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1053, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1056, %r1049, %r1053;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1054, %r1055, %r1056;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1066, %r690, %r12, %r1060, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1064, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1067, %r1060, %r1064;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1065, %r1066, %r1067;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1077, %r679, %r36, %r1049, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1075, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1078, %r1049, %r1075;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1076, %r1077, %r1078;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1088, %r690, %r36, %r1060, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1086, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1089, %r1060, %r1086;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1087, %r1088, %r1089;
	// end inline asm
	// begin inline asm
	mov.b32 %r1095, {%rs347, %rs347};
	// end inline asm
	// begin inline asm
	mov.b32 %r1106, {%rs349, %rs349};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1101, %r679, %r13, %r1095, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1099, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1102, %r1095, %r1099;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1100, %r1101, %r1102;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1112, %r690, %r13, %r1106, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1110, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1113, %r1106, %r1110;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1111, %r1112, %r1113;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1123, %r679, %r37, %r1095, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1121, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1124, %r1095, %r1121;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1122, %r1123, %r1124;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1134, %r690, %r37, %r1106, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1132, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1135, %r1106, %r1132;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1133, %r1134, %r1135;
	// end inline asm
	// begin inline asm
	mov.b32 %r1141, {%rs347, %rs347};
	// end inline asm
	// begin inline asm
	mov.b32 %r1152, {%rs349, %rs349};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1147, %r679, %r14, %r1141, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1145, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1148, %r1141, %r1145;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1146, %r1147, %r1148;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1158, %r690, %r14, %r1152, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1156, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1159, %r1152, %r1156;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1157, %r1158, %r1159;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1169, %r679, %r38, %r1141, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1167, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1170, %r1141, %r1167;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1168, %r1169, %r1170;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1180, %r690, %r38, %r1152, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1178, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1181, %r1152, %r1178;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1179, %r1180, %r1181;
	// end inline asm
	// begin inline asm
	mov.b32 %r1187, {%rs347, %rs347};
	// end inline asm
	// begin inline asm
	mov.b32 %r1198, {%rs349, %rs349};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1193, %r679, %r15, %r1187, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1191, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1194, %r1187, %r1191;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1192, %r1193, %r1194;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1204, %r690, %r15, %r1198, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1202, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1205, %r1198, %r1202;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1203, %r1204, %r1205;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1215, %r679, %r39, %r1187, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1213, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1216, %r1187, %r1213;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1214, %r1215, %r1216;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1226, %r690, %r39, %r1198, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1224, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1227, %r1198, %r1224;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1225, %r1226, %r1227;
	// end inline asm
	// begin inline asm
	mov.b32 %r1233, {%rs347, %rs347};
	// end inline asm
	// begin inline asm
	mov.b32 %r1244, {%rs349, %rs349};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1239, %r679, %r16, %r1233, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1237, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1240, %r1233, %r1237;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1238, %r1239, %r1240;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1250, %r690, %r16, %r1244, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1248, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1251, %r1244, %r1248;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1249, %r1250, %r1251;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1261, %r679, %r40, %r1233, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1259, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1262, %r1233, %r1259;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1260, %r1261, %r1262;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1272, %r690, %r40, %r1244, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1270, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1273, %r1244, %r1270;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1271, %r1272, %r1273;
	// end inline asm
	// begin inline asm
	mov.b32 %r1279, {%rs347, %rs347};
	// end inline asm
	// begin inline asm
	mov.b32 %r1290, {%rs349, %rs349};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1285, %r679, %r17, %r1279, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1283, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1286, %r1279, %r1283;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1284, %r1285, %r1286;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1296, %r690, %r17, %r1290, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1294, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1297, %r1290, %r1294;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1295, %r1296, %r1297;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1307, %r679, %r41, %r1279, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1305, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1308, %r1279, %r1305;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1306, %r1307, %r1308;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1318, %r690, %r41, %r1290, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1316, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1319, %r1290, %r1316;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1317, %r1318, %r1319;
	// end inline asm
	// begin inline asm
	mov.b32 %r1325, {%rs347, %rs347};
	// end inline asm
	// begin inline asm
	mov.b32 %r1336, {%rs349, %rs349};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1331, %r679, %r18, %r1325, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1329, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1332, %r1325, %r1329;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1330, %r1331, %r1332;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1342, %r690, %r18, %r1336, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1340, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1343, %r1336, %r1340;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1341, %r1342, %r1343;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1353, %r679, %r42, %r1325, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1351, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1354, %r1325, %r1351;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1352, %r1353, %r1354;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1364, %r690, %r42, %r1336, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1362, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1365, %r1336, %r1362;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1363, %r1364, %r1365;
	// end inline asm
	// begin inline asm
	mov.b32 %r1371, {%rs347, %rs347};
	// end inline asm
	// begin inline asm
	mov.b32 %r1382, {%rs349, %rs349};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1377, %r679, %r19, %r1371, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1375, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1378, %r1371, %r1375;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1376, %r1377, %r1378;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1388, %r690, %r19, %r1382, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1386, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1389, %r1382, %r1386;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1387, %r1388, %r1389;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1399, %r679, %r43, %r1371, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1397, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1400, %r1371, %r1397;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1398, %r1399, %r1400;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1410, %r690, %r43, %r1382, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1408, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1411, %r1382, %r1408;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1409, %r1410, %r1411;
	// end inline asm
	// begin inline asm
	mov.b32 %r1417, {%rs347, %rs347};
	// end inline asm
	// begin inline asm
	mov.b32 %r1428, {%rs349, %rs349};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1423, %r679, %r20, %r1417, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1421, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1424, %r1417, %r1421;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1422, %r1423, %r1424;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1434, %r690, %r20, %r1428, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1432, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1435, %r1428, %r1432;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1433, %r1434, %r1435;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1445, %r679, %r44, %r1417, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1443, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1446, %r1417, %r1443;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1444, %r1445, %r1446;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1456, %r690, %r44, %r1428, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1454, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1457, %r1428, %r1454;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1455, %r1456, %r1457;
	// end inline asm
	// begin inline asm
	mov.b32 %r1463, {%rs347, %rs347};
	// end inline asm
	// begin inline asm
	mov.b32 %r1474, {%rs349, %rs349};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1469, %r679, %r21, %r1463, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1467, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1470, %r1463, %r1467;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1468, %r1469, %r1470;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1480, %r690, %r21, %r1474, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1478, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1481, %r1474, %r1478;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1479, %r1480, %r1481;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1491, %r679, %r45, %r1463, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1489, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1492, %r1463, %r1489;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1490, %r1491, %r1492;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1502, %r690, %r45, %r1474, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1500, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1503, %r1474, %r1500;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1501, %r1502, %r1503;
	// end inline asm
	// begin inline asm
	mov.b32 %r1509, {%rs347, %rs347};
	// end inline asm
	// begin inline asm
	mov.b32 %r1520, {%rs349, %rs349};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1515, %r679, %r22, %r1509, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1513, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1516, %r1509, %r1513;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1514, %r1515, %r1516;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1526, %r690, %r22, %r1520, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1524, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1527, %r1520, %r1524;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1525, %r1526, %r1527;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1537, %r679, %r46, %r1509, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1535, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1538, %r1509, %r1535;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1536, %r1537, %r1538;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1548, %r690, %r46, %r1520, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1546, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1549, %r1520, %r1546;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1547, %r1548, %r1549;
	// end inline asm
	// begin inline asm
	mov.b32 %r1555, {%rs347, %rs347};
	// end inline asm
	// begin inline asm
	mov.b32 %r1566, {%rs349, %rs349};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1561, %r679, %r23, %r1555, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1559, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1562, %r1555, %r1559;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1560, %r1561, %r1562;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1572, %r690, %r23, %r1566, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1570, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1573, %r1566, %r1570;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1571, %r1572, %r1573;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1583, %r679, %r47, %r1555, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1581, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1584, %r1555, %r1581;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1582, %r1583, %r1584;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1594, %r690, %r47, %r1566, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1592, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1595, %r1566, %r1592;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1593, %r1594, %r1595;
	// end inline asm
	// begin inline asm
	mov.b32 %r1601, {%rs347, %rs347};
	// end inline asm
	// begin inline asm
	mov.b32 %r1612, {%rs349, %rs349};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1607, %r679, %r24, %r1601, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1605, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1608, %r1601, %r1605;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1606, %r1607, %r1608;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1618, %r690, %r24, %r1612, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1616, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1619, %r1612, %r1616;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1617, %r1618, %r1619;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1629, %r679, %r48, %r1601, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1627, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1630, %r1601, %r1627;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1628, %r1629, %r1630;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1640, %r690, %r48, %r1612, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1638, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1641, %r1612, %r1638;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1639, %r1640, %r1641;
	// end inline asm
	// begin inline asm
	mov.b32 %r1647, {%rs347, %rs347};
	// end inline asm
	// begin inline asm
	mov.b32 %r1658, {%rs349, %rs349};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1653, %r679, %r25, %r1647, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1651, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1654, %r1647, %r1651;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1652, %r1653, %r1654;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1664, %r690, %r25, %r1658, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1662, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1665, %r1658, %r1662;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1663, %r1664, %r1665;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1675, %r679, %r49, %r1647, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1673, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1676, %r1647, %r1673;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1674, %r1675, %r1676;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1686, %r690, %r49, %r1658, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1684, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1687, %r1658, %r1684;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1685, %r1686, %r1687;
	// end inline asm
	// begin inline asm
	mov.b32 %r1693, {%rs347, %rs347};
	// end inline asm
	// begin inline asm
	mov.b32 %r1704, {%rs349, %rs349};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1699, %r679, %r26, %r1693, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1697, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1700, %r1693, %r1697;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1698, %r1699, %r1700;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1710, %r690, %r26, %r1704, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1708, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1711, %r1704, %r1708;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1709, %r1710, %r1711;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1721, %r679, %r50, %r1693, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1719, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1722, %r1693, %r1719;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1720, %r1721, %r1722;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1732, %r690, %r50, %r1704, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1730, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1733, %r1704, %r1730;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1731, %r1732, %r1733;
	// end inline asm
	// begin inline asm
	mov.b32 %r1739, {%rs347, %rs347};
	// end inline asm
	// begin inline asm
	mov.b32 %r1750, {%rs349, %rs349};
	// end inline asm
	// begin inline asm
	lop3.b32 %r1745, %r679, %r27, %r1739, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1743, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1746, %r1739, %r1743;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1744, %r1745, %r1746;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1756, %r690, %r27, %r1750, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1754, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1757, %r1750, %r1754;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1755, %r1756, %r1757;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1767, %r679, %r51, %r1739, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1765, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1768, %r1739, %r1765;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1766, %r1767, %r1768;
	// end inline asm
	// begin inline asm
	lop3.b32 %r1778, %r690, %r51, %r1750, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r1776, {%rs74, %rs74};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r1779, %r1750, %r1776;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r1777, %r1778, %r1779;
	// end inline asm
	setp.eq.s32 	%p45, %r61, 0;
	selp.b32 	%r2132, %r686, 0, %p45;
	setp.eq.s32 	%p46, %r61, 4;
	selp.b32 	%r2133, %r870, %r2132, %p46;
	setp.eq.s32 	%p47, %r61, 8;
	selp.b32 	%r2134, %r1054, %r2133, %p47;
	setp.eq.s32 	%p48, %r61, 12;
	selp.b32 	%r2135, %r1238, %r2134, %p48;
	setp.eq.s32 	%p49, %r61, 16;
	selp.b32 	%r2136, %r1422, %r2135, %p49;
	setp.eq.s32 	%p50, %r61, 20;
	selp.b32 	%r2137, %r1606, %r2136, %p50;
	setp.eq.s32 	%p51, %r61, 24;
	selp.b32 	%r2138, %r708, %r2137, %p51;
	setp.eq.s32 	%p52, %r61, 28;
	selp.b32 	%r2139, %r892, %r2138, %p52;
	setp.eq.s32 	%p53, %r61, 32;
	selp.b32 	%r2140, %r1076, %r2139, %p53;
	setp.eq.s32 	%p54, %r61, 36;
	selp.b32 	%r2141, %r1260, %r2140, %p54;
	setp.eq.s32 	%p55, %r61, 40;
	selp.b32 	%r2142, %r1444, %r2141, %p55;
	setp.eq.s32 	%p56, %r61, 44;
	selp.b32 	%r1782, %r1628, %r2142, %p56;
	selp.b32 	%r2143, %r697, 0, %p45;
	selp.b32 	%r2144, %r881, %r2143, %p46;
	selp.b32 	%r2145, %r1065, %r2144, %p47;
	selp.b32 	%r2146, %r1249, %r2145, %p48;
	selp.b32 	%r2147, %r1433, %r2146, %p49;
	selp.b32 	%r2148, %r1617, %r2147, %p50;
	selp.b32 	%r2149, %r719, %r2148, %p51;
	selp.b32 	%r2150, %r903, %r2149, %p52;
	selp.b32 	%r2151, %r1087, %r2150, %p53;
	selp.b32 	%r2152, %r1271, %r2151, %p54;
	selp.b32 	%r2153, %r1455, %r2152, %p55;
	selp.b32 	%r1785, %r1639, %r2153, %p56;
	selp.b32 	%r2154, %r732, 0, %p45;
	selp.b32 	%r2155, %r916, %r2154, %p46;
	selp.b32 	%r2156, %r1100, %r2155, %p47;
	selp.b32 	%r2157, %r1284, %r2156, %p48;
	selp.b32 	%r2158, %r1468, %r2157, %p49;
	selp.b32 	%r2159, %r1652, %r2158, %p50;
	selp.b32 	%r2160, %r754, %r2159, %p51;
	selp.b32 	%r2161, %r938, %r2160, %p52;
	selp.b32 	%r2162, %r1122, %r2161, %p53;
	selp.b32 	%r2163, %r1306, %r2162, %p54;
	selp.b32 	%r2164, %r1490, %r2163, %p55;
	selp.b32 	%r1788, %r1674, %r2164, %p56;
	selp.b32 	%r2165, %r743, 0, %p45;
	selp.b32 	%r2166, %r927, %r2165, %p46;
	selp.b32 	%r2167, %r1111, %r2166, %p47;
	selp.b32 	%r2168, %r1295, %r2167, %p48;
	selp.b32 	%r2169, %r1479, %r2168, %p49;
	selp.b32 	%r2170, %r1663, %r2169, %p50;
	selp.b32 	%r2171, %r765, %r2170, %p51;
	selp.b32 	%r2172, %r949, %r2171, %p52;
	selp.b32 	%r2173, %r1133, %r2172, %p53;
	selp.b32 	%r2174, %r1317, %r2173, %p54;
	selp.b32 	%r2175, %r1501, %r2174, %p55;
	selp.b32 	%r1791, %r1685, %r2175, %p56;
	selp.b32 	%r2176, %r778, 0, %p45;
	selp.b32 	%r2177, %r962, %r2176, %p46;
	selp.b32 	%r2178, %r1146, %r2177, %p47;
	selp.b32 	%r2179, %r1330, %r2178, %p48;
	selp.b32 	%r2180, %r1514, %r2179, %p49;
	selp.b32 	%r2181, %r1698, %r2180, %p50;
	selp.b32 	%r2182, %r800, %r2181, %p51;
	selp.b32 	%r2183, %r984, %r2182, %p52;
	selp.b32 	%r2184, %r1168, %r2183, %p53;
	selp.b32 	%r2185, %r1352, %r2184, %p54;
	selp.b32 	%r2186, %r1536, %r2185, %p55;
	selp.b32 	%r1794, %r1720, %r2186, %p56;
	selp.b32 	%r2187, %r789, 0, %p45;
	selp.b32 	%r2188, %r973, %r2187, %p46;
	selp.b32 	%r2189, %r1157, %r2188, %p47;
	selp.b32 	%r2190, %r1341, %r2189, %p48;
	selp.b32 	%r2191, %r1525, %r2190, %p49;
	selp.b32 	%r2192, %r1709, %r2191, %p50;
	selp.b32 	%r2193, %r811, %r2192, %p51;
	selp.b32 	%r2194, %r995, %r2193, %p52;
	selp.b32 	%r2195, %r1179, %r2194, %p53;
	selp.b32 	%r2196, %r1363, %r2195, %p54;
	selp.b32 	%r2197, %r1547, %r2196, %p55;
	selp.b32 	%r1797, %r1731, %r2197, %p56;
	selp.b32 	%r2198, %r824, 0, %p45;
	selp.b32 	%r2199, %r1008, %r2198, %p46;
	selp.b32 	%r2200, %r1192, %r2199, %p47;
	selp.b32 	%r2201, %r1376, %r2200, %p48;
	selp.b32 	%r2202, %r1560, %r2201, %p49;
	selp.b32 	%r2203, %r1744, %r2202, %p50;
	selp.b32 	%r2204, %r846, %r2203, %p51;
	selp.b32 	%r2205, %r1030, %r2204, %p52;
	selp.b32 	%r2206, %r1214, %r2205, %p53;
	selp.b32 	%r2207, %r1398, %r2206, %p54;
	selp.b32 	%r2208, %r1582, %r2207, %p55;
	selp.b32 	%r1800, %r1766, %r2208, %p56;
	selp.b32 	%r2209, %r835, 0, %p45;
	selp.b32 	%r2210, %r1019, %r2209, %p46;
	selp.b32 	%r2211, %r1203, %r2210, %p47;
	selp.b32 	%r2212, %r1387, %r2211, %p48;
	selp.b32 	%r2213, %r1571, %r2212, %p49;
	selp.b32 	%r2214, %r1755, %r2213, %p50;
	selp.b32 	%r2215, %r857, %r2214, %p51;
	selp.b32 	%r2216, %r1041, %r2215, %p52;
	selp.b32 	%r2217, %r1225, %r2216, %p53;
	selp.b32 	%r2218, %r1409, %r2217, %p54;
	selp.b32 	%r2219, %r1593, %r2218, %p55;
	selp.b32 	%r1803, %r1777, %r2219, %p56;
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1im, %r1re}, %r92;
    mov.b32 {%r2im, %r2re}, %r1782;
    mul.f16 %retmp, %r1re, %r2re;
    mul.f16 %imtmp, %r1re, %r2im;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1808, {%r0im, %r0re};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1im, %r1re}, %r93;
    mov.b32 {%r2im, %r2re}, %r1785;
    mul.f16 %retmp, %r1re, %r2re;
    mul.f16 %imtmp, %r1re, %r2im;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1815, {%r0im, %r0re};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1im, %r1re}, %r92;
    mov.b32 {%r2im, %r2re}, %r1788;
    mul.f16 %retmp, %r1re, %r2re;
    mul.f16 %imtmp, %r1re, %r2im;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1822, {%r0im, %r0re};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1im, %r1re}, %r93;
    mov.b32 {%r2im, %r2re}, %r1791;
    mul.f16 %retmp, %r1re, %r2re;
    mul.f16 %imtmp, %r1re, %r2im;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1829, {%r0im, %r0re};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1im, %r1re}, %r92;
    mov.b32 {%r2im, %r2re}, %r1794;
    mul.f16 %retmp, %r1re, %r2re;
    mul.f16 %imtmp, %r1re, %r2im;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1836, {%r0im, %r0re};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1im, %r1re}, %r93;
    mov.b32 {%r2im, %r2re}, %r1797;
    mul.f16 %retmp, %r1re, %r2re;
    mul.f16 %imtmp, %r1re, %r2im;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1843, {%r0im, %r0re};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1im, %r1re}, %r92;
    mov.b32 {%r2im, %r2re}, %r1800;
    mul.f16 %retmp, %r1re, %r2re;
    mul.f16 %imtmp, %r1re, %r2im;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1850, {%r0im, %r0re};
}

	// end inline asm
	// begin inline asm
	{
    .reg .f16 %r1re, %r1im, %r2re, %r2im, %r1imneg, %retmp, %r0re, %imtmp, %r0im;
    mov.b32 {%r1im, %r1re}, %r93;
    mov.b32 {%r2im, %r2re}, %r1803;
    mul.f16 %retmp, %r1re, %r2re;
    mul.f16 %imtmp, %r1re, %r2im;
    neg.f16 %r1imneg, %r1im;
    fma.rn.f16 %r0re, %r1imneg, %r2im, %retmp;
    fma.rn.f16 %r0im, %r1im, %r2re, %imtmp;
    mov.b32 %r1857, {%r0im, %r0re};
}

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1864, %r1867}, {%r133, %r130}, {%r1808}, {%r639, %r639};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1873, %r1876}, {%r133, %r130}, {%r1815}, {%r639, %r639};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1882, %r1885}, {%r133, %r130}, {%r1822}, {%r639, %r639};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1891, %r1894}, {%r133, %r130}, {%r1829}, {%r639, %r639};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1900, %r1903}, {%r133, %r130}, {%r1836}, {%r639, %r639};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1909, %r1912}, {%r133, %r130}, {%r1843}, {%r639, %r639};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1918, %r1921}, {%r133, %r130}, {%r1850}, {%r639, %r639};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r1927, %r1930}, {%r133, %r130}, {%r1857}, {%r639, %r639};
	// end inline asm
	// begin inline asm
	neg.f16x2 %r1863, %r139;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1868, %r1863, %r1864;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r1995, %r136, %r1867, %r1868;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r1872, %r139;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1877, %r1872, %r1873;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2005, %r136, %r1876, %r1877;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r1881, %r139;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1886, %r1881, %r1882;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2015, %r136, %r1885, %r1886;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r1890, %r139;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1895, %r1890, %r1891;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2025, %r136, %r1894, %r1895;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r1899, %r139;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1904, %r1899, %r1900;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2035, %r136, %r1903, %r1904;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r1908, %r139;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1913, %r1908, %r1909;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2045, %r136, %r1912, %r1913;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r1917, %r139;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1922, %r1917, %r1918;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2055, %r136, %r1921, %r1922;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r1926, %r139;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1931, %r1926, %r1927;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2065, %r136, %r1930, %r1931;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1938, %r139, %r1867;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r1994, %r136, %r1864, %r1938;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1945, %r139, %r1876;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2004, %r136, %r1873, %r1945;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1952, %r139, %r1885;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2014, %r136, %r1882, %r1952;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1959, %r139, %r1894;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2024, %r136, %r1891, %r1959;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1966, %r139, %r1903;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2034, %r136, %r1900, %r1966;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1973, %r139, %r1912;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2044, %r136, %r1909, %r1973;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1980, %r139, %r1921;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2054, %r136, %r1918, %r1980;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r1987, %r139, %r1930;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2064, %r136, %r1927, %r1987;
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2069, %r2070}, {%r151, %r145, %r148, %r142}, {%r1994, %r1995}, {%r639, %r639};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2077, %r2078}, {%r151, %r145, %r148, %r142}, {%r2004, %r2005}, {%r639, %r639};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2085, %r2086}, {%r151, %r145, %r148, %r142}, {%r2014, %r2015}, {%r639, %r639};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2093, %r2094}, {%r151, %r145, %r148, %r142}, {%r2024, %r2025}, {%r639, %r639};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2101, %r2102}, {%r151, %r145, %r148, %r142}, {%r2034, %r2035}, {%r639, %r639};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2109, %r2110}, {%r151, %r145, %r148, %r142}, {%r2044, %r2045}, {%r639, %r639};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2117, %r2118}, {%r151, %r145, %r148, %r142}, {%r2054, %r2055}, {%r639, %r639};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2125, %r2126}, {%r151, %r145, %r148, %r142}, {%r2064, %r2065}, {%r639, %r639};
	// end inline asm
	// begin inline asm
	prmt.b32 %r2068, %r2069, %r2070, %r405;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2072, %r2069, %r2070, %r409;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2076, %r2077, %r2078, %r405;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2080, %r2077, %r2078, %r409;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2084, %r2085, %r2086, %r405;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2088, %r2085, %r2086, %r409;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2092, %r2093, %r2094, %r405;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2096, %r2093, %r2094, %r409;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2100, %r2101, %r2102, %r405;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2104, %r2101, %r2102, %r409;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2108, %r2109, %r2110, %r405;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2112, %r2109, %r2110, %r409;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2116, %r2117, %r2118, %r405;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2120, %r2117, %r2118, %r409;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2124, %r2125, %r2126, %r405;
	// end inline asm
	// begin inline asm
	prmt.b32 %r2128, %r2125, %r2126, %r409;
	// end inline asm
	st.global.u32 	[%rd220], %r2068;
	cvt.u64.u32 	%rd221, %r57;
	cvt.u64.u32 	%rd222, %r56;
	cvt.u64.u32 	%rd223, %r55;
	cvt.u64.u32 	%rd224, %r54;
	cvt.u64.u32 	%rd225, %r53;
	cvt.u64.u32 	%rd226, %r3;
	cvt.u64.u32 	%rd227, %r52;
	add.s64 	%rd228, %rd227, %rd226;
	add.s64 	%rd229, %rd228, %rd225;
	add.s64 	%rd230, %rd229, %rd224;
	add.s64 	%rd231, %rd230, %rd223;
	add.s64 	%rd232, %rd231, %rd222;
	add.s64 	%rd233, %rd232, %rd221;
	shl.b64 	%rd234, %rd233, 2;
	add.s64 	%rd235, %rd10, %rd234;
	st.global.u32 	[%rd235+33024], %r2072;
	st.global.u32 	[%rd235+128], %r2076;
	st.global.u32 	[%rd235+33152], %r2080;
	st.global.u32 	[%rd237], %r2084;
	st.global.u32 	[%rd239], %r2088;
	st.global.u32 	[%rd241], %r2092;
	st.global.u32 	[%rd243], %r2096;
	st.global.u32 	[%rd245], %r2100;
	st.global.u32 	[%rd247], %r2104;
	st.global.u32 	[%rd249], %r2108;
	st.global.u32 	[%rd251], %r2112;
	st.global.u32 	[%rd253], %r2116;
	st.global.u32 	[%rd255], %r2120;
	st.global.u32 	[%rd257], %r2124;
	st.global.u32 	[%rd259], %r2128;
	bar.sync 	0;
	mov.u64 	%rd29, 0;
	bra.uni 	LBB0_14;
LBB0_16:                                // %L21966
                                        //   in Loop: Header=BB0_14 Depth=2
	add.s32 	%r62, %r62, 1;
	add.s64 	%rd29, %rd29, 256;
	cvt.u32.u64 	%r2389, %rd29;
	setp.ne.s32 	%p60, %r2389, 1024;
	@%p60 bra 	LBB0_14;
	bra.uni 	LBB0_17;
LBB0_14:                                // %L19987
                                        //   Parent Loop BB0_13 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	mov.u32 	%r2220, 0;
	mov.u32 	%r2420, %r2220;
	mov.u32 	%r2421, %r2220;
	mov.u32 	%r2422, %r2220;
	mov.u32 	%r2423, %r2220;
	@%p43 bra 	LBB0_24;
	bra.uni 	LBB0_15;
LBB0_24:                                // %pass5601
                                        //   in Loop: Header=BB0_14 Depth=2
	add.s64 	%rd260, %rd28, %rd29;
	ld.global.u32 	%r2423, [%rd260];
	add.s64 	%rd261, %rd27, %rd29;
	ld.global.u32 	%r2422, [%rd261];
	add.s64 	%rd262, %rd26, %rd29;
	ld.global.u32 	%r2421, [%rd262];
	add.s64 	%rd263, %rd25, %rd29;
	ld.global.u32 	%r2420, [%rd263];
LBB0_15:                                // %L21297
                                        //   in Loop: Header=BB0_14 Depth=2
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2253, %r2256}, {%r133, %r130}, {%r2423}, {%r2220, %r2220};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2262, %r2265}, {%r133, %r130}, {%r2422}, {%r2220, %r2220};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2271, %r2274}, {%r133, %r130}, {%r2421}, {%r2220, %r2220};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 {%r2280, %r2283}, {%r133, %r130}, {%r2420}, {%r2220, %r2220};
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2249, %r139;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2251, %r2249, %r2253;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2254, %r136, %r2256, %r2251;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2258, %r139;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2260, %r2258, %r2262;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2263, %r136, %r2265, %r2260;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2267, %r139;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2269, %r2267, %r2271;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2272, %r136, %r2274, %r2269;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r2276, %r139;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2278, %r2276, %r2280;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2281, %r136, %r2283, %r2278;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2285, %r139, %r2256;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2288, %r136, %r2253, %r2285;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2292, %r139, %r2265;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2295, %r136, %r2262, %r2292;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2299, %r139, %r2274;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2302, %r136, %r2271, %r2299;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r2306, %r139, %r2283;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2309, %r136, %r2280, %r2306;
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2313, %r2314}, {%r151, %r145, %r148, %r142}, {%r2288, %r2254}, {%r2220, %r2220};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2323, %r2324}, {%r151, %r145, %r148, %r142}, {%r2295, %r2263}, {%r2220, %r2220};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2333, %r2334}, {%r151, %r145, %r148, %r142}, {%r2302, %r2272}, {%r2220, %r2220};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r2343, %r2344}, {%r151, %r145, %r148, %r142}, {%r2309, %r2281}, {%r2220, %r2220};
	// end inline asm
	@%p43 bra 	LBB0_25;
	bra.uni 	LBB0_16;
LBB0_25:                                // %oksrem6028
                                        //   in Loop: Header=BB0_14 Depth=2
	setp.gt.u32 	%p59, %r62, 47;
	@%p59 bra 	LBB0_27;
// %bb.26:                              // %oksrem6045
                                        //   in Loop: Header=BB0_14 Depth=2
	// begin inline asm
	fma.rn.f16x2 %r2353, %r2313, %r2313, %r2220;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2357, %r2314, %r2314, %r2353;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2361, %r2323, %r2323, %r2220;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2365, %r2324, %r2324, %r2361;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2369, %r2333, %r2333, %r2220;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2373, %r2334, %r2334, %r2369;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2377, %r2343, %r2343, %r2220;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r2381, %r2344, %r2344, %r2377;
	// end inline asm
	cvt.u16.u32 	%rs358, %r62;
	and.b16  	%rs359, %rs358, 255;
	mul.lo.s16 	%rs360, %rs359, 171;
	shr.u16 	%rs361, %rs360, 13;
	mul.lo.s16 	%rs362, %rs361, 48;
	sub.s16 	%rs363, %rs358, %rs362;
	and.b16  	%rs364, %rs363, 255;
	mul.wide.u16 	%r2385, %rs364, 2304;
	or.b32  	%r2386, %r2385, %r88;
	add.s32 	%r2387, %r2386, %r58;
	mul.wide.u32 	%rd264, %r2387, 4;
	add.s64 	%rd265, %rd4, %rd264;
	st.global.u32 	[%rd265], %r2357;
	add.s32 	%r2388, %r2386, %r59;
	mul.wide.u32 	%rd266, %r2388, 4;
	add.s64 	%rd267, %rd4, %rd266;
	st.global.u32 	[%rd267], %r2365;
	cvt.u64.u32 	%rd268, %r58;
	cvt.u64.u32 	%rd269, %r2385;
	or.b64  	%rd270, %rd269, %rd32;
	add.s64 	%rd271, %rd270, %rd268;
	shl.b64 	%rd272, %rd271, 2;
	add.s64 	%rd273, %rd4, %rd272;
	st.global.u32 	[%rd273+4608], %r2373;
	cvt.u64.u32 	%rd274, %r59;
	add.s64 	%rd275, %rd270, %rd274;
	shl.b64 	%rd276, %rd275, 2;
	add.s64 	%rd277, %rd4, %rd276;
	st.global.u32 	[%rd277+4608], %r2381;
	bra.uni 	LBB0_16;
LBB0_18:                                // %oksrem6198
	mov.u32 	%r2390, 0;
	st.global.u32 	[%rd31], %r2390;
	ret;
LBB0_27:                                // %L21616
	{ // callseq 21, 0
	.reg .b32 temp_param_reg;
	.param .align 8 .b8 param0[8];
	st.param.b64 	[param0+0], %rd33;
	call.uni 
	julia_unreachable_13471, 
	(
	param0
	);
	} // callseq 21
LBB0_1:                                 // %L22
	{ // callseq 17, 0
	.reg .b32 temp_param_reg;
	.param .align 8 .b8 param0[8];
	st.param.b64 	[param0+0], %rd33;
	call.uni 
	julia_unreachable_13471, 
	(
	param0
	);
	} // callseq 17
LBB0_3:                                 // %L60
	{ // callseq 18, 0
	.reg .b32 temp_param_reg;
	.param .align 8 .b8 param0[8];
	st.param.b64 	[param0+0], %rd33;
	call.uni 
	julia__throw_boundserror_13473, 
	(
	param0
	);
	} // callseq 18
LBB0_5:                                 // %L127
	{ // callseq 19, 0
	.reg .b32 temp_param_reg;
	.param .align 8 .b8 param0[8];
	st.param.b64 	[param0+0], %rd33;
	call.uni 
	julia__throw_boundserror_13473, 
	(
	param0
	);
	} // callseq 19
LBB0_7:                                 // %L194
	{ // callseq 20, 0
	.reg .b32 temp_param_reg;
	.param .align 8 .b8 param0[8];
	st.param.b64 	[param0+0], %rd33;
	call.uni 
	julia__throw_boundserror_13476, 
	(
	param0
	);
	} // callseq 20
LBB0_9:                                 // %L223
	{ // callseq 23, 0
	.reg .b32 temp_param_reg;
	.param .align 8 .b8 param0[8];
	st.param.b64 	[param0+0], %rd33;
	call.uni 
	julia_unreachable_13471, 
	(
	param0
	);
	} // callseq 23
LBB0_10:                                // %L248
	{ // callseq 22, 0
	.reg .b32 temp_param_reg;
	.param .align 8 .b8 param0[8];
	st.param.b64 	[param0+0], %rd33;
	call.uni 
	julia_unreachable_13471, 
	(
	param0
	);
	} // callseq 22
                                        // -- End function
}
