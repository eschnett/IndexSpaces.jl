// PTX CompilerJob of kernel #upchan(CuDeviceVector{Float16x2, 1}, CuDeviceVector{Float16x2, 1}, CuDeviceVector{Int4x8, 1}, CuDeviceVector{Int4x8, 1}, CuDeviceVector{Int32, 1}) for sm_86, minthreads=512, blocks_per_sm=2

//
// Generated by LLVM NVPTX Back-End
//

.version 7.1
.target sm_86
.address_size 64

	// .globl	_Z17julia_upchan_373313CuDeviceArrayI9Float16x2Li1ELi1EES_IS0_Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_I5Int32Li1ELi1EE // -- Begin function _Z17julia_upchan_373313CuDeviceArrayI9Float16x2Li1ELi1EES_IS0_Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_I5Int32Li1ELi1EE
.func gpu_report_exception
(
	.param .b64 gpu_report_exception_param_0
)
.noreturn
{
	trap;
}
.func gpu_signal_exception
(
	.param .align 8 .b8 gpu_signal_exception_param_0[8]
)
.noreturn
{
	trap;
}
.extern .shared .align 32 .b8 shmem[];
.global .align 1 .b8 exception11410[10] = {101, 120, 99, 101, 112, 116, 105, 111, 110, 0};
                                        // @_Z17julia_upchan_373313CuDeviceArrayI9Float16x2Li1ELi1EES_IS0_Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_I5Int32Li1ELi1EE
.visible .entry _Z17julia_upchan_373313CuDeviceArrayI9Float16x2Li1ELi1EES_IS0_Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_I5Int32Li1ELi1EE(
	.param .align 8 .b8 _Z17julia_upchan_373313CuDeviceArrayI9Float16x2Li1ELi1EES_IS0_Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_I5Int32Li1ELi1EE_param_0[8],
	.param .align 8 .b8 _Z17julia_upchan_373313CuDeviceArrayI9Float16x2Li1ELi1EES_IS0_Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_I5Int32Li1ELi1EE_param_1[32],
	.param .align 8 .b8 _Z17julia_upchan_373313CuDeviceArrayI9Float16x2Li1ELi1EES_IS0_Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_I5Int32Li1ELi1EE_param_2[32],
	.param .align 8 .b8 _Z17julia_upchan_373313CuDeviceArrayI9Float16x2Li1ELi1EES_IS0_Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_I5Int32Li1ELi1EE_param_3[32],
	.param .align 8 .b8 _Z17julia_upchan_373313CuDeviceArrayI9Float16x2Li1ELi1EES_IS0_Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_I5Int32Li1ELi1EE_param_4[32],
	.param .align 8 .b8 _Z17julia_upchan_373313CuDeviceArrayI9Float16x2Li1ELi1EES_IS0_Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_I5Int32Li1ELi1EE_param_5[32]
)
.reqntid 512, 1, 1
.minnctapersm 2
{
	.reg .pred 	%p<167>;
	.reg .b16 	%rs<93>;
	.reg .b32 	%r<1039>;
	.reg .f32 	%f<613>;
	.reg .b64 	%rd<95>;

// %bb.0:                               // %conversion
	// begin inline asm
	mov.u32 %r117, %dynamic_smem_size;
	// end inline asm
	setp.gt.u32 	%p1, %r117, 69887;
	@%p1 bra 	LBB0_64;
	bra.uni 	LBB0_1;
LBB0_64:                                // %L10
	ld.param.u64 	%rd30, [_Z17julia_upchan_373313CuDeviceArrayI9Float16x2Li1ELi1EES_IS0_Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_I5Int32Li1ELi1EE_param_5];
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %tid.y;
	shl.b32 	%r118, %r2, 5;
	mov.u32 	%r3, %ctaid.x;
	shl.b32 	%r4, %r3, 9;
	or.b32  	%r119, %r118, %r1;
	or.b32  	%r120, %r119, %r4;
	mul.wide.u32 	%rd36, %r120, 4;
	add.s64 	%rd3, %rd30, %rd36;
	mov.u32 	%r121, 1;
	st.global.u32 	[%rd3], %r121;
	shl.b32 	%r6, %r1, 1;
	bfe.u32 	%r10, %r1, 2, 1;
	and.b32  	%r129, %r6, 2;
	and.b32  	%r130, %r6, 4;
	or.b32  	%r131, %r10, %r129;
	or.b32  	%r132, %r131, %r130;
	mul.lo.s32 	%r15, %r132, 15;
	cvt.rn.f32.s32 	%f146, %r15;
	mov.f32 	%f147, 0f41800000;
	div.approx.f32 	%f1, %f146, %f147;
	abs.f32 	%f599, %f1;
	setp.lt.f32 	%p2, %f599, 0f40000000;
	mov.f32 	%f580, 0f40000000;
	@%p2 bra 	LBB0_76;
// %bb.65:
	setp.gtu.f32 	%p3, %f599, 0f4B800000;
	@%p3 bra 	LBB0_72;
	bra.uni 	LBB0_66;
LBB0_72:
	mov.b32 	%r68, %f599;
	and.b32  	%r133, %r68, 8388607;
	or.b32  	%r1031, %r133, 1065353216;
	mov.b32 	%f598, %r1031;
	add.s32 	%r134, %r68, -1073741824;
	and.b32  	%r1032, %r134, -8388608;
	setp.eq.s32 	%p9, %r1032, 0;
	@%p9 bra 	LBB0_75;
// %bb.73:                              // %__nv_fmaf_rn.exit4.i.i.i446.preheader
	mov.f32 	%f157, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f156,%f157;
	// end inline asm
LBB0_74:                                // %__nv_fmaf_rn.exit4.i.i.i446
                                        // =>This Inner Loop Header: Depth=1
	min.u32 	%r135, %r1032, 192937984;
	add.s32 	%r136, %r135, %r1031;
	mov.b32 	%f158, %r136;
	mul.f32 	%f159, %f156, %f158;
	sub.f32 	%f160, %f158, %f159;
	fma.rn.f32 	%f161, %f160, %f156, %f159;
	sub.f32 	%f162, %f158, %f161;
	fma.rz.f32 	%f163, %f162, %f156, %f161;
	cvt.rzi.f32.f32 	%f164, %f163;
	sub.f32 	%f598, %f158, %f164;
	sub.s32 	%r1032, %r1032, %r135;
	mov.b32 	%r1031, %f598;
	setp.ne.s32 	%p10, %r1032, 0;
	setp.ne.s32 	%p11, %r1031, 0;
	and.pred  	%p12, %p10, %p11;
	@%p12 bra 	LBB0_74;
LBB0_75:                                // %__internal_fmodf_slowpath_mod.exit.i.i448
	setp.gt.u32 	%p13, %r68, 2139095039;
	selp.f32 	%f165, 0f7FFFFFFF, 0f4B800000, %p13;
	mul.f32 	%f166, %f598, 0f34000000;
	mul.f32 	%f599, %f165, %f166;
	bra.uni 	LBB0_76;
LBB0_66:                                // %__nv_fast_fdividef.exit.i.i.i418
	div.approx.f32 	%f149, %f599, %f580;
	cvt.rzi.f32.f32 	%f597, %f149;
	fma.rn.f32 	%f76, %f597, 0fC0000000, %f599;
	mov.b32 	%r67, %f76;
	setp.lt.u32 	%p4, %r67, 1073741824;
	@%p4 bra 	LBB0_71;
// %bb.67:
	setp.lt.u32 	%p5, %r67, -2147483647;
	@%p5 bra 	LBB0_69;
// %bb.68:
	add.f32 	%f154, %f597, 0fBF800000;
	setp.lt.f32 	%p8, %f76, 0fC0000000;
	add.f32 	%f155, %f154, 0fBF800000;
	selp.f32 	%f597, %f155, %f154, %p8;
	bra.uni 	LBB0_71;
LBB0_69:
	add.f32 	%f597, %f597, 0f3F800000;
	setp.ltu.f32 	%p6, %f76, 0f40800000;
	@%p6 bra 	LBB0_71;
// %bb.70:                              // %__nv_fmaf_rn.exit.i.i.i423
	add.f32 	%f150, %f597, 0f3F800000;
	fma.rn.f32 	%f152, %f580, 0fC0400000, %f76;
	setp.ge.f32 	%p7, %f152, 0f00000000;
	add.f32 	%f153, %f150, 0f3F800000;
	selp.f32 	%f597, %f153, %f150, %p7;
LBB0_71:                                // %__internal_fmodf_fastpath_quot.exit.i.i427
	fma.rn.f32 	%f599, %f597, 0fC0000000, %f599;
LBB0_76:                                // %__internal_fmodf_kernel.exit.i452
	abs.f32 	%f167, %f599;
	setp.gtu.f32 	%p14, %f167, 0f7F800000;
	@%p14 bra 	LBB0_78;
// %bb.77:
	mov.b32 	%r137, %f1;
	and.b32  	%r138, %r137, -2147483648;
	mov.b32 	%r139, %f599;
	or.b32  	%r140, %r138, %r139;
	mov.b32 	%f599, %r140;
LBB0_78:                                // %__nv_fmodf.exit453
	add.f32 	%f168, %f599, %f599;
	mov.b32 	%r141, %f168;
	and.b32  	%r142, %r141, -2147483648;
	or.b32  	%r143, %r142, 1056964608;
	mov.b32 	%f169, %r143;
	add.f32 	%f170, %f168, %f169;
	cvt.rzi.f32.f32 	%f171, %f170;
	abs.f32 	%f172, %f168;
	setp.gt.f32 	%p15, %f172, 0f4B000000;
	selp.f32 	%f173, %f168, %f171, %p15;
	cvt.rzi.f32.f32 	%f174, %f168;
	setp.lt.f32 	%p16, %f172, 0f3F000000;
	selp.f32 	%f175, %f174, %f173, %p16;
	fma.rn.f32 	%f176, %f175, 0fBF000000, %f599;
	mul.f32 	%f177, %f176, 0f34222169;
	add.s32 	%r149, %r15, 120;
	cvt.rn.f32.s32 	%f199, %r149;
	div.approx.f32 	%f92, %f199, %f147;
	abs.f32 	%f603, %f92;
	setp.lt.f32 	%p22, %f603, 0f40000000;
	@%p22 bra 	LBB0_90;
// %bb.79:
	setp.gtu.f32 	%p23, %f603, 0f4B800000;
	@%p23 bra 	LBB0_86;
	bra.uni 	LBB0_80;
LBB0_86:
	mov.b32 	%r76, %f603;
	and.b32  	%r150, %r76, 8388607;
	or.b32  	%r1033, %r150, 1065353216;
	mov.b32 	%f602, %r1033;
	add.s32 	%r151, %r76, -1073741824;
	and.b32  	%r1034, %r151, -8388608;
	setp.eq.s32 	%p29, %r1034, 0;
	@%p29 bra 	LBB0_89;
// %bb.87:                              // %__nv_fmaf_rn.exit4.i.i.i492.preheader
	mov.f32 	%f210, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f209,%f210;
	// end inline asm
LBB0_88:                                // %__nv_fmaf_rn.exit4.i.i.i492
                                        // =>This Inner Loop Header: Depth=1
	min.u32 	%r152, %r1034, 192937984;
	add.s32 	%r153, %r152, %r1033;
	mov.b32 	%f211, %r153;
	mul.f32 	%f212, %f209, %f211;
	sub.f32 	%f213, %f211, %f212;
	fma.rn.f32 	%f214, %f213, %f209, %f212;
	sub.f32 	%f215, %f211, %f214;
	fma.rz.f32 	%f216, %f215, %f209, %f214;
	cvt.rzi.f32.f32 	%f217, %f216;
	sub.f32 	%f602, %f211, %f217;
	sub.s32 	%r1034, %r1034, %r152;
	mov.b32 	%r1033, %f602;
	setp.ne.s32 	%p30, %r1034, 0;
	setp.ne.s32 	%p31, %r1033, 0;
	and.pred  	%p32, %p30, %p31;
	@%p32 bra 	LBB0_88;
LBB0_89:                                // %__internal_fmodf_slowpath_mod.exit.i.i494
	setp.gt.u32 	%p33, %r76, 2139095039;
	selp.f32 	%f218, 0f7FFFFFFF, 0f4B800000, %p33;
	mul.f32 	%f219, %f602, 0f34000000;
	mul.f32 	%f603, %f218, %f219;
	bra.uni 	LBB0_90;
LBB0_80:                                // %__nv_fast_fdividef.exit.i.i.i464
	div.approx.f32 	%f202, %f603, %f580;
	cvt.rzi.f32.f32 	%f601, %f202;
	fma.rn.f32 	%f95, %f601, 0fC0000000, %f603;
	mov.b32 	%r75, %f95;
	setp.lt.u32 	%p24, %r75, 1073741824;
	@%p24 bra 	LBB0_85;
// %bb.81:
	setp.lt.u32 	%p25, %r75, -2147483647;
	@%p25 bra 	LBB0_83;
// %bb.82:
	add.f32 	%f207, %f601, 0fBF800000;
	setp.lt.f32 	%p28, %f95, 0fC0000000;
	add.f32 	%f208, %f207, 0fBF800000;
	selp.f32 	%f601, %f208, %f207, %p28;
	bra.uni 	LBB0_85;
LBB0_83:
	add.f32 	%f601, %f601, 0f3F800000;
	setp.ltu.f32 	%p26, %f95, 0f40800000;
	@%p26 bra 	LBB0_85;
// %bb.84:                              // %__nv_fmaf_rn.exit.i.i.i469
	add.f32 	%f203, %f601, 0f3F800000;
	fma.rn.f32 	%f205, %f580, 0fC0400000, %f95;
	setp.ge.f32 	%p27, %f205, 0f00000000;
	add.f32 	%f206, %f203, 0f3F800000;
	selp.f32 	%f601, %f206, %f203, %p27;
LBB0_85:                                // %__internal_fmodf_fastpath_quot.exit.i.i473
	fma.rn.f32 	%f603, %f601, 0fC0000000, %f603;
LBB0_90:                                // %__internal_fmodf_kernel.exit.i498
	fma.rn.f32 	%f178, %f176, 0f40490FDA, %f177;
	shr.u32 	%r9, %r1, 2;
	abs.f32 	%f220, %f603;
	setp.gtu.f32 	%p34, %f220, 0f7F800000;
	@%p34 bra 	LBB0_92;
// %bb.91:
	mov.b32 	%r154, %f92;
	and.b32  	%r155, %r154, -2147483648;
	mov.b32 	%r156, %f603;
	or.b32  	%r157, %r155, %r156;
	mov.b32 	%f603, %r157;
LBB0_92:                                // %__nv_fmodf.exit499
	mul.f32 	%f179, %f178, %f178;
	add.f32 	%f221, %f603, %f603;
	mov.b32 	%r164, %f221;
	and.b32  	%r165, %r164, -2147483648;
	or.b32  	%r166, %r165, 1056964608;
	mov.b32 	%f222, %r166;
	add.f32 	%f223, %f221, %f222;
	cvt.rzi.f32.f32 	%f224, %f223;
	abs.f32 	%f225, %f221;
	setp.gt.f32 	%p35, %f225, 0f4B000000;
	selp.f32 	%f226, %f221, %f224, %p35;
	cvt.rzi.f32.f32 	%f227, %f221;
	setp.lt.f32 	%p36, %f225, 0f3F000000;
	selp.f32 	%f228, %f227, %f226, %p36;
	fma.rn.f32 	%f229, %f228, 0fBF000000, %f603;
	mul.f32 	%f230, %f229, 0f34222169;
	fma.rn.f32 	%f231, %f229, 0f40490FDA, %f230;
	mul.f32 	%f232, %f231, %f231;
	and.b32  	%r172, %r1, 3;
	mul.wide.u32 	%rd41, %r172, %r9;
	shl.b64 	%rd42, %rd41, 1;
	neg.s64 	%rd43, %rd42;
	cvt.rn.f32.s64 	%f254, %rd43;
	mov.f32 	%f255, 0f41000000;
	div.approx.f32 	%f109, %f254, %f255;
	abs.f32 	%f583, %f109;
	setp.lt.f32 	%p42, %f583, 0f40000000;
	@%p42 bra 	LBB0_13;
// %bb.2:
	setp.gtu.f32 	%p43, %f583, 0f4B800000;
	@%p43 bra 	LBB0_9;
	bra.uni 	LBB0_3;
LBB0_9:
	mov.b32 	%r17, %f583;
	and.b32  	%r173, %r17, 8388607;
	or.b32  	%r1015, %r173, 1065353216;
	mov.b32 	%f582, %r1015;
	add.s32 	%r174, %r17, -1073741824;
	and.b32  	%r1016, %r174, -8388608;
	setp.eq.s32 	%p49, %r1016, 0;
	@%p49 bra 	LBB0_12;
// %bb.10:                              // %__nv_fmaf_rn.exit4.i.i.i.preheader
	mov.f32 	%f265, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f264,%f265;
	// end inline asm
LBB0_11:                                // %__nv_fmaf_rn.exit4.i.i.i
                                        // =>This Inner Loop Header: Depth=1
	min.u32 	%r175, %r1016, 192937984;
	add.s32 	%r176, %r175, %r1015;
	mov.b32 	%f266, %r176;
	mul.f32 	%f267, %f264, %f266;
	sub.f32 	%f268, %f266, %f267;
	fma.rn.f32 	%f269, %f268, %f264, %f267;
	sub.f32 	%f270, %f266, %f269;
	fma.rz.f32 	%f271, %f270, %f264, %f269;
	cvt.rzi.f32.f32 	%f272, %f271;
	sub.f32 	%f582, %f266, %f272;
	sub.s32 	%r1016, %r1016, %r175;
	mov.b32 	%r1015, %f582;
	setp.ne.s32 	%p50, %r1016, 0;
	setp.ne.s32 	%p51, %r1015, 0;
	and.pred  	%p52, %p50, %p51;
	@%p52 bra 	LBB0_11;
LBB0_12:                                // %__internal_fmodf_slowpath_mod.exit.i.i
	setp.gt.u32 	%p53, %r17, 2139095039;
	selp.f32 	%f273, 0f7FFFFFFF, 0f4B800000, %p53;
	mul.f32 	%f274, %f582, 0f34000000;
	mul.f32 	%f583, %f273, %f274;
	bra.uni 	LBB0_13;
LBB0_3:                                 // %__nv_fast_fdividef.exit.i.i.i
	div.approx.f32 	%f257, %f583, %f580;
	cvt.rzi.f32.f32 	%f581, %f257;
	fma.rn.f32 	%f4, %f581, 0fC0000000, %f583;
	mov.b32 	%r16, %f4;
	setp.lt.u32 	%p44, %r16, 1073741824;
	@%p44 bra 	LBB0_8;
// %bb.4:
	setp.lt.u32 	%p45, %r16, -2147483647;
	@%p45 bra 	LBB0_6;
// %bb.5:
	add.f32 	%f262, %f581, 0fBF800000;
	setp.lt.f32 	%p48, %f4, 0fC0000000;
	add.f32 	%f263, %f262, 0fBF800000;
	selp.f32 	%f581, %f263, %f262, %p48;
	bra.uni 	LBB0_8;
LBB0_6:
	add.f32 	%f581, %f581, 0f3F800000;
	setp.ltu.f32 	%p46, %f4, 0f40800000;
	@%p46 bra 	LBB0_8;
// %bb.7:                               // %__nv_fmaf_rn.exit.i.i.i
	add.f32 	%f258, %f581, 0f3F800000;
	fma.rn.f32 	%f260, %f580, 0fC0400000, %f4;
	setp.ge.f32 	%p47, %f260, 0f00000000;
	add.f32 	%f261, %f258, 0f3F800000;
	selp.f32 	%f581, %f261, %f258, %p47;
LBB0_8:                                 // %__internal_fmodf_fastpath_quot.exit.i.i
	fma.rn.f32 	%f583, %f581, 0fC0000000, %f583;
LBB0_13:                                // %__internal_fmodf_kernel.exit.i
	fma.rn.f32 	%f180, %f179, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f233, %f232, 0f37CBAC00, 0fBAB607ED;
	or.b32  	%r86, %r172, 4;
	cvt.u64.u32 	%rd10, %r9;
	abs.f32 	%f275, %f583;
	setp.gtu.f32 	%p54, %f275, 0f7F800000;
	@%p54 bra 	LBB0_15;
// %bb.14:
	mov.b32 	%r177, %f109;
	and.b32  	%r178, %r177, -2147483648;
	mov.b32 	%r179, %f583;
	or.b32  	%r180, %r178, %r179;
	mov.b32 	%f583, %r180;
LBB0_15:                                // %__nv_fmodf.exit
	cvt.rzi.s32.f32 	%r144, %f175;
	fma.rn.f32 	%f181, %f180, %f179, 0f3D2AAABB;
	fma.rn.f32 	%f185, %f179, 0fB94D4153, 0f3C0885E4;
	cvt.rzi.s32.f32 	%r167, %f228;
	fma.rn.f32 	%f234, %f233, %f232, 0f3D2AAABB;
	fma.rn.f32 	%f238, %f232, 0fB94D4153, 0f3C0885E4;
	add.f32 	%f276, %f583, %f583;
	mov.b32 	%r181, %f276;
	and.b32  	%r182, %r181, -2147483648;
	or.b32  	%r183, %r182, 1056964608;
	mov.b32 	%f277, %r183;
	add.f32 	%f278, %f276, %f277;
	cvt.rzi.f32.f32 	%f279, %f278;
	abs.f32 	%f280, %f276;
	setp.gt.f32 	%p55, %f280, 0f4B000000;
	selp.f32 	%f281, %f276, %f279, %p55;
	cvt.rzi.f32.f32 	%f282, %f276;
	setp.lt.f32 	%p56, %f280, 0f3F000000;
	selp.f32 	%f283, %f282, %f281, %p56;
	cvt.rzi.s32.f32 	%r184, %f283;
	fma.rn.f32 	%f284, %f283, 0fBF000000, %f583;
	mul.f32 	%f285, %f284, 0f34222169;
	fma.rn.f32 	%f286, %f284, 0f40490FDA, %f285;
	mul.f32 	%f287, %f286, %f286;
	fma.rn.f32 	%f288, %f287, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f289, %f288, %f287, 0f3D2AAABB;
	fma.rn.f32 	%f290, %f289, %f287, 0fBEFFFFFF;
	fma.rn.f32 	%f292, %f287, %f286, 0f00000000;
	fma.rn.f32 	%f293, %f287, 0fB94D4153, 0f3C0885E4;
	fma.rn.f32 	%f294, %f293, %f287, 0fBE2AAAA8;
	and.b32  	%r185, %r184, 1;
	cvt.u64.u32 	%rd44, %r86;
	mul.lo.s64 	%rd45, %rd44, %rd10;
	shl.b64 	%rd46, %rd45, 1;
	neg.s64 	%rd47, %rd46;
	cvt.rn.f32.s64 	%f307, %rd47;
	div.approx.f32 	%f20, %f307, %f255;
	abs.f32 	%f587, %f20;
	setp.lt.f32 	%p62, %f587, 0f40000000;
	@%p62 bra 	LBB0_27;
// %bb.16:
	setp.gtu.f32 	%p63, %f587, 0f4B800000;
	@%p63 bra 	LBB0_23;
	bra.uni 	LBB0_17;
LBB0_23:
	mov.b32 	%r25, %f587;
	and.b32  	%r189, %r25, 8388607;
	or.b32  	%r1017, %r189, 1065353216;
	mov.b32 	%f586, %r1017;
	add.s32 	%r190, %r25, -1073741824;
	and.b32  	%r1018, %r190, -8388608;
	setp.eq.s32 	%p69, %r1018, 0;
	@%p69 bra 	LBB0_26;
// %bb.24:                              // %__nv_fmaf_rn.exit4.i.i.i308.preheader
	mov.f32 	%f318, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f317,%f318;
	// end inline asm
LBB0_25:                                // %__nv_fmaf_rn.exit4.i.i.i308
                                        // =>This Inner Loop Header: Depth=1
	min.u32 	%r191, %r1018, 192937984;
	add.s32 	%r192, %r191, %r1017;
	mov.b32 	%f319, %r192;
	mul.f32 	%f320, %f317, %f319;
	sub.f32 	%f321, %f319, %f320;
	fma.rn.f32 	%f322, %f321, %f317, %f320;
	sub.f32 	%f323, %f319, %f322;
	fma.rz.f32 	%f324, %f323, %f317, %f322;
	cvt.rzi.f32.f32 	%f325, %f324;
	sub.f32 	%f586, %f319, %f325;
	sub.s32 	%r1018, %r1018, %r191;
	mov.b32 	%r1017, %f586;
	setp.ne.s32 	%p70, %r1018, 0;
	setp.ne.s32 	%p71, %r1017, 0;
	and.pred  	%p72, %p70, %p71;
	@%p72 bra 	LBB0_25;
LBB0_26:                                // %__internal_fmodf_slowpath_mod.exit.i.i310
	setp.gt.u32 	%p73, %r25, 2139095039;
	selp.f32 	%f326, 0f7FFFFFFF, 0f4B800000, %p73;
	mul.f32 	%f327, %f586, 0f34000000;
	mul.f32 	%f587, %f326, %f327;
	bra.uni 	LBB0_27;
LBB0_17:                                // %__nv_fast_fdividef.exit.i.i.i280
	div.approx.f32 	%f310, %f587, %f580;
	cvt.rzi.f32.f32 	%f585, %f310;
	fma.rn.f32 	%f23, %f585, 0fC0000000, %f587;
	mov.b32 	%r24, %f23;
	setp.lt.u32 	%p64, %r24, 1073741824;
	@%p64 bra 	LBB0_22;
// %bb.18:
	setp.lt.u32 	%p65, %r24, -2147483647;
	@%p65 bra 	LBB0_20;
// %bb.19:
	add.f32 	%f315, %f585, 0fBF800000;
	setp.lt.f32 	%p68, %f23, 0fC0000000;
	add.f32 	%f316, %f315, 0fBF800000;
	selp.f32 	%f585, %f316, %f315, %p68;
	bra.uni 	LBB0_22;
LBB0_20:
	add.f32 	%f585, %f585, 0f3F800000;
	setp.ltu.f32 	%p66, %f23, 0f40800000;
	@%p66 bra 	LBB0_22;
// %bb.21:                              // %__nv_fmaf_rn.exit.i.i.i285
	add.f32 	%f311, %f585, 0f3F800000;
	fma.rn.f32 	%f313, %f580, 0fC0400000, %f23;
	setp.ge.f32 	%p67, %f313, 0f00000000;
	add.f32 	%f314, %f311, 0f3F800000;
	selp.f32 	%f585, %f314, %f311, %p67;
LBB0_22:                                // %__internal_fmodf_fastpath_quot.exit.i.i289
	fma.rn.f32 	%f587, %f585, 0fC0000000, %f587;
LBB0_27:                                // %__internal_fmodf_kernel.exit.i314
	fma.rn.f32 	%f182, %f181, %f179, 0fBEFFFFFF;
	fma.rn.f32 	%f184, %f179, %f178, 0f00000000;
	fma.rn.f32 	%f186, %f185, %f179, 0fBE2AAAA8;
	and.b32  	%r145, %r144, 1;
	fma.rn.f32 	%f235, %f234, %f232, 0fBEFFFFFF;
	fma.rn.f32 	%f237, %f232, %f231, 0f00000000;
	fma.rn.f32 	%f239, %f238, %f232, 0fBE2AAAA8;
	and.b32  	%r168, %r167, 1;
	fma.rn.f32 	%f291, %f290, %f287, 0f3F800000;
	fma.rn.f32 	%f295, %f294, %f292, %f286;
	setp.eq.b32 	%p57, %r185, 1;
	mov.f32 	%f192, 0f00000000;
	abs.f32 	%f328, %f587;
	setp.gtu.f32 	%p74, %f328, 0f7F800000;
	@%p74 bra 	LBB0_29;
// %bb.28:
	mov.b32 	%r193, %f20;
	and.b32  	%r194, %r193, -2147483648;
	mov.b32 	%r195, %f587;
	or.b32  	%r196, %r194, %r195;
	mov.b32 	%f587, %r196;
LBB0_29:                                // %__nv_fmodf.exit315
	fma.rn.f32 	%f183, %f182, %f179, 0f3F800000;
	fma.rn.f32 	%f187, %f186, %f184, %f178;
	setp.eq.b32 	%p17, %r145, 1;
	fma.rn.f32 	%f236, %f235, %f232, 0f3F800000;
	fma.rn.f32 	%f240, %f239, %f237, %f231;
	setp.eq.b32 	%p37, %r168, 1;
	selp.f32 	%f296, %f291, %f295, %p57;
	and.b32  	%r186, %r184, 2;
	add.f32 	%f329, %f587, %f587;
	mov.b32 	%r209, %f329;
	and.b32  	%r210, %r209, -2147483648;
	or.b32  	%r211, %r210, 1056964608;
	mov.b32 	%f330, %r211;
	add.f32 	%f331, %f329, %f330;
	cvt.rzi.f32.f32 	%f332, %f331;
	abs.f32 	%f333, %f329;
	setp.gt.f32 	%p75, %f333, 0f4B000000;
	selp.f32 	%f334, %f329, %f332, %p75;
	cvt.rzi.f32.f32 	%f335, %f329;
	setp.lt.f32 	%p76, %f333, 0f3F000000;
	selp.f32 	%f336, %f335, %f334, %p76;
	cvt.rzi.s32.f32 	%r212, %f336;
	fma.rn.f32 	%f337, %f336, 0fBF000000, %f587;
	mul.f32 	%f338, %f337, 0f34222169;
	fma.rn.f32 	%f339, %f337, 0f40490FDA, %f338;
	mul.f32 	%f340, %f339, %f339;
	fma.rn.f32 	%f341, %f340, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f342, %f341, %f340, 0f3D2AAABB;
	fma.rn.f32 	%f343, %f342, %f340, 0fBEFFFFFF;
	fma.rn.f32 	%f344, %f343, %f340, 0f3F800000;
	fma.rn.f32 	%f345, %f340, %f339, 0f00000000;
	fma.rn.f32 	%f346, %f340, 0fB94D4153, 0f3C0885E4;
	fma.rn.f32 	%f347, %f346, %f340, 0fBE2AAAA8;
	fma.rn.f32 	%f348, %f347, %f345, %f339;
	and.b32  	%r213, %r212, 1;
	setp.eq.b32 	%p77, %r213, 1;
	selp.f32 	%f349, %f344, %f348, %p77;
	and.b32  	%r214, %r212, 2;
	div.approx.f32 	%f37, %f192, %f147;
	abs.f32 	%f591, %f37;
	setp.lt.f32 	%p82, %f591, 0f40000000;
	@%p82 bra 	LBB0_41;
// %bb.30:
	setp.gtu.f32 	%p83, %f591, 0f4B800000;
	@%p83 bra 	LBB0_37;
	bra.uni 	LBB0_31;
LBB0_37:
	mov.b32 	%r37, %f591;
	and.b32  	%r217, %r37, 8388607;
	or.b32  	%r1019, %r217, 1065353216;
	mov.b32 	%f590, %r1019;
	add.s32 	%r218, %r37, -1073741824;
	and.b32  	%r1020, %r218, -8388608;
	setp.eq.s32 	%p89, %r1020, 0;
	@%p89 bra 	LBB0_40;
// %bb.38:                              // %__nv_fmaf_rn.exit4.i.i.i354.preheader
	mov.f32 	%f372, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f371,%f372;
	// end inline asm
LBB0_39:                                // %__nv_fmaf_rn.exit4.i.i.i354
                                        // =>This Inner Loop Header: Depth=1
	min.u32 	%r219, %r1020, 192937984;
	add.s32 	%r220, %r219, %r1019;
	mov.b32 	%f373, %r220;
	mul.f32 	%f374, %f371, %f373;
	sub.f32 	%f375, %f373, %f374;
	fma.rn.f32 	%f376, %f375, %f371, %f374;
	sub.f32 	%f377, %f373, %f376;
	fma.rz.f32 	%f378, %f377, %f371, %f376;
	cvt.rzi.f32.f32 	%f379, %f378;
	sub.f32 	%f590, %f373, %f379;
	sub.s32 	%r1020, %r1020, %r219;
	mov.b32 	%r1019, %f590;
	setp.ne.s32 	%p90, %r1020, 0;
	setp.ne.s32 	%p91, %r1019, 0;
	and.pred  	%p92, %p90, %p91;
	@%p92 bra 	LBB0_39;
LBB0_40:                                // %__internal_fmodf_slowpath_mod.exit.i.i356
	setp.gt.u32 	%p93, %r37, 2139095039;
	selp.f32 	%f380, 0f7FFFFFFF, 0f4B800000, %p93;
	mul.f32 	%f381, %f590, 0f34000000;
	mul.f32 	%f591, %f380, %f381;
	bra.uni 	LBB0_41;
LBB0_31:                                // %__nv_fast_fdividef.exit.i.i.i326
	div.approx.f32 	%f364, %f591, %f580;
	cvt.rzi.f32.f32 	%f589, %f364;
	fma.rn.f32 	%f40, %f589, 0fC0000000, %f591;
	mov.b32 	%r36, %f40;
	setp.lt.u32 	%p84, %r36, 1073741824;
	@%p84 bra 	LBB0_36;
// %bb.32:
	setp.lt.u32 	%p85, %r36, -2147483647;
	@%p85 bra 	LBB0_34;
// %bb.33:
	add.f32 	%f369, %f589, 0fBF800000;
	setp.lt.f32 	%p88, %f40, 0fC0000000;
	add.f32 	%f370, %f369, 0fBF800000;
	selp.f32 	%f589, %f370, %f369, %p88;
	bra.uni 	LBB0_36;
LBB0_34:
	add.f32 	%f589, %f589, 0f3F800000;
	setp.ltu.f32 	%p86, %f40, 0f40800000;
	@%p86 bra 	LBB0_36;
// %bb.35:                              // %__nv_fmaf_rn.exit.i.i.i331
	add.f32 	%f365, %f589, 0f3F800000;
	fma.rn.f32 	%f367, %f580, 0fC0400000, %f40;
	setp.ge.f32 	%p87, %f367, 0f00000000;
	add.f32 	%f368, %f365, 0f3F800000;
	selp.f32 	%f589, %f368, %f365, %p87;
LBB0_36:                                // %__internal_fmodf_fastpath_quot.exit.i.i335
	fma.rn.f32 	%f591, %f589, 0fC0000000, %f591;
LBB0_41:                                // %__internal_fmodf_kernel.exit.i360
	selp.f32 	%f188, %f183, %f187, %p17;
	and.b32  	%r146, %r144, 2;
	selp.f32 	%f241, %f236, %f240, %p37;
	and.b32  	%r169, %r167, 2;
	setp.eq.s32 	%p58, %r186, 0;
	neg.f32 	%f298, %f296;
	add.s32 	%r187, %r184, 1;
	cvt.rzi.f32.f32 	%f303, %f583;
	setp.eq.s32 	%p78, %r214, 0;
	neg.f32 	%f351, %f349;
	add.s32 	%r215, %r212, 1;
	cvt.rzi.f32.f32 	%f356, %f587;
	abs.f32 	%f382, %f591;
	setp.gtu.f32 	%p94, %f382, 0f7F800000;
	@%p94 bra 	LBB0_43;
// %bb.42:
	mov.b32 	%r221, %f37;
	and.b32  	%r222, %r221, -2147483648;
	mov.b32 	%r223, %f591;
	or.b32  	%r224, %r222, %r223;
	mov.b32 	%f591, %r224;
LBB0_43:                                // %__nv_fmodf.exit361
	shl.b32 	%r5, %r1, 2;
	and.b32  	%r123, %r6, 8;
	and.b32  	%r124, %r1, 2;
	setp.eq.s32 	%p18, %r146, 0;
	neg.f32 	%f190, %f188;
	add.s32 	%r147, %r144, 1;
	cvt.rzi.f32.f32 	%f195, %f599;
	setp.eq.s32 	%p38, %r169, 0;
	neg.f32 	%f243, %f241;
	add.s32 	%r170, %r167, 1;
	cvt.rzi.f32.f32 	%f248, %f603;
	selp.f32 	%f297, %f295, %f291, %p57;
	selp.f32 	%f299, %f296, %f298, %p58;
	and.b32  	%r188, %r187, 2;
	setp.eq.f32 	%p60, %f303, %f583;
	mul.f32 	%f304, %f583, 0f00000000;
	selp.f32 	%f350, %f348, %f344, %p77;
	selp.f32 	%f352, %f349, %f351, %p78;
	and.b32  	%r216, %r215, 2;
	setp.eq.f32 	%p80, %f356, %f587;
	mul.f32 	%f357, %f587, 0f00000000;
	add.f32 	%f383, %f591, %f591;
	mov.b32 	%r225, %f383;
	and.b32  	%r226, %r225, -2147483648;
	or.b32  	%r227, %r226, 1056964608;
	mov.b32 	%f384, %r227;
	add.f32 	%f385, %f383, %f384;
	cvt.rzi.f32.f32 	%f386, %f385;
	abs.f32 	%f387, %f383;
	setp.gt.f32 	%p95, %f387, 0f4B000000;
	selp.f32 	%f388, %f383, %f386, %p95;
	cvt.rzi.f32.f32 	%f389, %f383;
	setp.lt.f32 	%p96, %f387, 0f3F000000;
	selp.f32 	%f390, %f389, %f388, %p96;
	cvt.rzi.s32.f32 	%r228, %f390;
	fma.rn.f32 	%f391, %f390, 0fBF000000, %f591;
	mul.f32 	%f392, %f391, 0f34222169;
	fma.rn.f32 	%f393, %f391, 0f40490FDA, %f392;
	mul.f32 	%f394, %f393, %f393;
	fma.rn.f32 	%f395, %f394, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f396, %f395, %f394, 0f3D2AAABB;
	fma.rn.f32 	%f397, %f396, %f394, 0fBEFFFFFF;
	fma.rn.f32 	%f398, %f397, %f394, 0f3F800000;
	fma.rn.f32 	%f399, %f394, %f393, 0f00000000;
	fma.rn.f32 	%f400, %f394, 0fB94D4153, 0f3C0885E4;
	fma.rn.f32 	%f401, %f400, %f394, 0fBE2AAAA8;
	fma.rn.f32 	%f402, %f401, %f399, %f393;
	and.b32  	%r229, %r228, 1;
	setp.eq.b32 	%p97, %r229, 1;
	selp.f32 	%f403, %f398, %f402, %p97;
	and.b32  	%r230, %r228, 2;
	setp.eq.s32 	%p98, %r230, 0;
	neg.f32 	%f405, %f403;
	add.s32 	%r231, %r228, 1;
	cvt.rzi.f32.f32 	%f410, %f591;
	shl.b64 	%rd48, %rd10, 1;
	neg.s64 	%rd49, %rd48;
	cvt.rn.f32.s64 	%f414, %rd49;
	div.approx.f32 	%f56, %f414, %f147;
	abs.f32 	%f595, %f56;
	setp.lt.f32 	%p102, %f595, 0f40000000;
	@%p102 bra 	LBB0_55;
// %bb.44:
	setp.gtu.f32 	%p103, %f595, 0f4B800000;
	@%p103 bra 	LBB0_51;
	bra.uni 	LBB0_45;
LBB0_51:
	mov.b32 	%r45, %f595;
	and.b32  	%r233, %r45, 8388607;
	or.b32  	%r1021, %r233, 1065353216;
	mov.b32 	%f594, %r1021;
	add.s32 	%r234, %r45, -1073741824;
	and.b32  	%r1022, %r234, -8388608;
	setp.eq.s32 	%p109, %r1022, 0;
	@%p109 bra 	LBB0_54;
// %bb.52:                              // %__nv_fmaf_rn.exit4.i.i.i400.preheader
	mov.f32 	%f425, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f424,%f425;
	// end inline asm
LBB0_53:                                // %__nv_fmaf_rn.exit4.i.i.i400
                                        // =>This Inner Loop Header: Depth=1
	min.u32 	%r235, %r1022, 192937984;
	add.s32 	%r236, %r235, %r1021;
	mov.b32 	%f426, %r236;
	mul.f32 	%f427, %f424, %f426;
	sub.f32 	%f428, %f426, %f427;
	fma.rn.f32 	%f429, %f428, %f424, %f427;
	sub.f32 	%f430, %f426, %f429;
	fma.rz.f32 	%f431, %f430, %f424, %f429;
	cvt.rzi.f32.f32 	%f432, %f431;
	sub.f32 	%f594, %f426, %f432;
	sub.s32 	%r1022, %r1022, %r235;
	mov.b32 	%r1021, %f594;
	setp.ne.s32 	%p110, %r1022, 0;
	setp.ne.s32 	%p111, %r1021, 0;
	and.pred  	%p112, %p110, %p111;
	@%p112 bra 	LBB0_53;
LBB0_54:                                // %__internal_fmodf_slowpath_mod.exit.i.i402
	setp.gt.u32 	%p113, %r45, 2139095039;
	selp.f32 	%f433, 0f7FFFFFFF, 0f4B800000, %p113;
	mul.f32 	%f434, %f594, 0f34000000;
	mul.f32 	%f595, %f433, %f434;
	bra.uni 	LBB0_55;
LBB0_45:                                // %__nv_fast_fdividef.exit.i.i.i372
	div.approx.f32 	%f417, %f595, %f580;
	cvt.rzi.f32.f32 	%f593, %f417;
	fma.rn.f32 	%f59, %f593, 0fC0000000, %f595;
	mov.b32 	%r44, %f59;
	setp.lt.u32 	%p104, %r44, 1073741824;
	@%p104 bra 	LBB0_50;
// %bb.46:
	setp.lt.u32 	%p105, %r44, -2147483647;
	@%p105 bra 	LBB0_48;
// %bb.47:
	add.f32 	%f422, %f593, 0fBF800000;
	setp.lt.f32 	%p108, %f59, 0fC0000000;
	add.f32 	%f423, %f422, 0fBF800000;
	selp.f32 	%f593, %f423, %f422, %p108;
	bra.uni 	LBB0_50;
LBB0_48:
	add.f32 	%f593, %f593, 0f3F800000;
	setp.ltu.f32 	%p106, %f59, 0f40800000;
	@%p106 bra 	LBB0_50;
// %bb.49:                              // %__nv_fmaf_rn.exit.i.i.i377
	add.f32 	%f418, %f593, 0f3F800000;
	fma.rn.f32 	%f420, %f580, 0fC0400000, %f59;
	setp.ge.f32 	%p107, %f420, 0f00000000;
	add.f32 	%f421, %f418, 0f3F800000;
	selp.f32 	%f593, %f421, %f418, %p107;
LBB0_50:                                // %__internal_fmodf_fastpath_quot.exit.i.i381
	fma.rn.f32 	%f595, %f593, 0fC0000000, %f595;
LBB0_55:                                // %__internal_fmodf_kernel.exit.i406
	and.b32  	%r122, %r5, 4;
	or.b32  	%r125, %r123, %r124;
	selp.f32 	%f189, %f187, %f183, %p17;
	selp.f32 	%f191, %f188, %f190, %p18;
	and.b32  	%r148, %r147, 2;
	setp.eq.f32 	%p20, %f195, %f599;
	mul.f32 	%f196, %f599, 0f00000000;
	selp.f32 	%f242, %f240, %f236, %p37;
	selp.f32 	%f244, %f241, %f243, %p38;
	and.b32  	%r171, %r170, 2;
	setp.eq.f32 	%p40, %f248, %f603;
	mul.f32 	%f249, %f603, 0f00000000;
	setp.eq.s32 	%p59, %r188, 0;
	sub.f32 	%f301, %f192, %f297;
	selp.f32 	%f18, %f304, %f299, %p60;
	abs.f32 	%f305, %f583;
	setp.eq.s32 	%p79, %r216, 0;
	sub.f32 	%f354, %f192, %f350;
	selp.f32 	%f358, %f357, %f352, %p80;
	abs.f32 	%f359, %f587;
	selp.f32 	%f404, %f402, %f398, %p97;
	selp.f32 	%f406, %f403, %f405, %p98;
	and.b32  	%r232, %r231, 2;
	setp.eq.f32 	%p100, %f410, %f591;
	mul.f32 	%f411, %f591, 0f00000000;
	abs.f32 	%f435, %f595;
	setp.gtu.f32 	%p114, %f435, 0f7F800000;
	@%p114 bra 	LBB0_57;
// %bb.56:
	mov.b32 	%r237, %f56;
	and.b32  	%r238, %r237, -2147483648;
	mov.b32 	%r239, %f595;
	or.b32  	%r240, %r238, %r239;
	mov.b32 	%f595, %r240;
LBB0_57:                                // %__nv_fmodf.exit407
	or.b32  	%r126, %r125, %r122;
	and.b32  	%r127, %r6, 6;
	setp.eq.s32 	%p19, %r148, 0;
	sub.f32 	%f193, %f192, %f189;
	selp.f32 	%f90, %f196, %f191, %p20;
	abs.f32 	%f197, %f599;
	setp.eq.s32 	%p39, %r171, 0;
	sub.f32 	%f246, %f192, %f242;
	selp.f32 	%f250, %f249, %f244, %p40;
	abs.f32 	%f251, %f603;
	selp.f32 	%f302, %f297, %f301, %p59;
	setp.gt.f32 	%p61, %f305, 0f4B800000;
	add.f32 	%f306, %f18, 0f3F800000;
	selp.f32 	%f355, %f350, %f354, %p79;
	setp.gt.f32 	%p81, %f359, 0f4B800000;
	add.f32 	%f360, %f358, 0f3F800000;
	setp.eq.s32 	%p99, %r232, 0;
	sub.f32 	%f408, %f192, %f404;
	selp.f32 	%f54, %f411, %f406, %p100;
	abs.f32 	%f412, %f591;
	and.b32  	%r85, %r9, 2;
	add.f32 	%f436, %f595, %f595;
	mov.b32 	%r247, %f436;
	and.b32  	%r248, %r247, -2147483648;
	or.b32  	%r249, %r248, 1056964608;
	mov.b32 	%f437, %r249;
	add.f32 	%f438, %f436, %f437;
	cvt.rzi.f32.f32 	%f439, %f438;
	abs.f32 	%f440, %f436;
	setp.gt.f32 	%p115, %f440, 0f4B000000;
	selp.f32 	%f441, %f436, %f439, %p115;
	cvt.rzi.f32.f32 	%f442, %f436;
	setp.lt.f32 	%p116, %f440, 0f3F000000;
	selp.f32 	%f443, %f442, %f441, %p116;
	cvt.rzi.s32.f32 	%r250, %f443;
	fma.rn.f32 	%f444, %f443, 0fBF000000, %f595;
	mul.f32 	%f445, %f444, 0f34222169;
	fma.rn.f32 	%f446, %f444, 0f40490FDA, %f445;
	mul.f32 	%f447, %f446, %f446;
	fma.rn.f32 	%f448, %f447, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f449, %f448, %f447, 0f3D2AAABB;
	fma.rn.f32 	%f450, %f449, %f447, 0fBEFFFFFF;
	fma.rn.f32 	%f451, %f450, %f447, 0f3F800000;
	fma.rn.f32 	%f452, %f447, %f446, 0f00000000;
	fma.rn.f32 	%f453, %f447, 0fB94D4153, 0f3C0885E4;
	fma.rn.f32 	%f454, %f453, %f447, 0fBE2AAAA8;
	fma.rn.f32 	%f455, %f454, %f452, %f446;
	and.b32  	%r251, %r250, 1;
	setp.eq.b32 	%p117, %r251, 1;
	selp.f32 	%f456, %f451, %f455, %p117;
	selp.f32 	%f457, %f455, %f451, %p117;
	and.b32  	%r252, %r250, 2;
	setp.eq.s32 	%p118, %r252, 0;
	neg.f32 	%f458, %f456;
	selp.f32 	%f459, %f456, %f458, %p118;
	add.s32 	%r253, %r250, 1;
	and.b32  	%r254, %r253, 2;
	setp.eq.s32 	%p119, %r254, 0;
	sub.f32 	%f461, %f192, %f457;
	cvt.rzi.f32.f32 	%f463, %f595;
	setp.eq.f32 	%p120, %f463, %f595;
	mul.f32 	%f464, %f595, 0f00000000;
	selp.f32 	%f465, %f464, %f459, %p120;
	abs.f32 	%f466, %f595;
	shr.u32 	%r54, %r1, 4;
	cvt.u16.u32 	%rs1, %r1;
	shr.u16 	%rs2, %rs1, 8;
	shl.b16 	%rs3, %rs1, 8;
	or.b16  	%rs4, %rs3, %rs2;
	shl.b16 	%rs5, %rs4, 4;
	shr.u16 	%rs6, %rs4, 4;
	and.b16  	%rs7, %rs6, 3840;
	or.b16  	%rs8, %rs7, %rs5;
	and.b16  	%rs9, %rs8, 13107;
	shl.b16 	%rs10, %rs9, 2;
	shr.u16 	%rs11, %rs8, 2;
	and.b16  	%rs12, %rs11, 13107;
	or.b16  	%rs13, %rs12, %rs10;
	shr.u16 	%rs14, %rs13, 1;
	and.b16  	%rs15, %rs13, 16384;
	shl.b16 	%rs16, %rs15, 1;
	or.b16  	%rs17, %rs14, %rs16;
	shr.u16 	%rs18, %rs17, 14;
	div.approx.f32 	%f73, %f192, %f580;
	abs.f32 	%f607, %f73;
	setp.lt.f32 	%p122, %f607, 0f40000000;
	@%p122 bra 	LBB0_100;
// %bb.58:
	setp.gtu.f32 	%p123, %f607, 0f4B800000;
	@%p123 bra 	LBB0_96;
	bra.uni 	LBB0_59;
LBB0_96:
	mov.b32 	%r89, %f607;
	and.b32  	%r255, %r89, 8388607;
	or.b32  	%r1035, %r255, 1065353216;
	mov.b32 	%f606, %r1035;
	add.s32 	%r256, %r89, -1073741824;
	and.b32  	%r1036, %r256, -8388608;
	setp.eq.s32 	%p129, %r1036, 0;
	@%p129 bra 	LBB0_99;
// %bb.97:                              // %__nv_fmaf_rn.exit4.i.i.i538.preheader
	mov.f32 	%f479, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f478,%f479;
	// end inline asm
LBB0_98:                                // %__nv_fmaf_rn.exit4.i.i.i538
                                        // =>This Inner Loop Header: Depth=1
	min.u32 	%r257, %r1036, 192937984;
	add.s32 	%r258, %r257, %r1035;
	mov.b32 	%f480, %r258;
	mul.f32 	%f481, %f478, %f480;
	sub.f32 	%f482, %f480, %f481;
	fma.rn.f32 	%f483, %f482, %f478, %f481;
	sub.f32 	%f484, %f480, %f483;
	fma.rz.f32 	%f485, %f484, %f478, %f483;
	cvt.rzi.f32.f32 	%f486, %f485;
	sub.f32 	%f606, %f480, %f486;
	sub.s32 	%r1036, %r1036, %r257;
	mov.b32 	%r1035, %f606;
	setp.ne.s32 	%p130, %r1036, 0;
	setp.ne.s32 	%p131, %r1035, 0;
	and.pred  	%p132, %p130, %p131;
	@%p132 bra 	LBB0_98;
LBB0_99:                                // %__internal_fmodf_slowpath_mod.exit.i.i540
	setp.gt.u32 	%p133, %r89, 2139095039;
	selp.f32 	%f487, 0f7FFFFFFF, 0f4B800000, %p133;
	mul.f32 	%f488, %f606, 0f34000000;
	mul.f32 	%f607, %f487, %f488;
	bra.uni 	LBB0_100;
LBB0_59:                                // %__nv_fast_fdividef.exit.i.i.i510
	div.approx.f32 	%f471, %f607, %f580;
	cvt.rzi.f32.f32 	%f605, %f471;
	fma.rn.f32 	%f112, %f605, 0fC0000000, %f607;
	mov.b32 	%r88, %f112;
	setp.lt.u32 	%p124, %r88, 1073741824;
	@%p124 bra 	LBB0_95;
// %bb.60:
	setp.lt.u32 	%p125, %r88, -2147483647;
	@%p125 bra 	LBB0_93;
// %bb.61:
	add.f32 	%f476, %f605, 0fBF800000;
	setp.lt.f32 	%p128, %f112, 0fC0000000;
	add.f32 	%f477, %f476, 0fBF800000;
	selp.f32 	%f605, %f477, %f476, %p128;
	bra.uni 	LBB0_95;
LBB0_93:
	add.f32 	%f605, %f605, 0f3F800000;
	setp.ltu.f32 	%p126, %f112, 0f40800000;
	@%p126 bra 	LBB0_95;
// %bb.94:                              // %__nv_fmaf_rn.exit.i.i.i515
	add.f32 	%f472, %f605, 0f3F800000;
	fma.rn.f32 	%f474, %f580, 0fC0400000, %f112;
	setp.ge.f32 	%p127, %f474, 0f00000000;
	add.f32 	%f475, %f472, 0f3F800000;
	selp.f32 	%f605, %f475, %f472, %p127;
LBB0_95:                                // %__internal_fmodf_fastpath_quot.exit.i.i519
	fma.rn.f32 	%f607, %f605, 0fC0000000, %f607;
LBB0_100:                               // %__internal_fmodf_kernel.exit.i544
	shr.u32 	%r7, %r126, 1;
	or.b32  	%r128, %r10, %r127;
	selp.f32 	%f194, %f189, %f193, %p19;
	setp.gt.f32 	%p21, %f197, 0f4B800000;
	add.f32 	%f198, %f90, 0f3F800000;
	selp.f32 	%f247, %f242, %f246, %p39;
	setp.gt.f32 	%p41, %f251, 0f4B800000;
	add.f32 	%f252, %f250, 0f3F800000;
	selp.f32 	%f19, %f306, %f302, %p61;
	selp.f32 	%f361, %f360, %f355, %p81;
	selp.f32 	%f409, %f404, %f408, %p99;
	setp.gt.f32 	%p101, %f412, 0f4B800000;
	add.f32 	%f413, %f54, 0f3F800000;
	selp.f32 	%f462, %f457, %f461, %p119;
	setp.gt.f32 	%p121, %f466, 0f4B800000;
	add.f32 	%f467, %f465, 0f3F800000;
	cvt.u32.u16 	%r55, %rs18;
	or.b32  	%r56, %r85, %r54;
	abs.f32 	%f489, %f607;
	setp.gtu.f32 	%p134, %f489, 0f7F800000;
	@%p134 bra 	LBB0_102;
// %bb.101:
	mov.b32 	%r259, %f73;
	and.b32  	%r260, %r259, -2147483648;
	mov.b32 	%r261, %f607;
	or.b32  	%r262, %r260, %r261;
	mov.b32 	%f607, %r262;
LBB0_102:                               // %__nv_fmodf.exit545
	ld.param.u64 	%rd26, [_Z17julia_upchan_373313CuDeviceArrayI9Float16x2Li1ELi1EES_IS0_Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_I5Int32Li1ELi1EE_param_2];
	ld.param.u64 	%rd22, [_Z17julia_upchan_373313CuDeviceArrayI9Float16x2Li1ELi1EES_IS0_Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_I5Int32Li1ELi1EE_param_1];
	mul.wide.u32 	%rd37, %r7, 4;
	mul.wide.u32 	%rd39, %r128, 4;
	selp.f32 	%f91, %f198, %f194, %p21;
	selp.f32 	%f253, %f252, %f247, %p41;
	mov.b32 	%r199, %f361;
	mov.b32 	%r198, %f19;
	mov.b32 	%r205, %f358;
	mov.b32 	%r204, %f18;
	selp.f32 	%f55, %f413, %f409, %p101;
	selp.f32 	%f468, %f467, %f462, %p121;
	setp.eq.s32 	%p135, %r56, %r55;
	add.f32 	%f490, %f607, %f607;
	mov.b32 	%r263, %f490;
	and.b32  	%r264, %r263, -2147483648;
	or.b32  	%r265, %r264, 1056964608;
	mov.b32 	%f491, %r265;
	add.f32 	%f492, %f490, %f491;
	cvt.rzi.f32.f32 	%f493, %f492;
	abs.f32 	%f494, %f490;
	setp.gt.f32 	%p136, %f494, 0f4B000000;
	selp.f32 	%f495, %f490, %f493, %p136;
	cvt.rzi.f32.f32 	%f496, %f490;
	setp.lt.f32 	%p137, %f494, 0f3F000000;
	selp.f32 	%f497, %f496, %f495, %p137;
	cvt.rzi.s32.f32 	%r266, %f497;
	fma.rn.f32 	%f498, %f497, 0fBF000000, %f607;
	mul.f32 	%f499, %f498, 0f34222169;
	fma.rn.f32 	%f500, %f498, 0f40490FDA, %f499;
	mul.f32 	%f501, %f500, %f500;
	fma.rn.f32 	%f502, %f501, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f503, %f502, %f501, 0f3D2AAABB;
	fma.rn.f32 	%f504, %f503, %f501, 0fBEFFFFFF;
	fma.rn.f32 	%f505, %f504, %f501, 0f3F800000;
	fma.rn.f32 	%f506, %f501, %f500, 0f00000000;
	fma.rn.f32 	%f507, %f501, 0fB94D4153, 0f3C0885E4;
	fma.rn.f32 	%f508, %f507, %f501, 0fBE2AAAA8;
	fma.rn.f32 	%f509, %f508, %f506, %f500;
	and.b32  	%r267, %r266, 1;
	setp.eq.b32 	%p138, %r267, 1;
	selp.f32 	%f510, %f505, %f509, %p138;
	selp.f32 	%f511, %f509, %f505, %p138;
	and.b32  	%r268, %r266, 2;
	setp.eq.s32 	%p139, %r268, 0;
	neg.f32 	%f512, %f510;
	selp.f32 	%f513, %f510, %f512, %p139;
	add.s32 	%r269, %r266, 1;
	and.b32  	%r270, %r269, 2;
	setp.eq.s32 	%p140, %r270, 0;
	sub.f32 	%f515, %f192, %f511;
	selp.f32 	%f516, %f511, %f515, %p140;
	cvt.rzi.f32.f32 	%f517, %f607;
	setp.eq.f32 	%p141, %f517, %f607;
	mul.f32 	%f518, %f607, 0f00000000;
	selp.f32 	%f519, %f518, %f513, %p141;
	abs.f32 	%f520, %f607;
	setp.gt.f32 	%p142, %f520, 0f4B800000;
	add.f32 	%f521, %f519, 0f3F800000;
	selp.f32 	%f522, %f521, %f516, %p142;
	selp.f32 	%f126, 0f3F800000, 0f00000000, %p135;
	mul.wide.u32 	%rd50, %r10, 2;
	neg.s64 	%rd51, %rd50;
	cvt.rn.f32.s64 	%f523, %rd51;
	div.approx.f32 	%f129, %f523, %f580;
	abs.f32 	%f611, %f129;
	setp.lt.f32 	%p143, %f611, 0f40000000;
	@%p143 bra 	LBB0_114;
// %bb.103:
	setp.gtu.f32 	%p144, %f611, 0f4B800000;
	@%p144 bra 	LBB0_110;
	bra.uni 	LBB0_104;
LBB0_110:
	mov.b32 	%r97, %f611;
	and.b32  	%r271, %r97, 8388607;
	or.b32  	%r1037, %r271, 1065353216;
	mov.b32 	%f610, %r1037;
	add.s32 	%r272, %r97, -1073741824;
	and.b32  	%r1038, %r272, -8388608;
	setp.eq.s32 	%p150, %r1038, 0;
	@%p150 bra 	LBB0_113;
// %bb.111:                             // %__nv_fmaf_rn.exit4.i.i.i584.preheader
	mov.f32 	%f534, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f533,%f534;
	// end inline asm
LBB0_112:                               // %__nv_fmaf_rn.exit4.i.i.i584
                                        // =>This Inner Loop Header: Depth=1
	min.u32 	%r273, %r1038, 192937984;
	add.s32 	%r274, %r273, %r1037;
	mov.b32 	%f535, %r274;
	mul.f32 	%f536, %f533, %f535;
	sub.f32 	%f537, %f535, %f536;
	fma.rn.f32 	%f538, %f537, %f533, %f536;
	sub.f32 	%f539, %f535, %f538;
	fma.rz.f32 	%f540, %f539, %f533, %f538;
	cvt.rzi.f32.f32 	%f541, %f540;
	sub.f32 	%f610, %f535, %f541;
	sub.s32 	%r1038, %r1038, %r273;
	mov.b32 	%r1037, %f610;
	setp.ne.s32 	%p151, %r1038, 0;
	setp.ne.s32 	%p152, %r1037, 0;
	and.pred  	%p153, %p151, %p152;
	@%p153 bra 	LBB0_112;
LBB0_113:                               // %__internal_fmodf_slowpath_mod.exit.i.i586
	setp.gt.u32 	%p154, %r97, 2139095039;
	selp.f32 	%f542, 0f7FFFFFFF, 0f4B800000, %p154;
	mul.f32 	%f543, %f610, 0f34000000;
	mul.f32 	%f611, %f542, %f543;
	bra.uni 	LBB0_114;
LBB0_104:                               // %__nv_fast_fdividef.exit.i.i.i556
	div.approx.f32 	%f526, %f611, %f580;
	cvt.rzi.f32.f32 	%f609, %f526;
	fma.rn.f32 	%f132, %f609, 0fC0000000, %f611;
	mov.b32 	%r96, %f132;
	setp.lt.u32 	%p145, %r96, 1073741824;
	@%p145 bra 	LBB0_109;
// %bb.105:
	setp.lt.u32 	%p146, %r96, -2147483647;
	@%p146 bra 	LBB0_107;
// %bb.106:
	add.f32 	%f531, %f609, 0fBF800000;
	setp.lt.f32 	%p149, %f132, 0fC0000000;
	add.f32 	%f532, %f531, 0fBF800000;
	selp.f32 	%f609, %f532, %f531, %p149;
	bra.uni 	LBB0_109;
LBB0_107:
	add.f32 	%f609, %f609, 0f3F800000;
	setp.ltu.f32 	%p147, %f132, 0f40800000;
	@%p147 bra 	LBB0_109;
// %bb.108:                             // %__nv_fmaf_rn.exit.i.i.i561
	add.f32 	%f527, %f609, 0f3F800000;
	fma.rn.f32 	%f529, %f580, 0fC0400000, %f132;
	setp.ge.f32 	%p148, %f529, 0f00000000;
	add.f32 	%f530, %f527, 0f3F800000;
	selp.f32 	%f609, %f530, %f527, %p148;
LBB0_109:                               // %__internal_fmodf_fastpath_quot.exit.i.i565
	fma.rn.f32 	%f611, %f609, 0fC0000000, %f611;
LBB0_114:                               // %__internal_fmodf_kernel.exit.i590
	add.s64 	%rd38, %rd22, %rd37;
	add.s64 	%rd40, %rd26, %rd39;
	mov.b32 	%r160, %f253;
	mov.b32 	%r159, %f91;
	mov.b32 	%r163, %f250;
	mov.b32 	%r162, %f90;
	xor.b32  	%r202, %r205, -2147483648;
	xor.b32  	%r201, %r204, -2147483648;
	mov.b32 	%r243, %f468;
	mov.b32 	%r242, %f55;
	mov.b32 	%r246, %f465;
	mov.b32 	%r245, %f54;
	mul.f32 	%f127, %f522, %f126;
	mul.f32 	%f128, %f519, %f126;
	abs.f32 	%f544, %f611;
	setp.gtu.f32 	%p155, %f544, 0f7F800000;
	@%p155 bra 	LBB0_116;
// %bb.115:
	mov.b32 	%r275, %f129;
	and.b32  	%r276, %r275, -2147483648;
	mov.b32 	%r277, %f611;
	or.b32  	%r278, %r276, %r277;
	mov.b32 	%f611, %r278;
LBB0_116:                               // %__nv_fmodf.exit591
	ld.param.u64 	%rd1, [_Z17julia_upchan_373313CuDeviceArrayI9Float16x2Li1ELi1EES_IS0_Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_I5Int32Li1ELi1EE_param_3];
	ld.param.u64 	%rd2, [_Z17julia_upchan_373313CuDeviceArrayI9Float16x2Li1ELi1EES_IS0_Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_I5Int32Li1ELi1EE_param_4];
	ld.global.u32 	%r8, [%rd38];
	ld.global.u32 	%r11, [%rd40];
	ld.global.u32 	%r12, [%rd40+32];
	ld.global.u32 	%r13, [%rd40+64];
	ld.global.u32 	%r14, [%rd40+96];
	// begin inline asm
	cvt.rn.f16x2.f32 %r158, %r160, %r159;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r161, %r163, %r162;
	// end inline asm
	and.b32  	%r87, %r9, 4;
	// begin inline asm
	cvt.rn.f16x2.f32 %r197, %r199, %r198;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r200, %r202, %r201;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r203, %r205, %r204;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r206, %r199, %r198;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r241, %r243, %r242;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r244, %r246, %r245;
	// end inline asm
	add.f32 	%f545, %f611, %f611;
	mov.b32 	%r292, %f545;
	and.b32  	%r293, %r292, -2147483648;
	or.b32  	%r294, %r293, 1056964608;
	mov.b32 	%f546, %r294;
	add.f32 	%f547, %f545, %f546;
	cvt.rzi.f32.f32 	%f548, %f547;
	abs.f32 	%f549, %f545;
	setp.gt.f32 	%p156, %f549, 0f4B000000;
	selp.f32 	%f550, %f545, %f548, %p156;
	cvt.rzi.f32.f32 	%f551, %f545;
	setp.lt.f32 	%p157, %f549, 0f3F000000;
	selp.f32 	%f552, %f551, %f550, %p157;
	cvt.rzi.s32.f32 	%r295, %f552;
	fma.rn.f32 	%f553, %f552, 0fBF000000, %f611;
	mul.f32 	%f554, %f553, 0f34222169;
	fma.rn.f32 	%f555, %f553, 0f40490FDA, %f554;
	mul.f32 	%f556, %f555, %f555;
	fma.rn.f32 	%f557, %f556, 0f37CBAC00, 0fBAB607ED;
	fma.rn.f32 	%f558, %f557, %f556, 0f3D2AAABB;
	fma.rn.f32 	%f559, %f558, %f556, 0fBEFFFFFF;
	fma.rn.f32 	%f560, %f559, %f556, 0f3F800000;
	fma.rn.f32 	%f561, %f556, %f555, 0f00000000;
	fma.rn.f32 	%f562, %f556, 0fB94D4153, 0f3C0885E4;
	fma.rn.f32 	%f563, %f562, %f556, 0fBE2AAAA8;
	fma.rn.f32 	%f564, %f563, %f561, %f555;
	and.b32  	%r296, %r295, 1;
	setp.eq.b32 	%p158, %r296, 1;
	selp.f32 	%f565, %f560, %f564, %p158;
	selp.f32 	%f566, %f564, %f560, %p158;
	and.b32  	%r297, %r295, 2;
	setp.eq.s32 	%p159, %r297, 0;
	neg.f32 	%f567, %f565;
	selp.f32 	%f568, %f565, %f567, %p159;
	add.s32 	%r298, %r295, 1;
	and.b32  	%r299, %r298, 2;
	setp.eq.s32 	%p160, %r299, 0;
	sub.f32 	%f570, %f192, %f566;
	selp.f32 	%f571, %f566, %f570, %p160;
	cvt.rzi.f32.f32 	%f572, %f611;
	setp.eq.f32 	%p161, %f572, %f611;
	mul.f32 	%f573, %f611, 0f00000000;
	selp.f32 	%f574, %f573, %f568, %p161;
	abs.f32 	%f575, %f611;
	setp.gt.f32 	%p162, %f575, 0f4B800000;
	add.f32 	%f576, %f574, 0f3F800000;
	selp.f32 	%f577, %f576, %f571, %p162;
	mul.f32 	%f578, %f577, %f126;
	mul.f32 	%f579, %f574, %f126;
	mov.b32 	%r281, %f578;
	mov.b32 	%r280, %f127;
	// begin inline asm
	cvt.rn.f16x2.f32 %r104, %r281, %r280;
	// end inline asm
	mov.b32 	%r287, %f579;
	xor.b32  	%r284, %r287, -2147483648;
	mov.b32 	%r286, %f128;
	xor.b32  	%r283, %r286, -2147483648;
	// begin inline asm
	cvt.rn.f16x2.f32 %r105, %r284, %r283;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r106, %r287, %r286;
	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.f32 %r107, %r281, %r280;
	// end inline asm
	and.b32  	%r300, %r4, 2048;
	and.b32  	%r301, %r5, 28;
	shl.b32 	%r302, %r3, 5;
	and.b32  	%r303, %r302, 96;
	and.b32  	%r108, %r1, 8;
	shl.b32 	%r109, %r2, 16;
	shl.b32 	%r304, %r3, 4;
	and.b32  	%r305, %r304, 1920;
	or.b32  	%r306, %r303, %r109;
	or.b32  	%r307, %r306, %r301;
	or.b32  	%r308, %r307, %r300;
	or.b32  	%r110, %r308, %r305;
	or.b32  	%r111, %r9, %r108;
	mul.lo.s32 	%r309, %r54, 65;
	mul.lo.s32 	%r310, %r2, 545;
	shl.b32 	%r311, %r1, 4;
	or.b32  	%r312, %r108, %r311;
	shr.u32 	%r313, %r312, 2;
	and.b32  	%r314, %r313, 30;
	add.s32 	%r315, %r309, %r310;
	add.s32 	%r316, %r315, %r314;
	mul.wide.u32 	%rd52, %r316, 4;
	mov.u64 	%rd53, shmem;
	add.s64 	%rd11, %rd53, %rd52;
	cvt.u64.u32 	%rd54, %r314;
	cvt.u64.u32 	%rd55, %r309;
	cvt.u64.u32 	%rd56, %r310;
	add.s64 	%rd57, %rd56, %rd55;
	add.s64 	%rd58, %rd57, %rd54;
	shl.b64 	%rd59, %rd58, 2;
	add.s64 	%rd12, %rd53, %rd59;
	shl.b32 	%r317, %r2, 2;
	and.b32  	%r318, %r317, 32;
	bfe.u32 	%r319, %r1, 1, 1;
	and.b32  	%r320, %r1, 1;
	and.b32  	%r321, %r317, 28;
	shl.b32 	%r322, %r1, 3;
	and.b32  	%r323, %r322, 64;
	or.b32  	%r324, %r321, %r323;
	and.b32  	%r325, %r6, 32;
	or.b32  	%r326, %r324, %r325;
	shr.u32 	%r327, %r326, 2;
	mad.lo.s32 	%r328, %r320, 130, %r318;
	mad.lo.s32 	%r329, %r319, 65, %r328;
	mad.lo.s32 	%r330, %r10, 260, %r329;
	add.s32 	%r331, %r330, %r327;
	or.b32  	%r332, %r327, %r318;
	mad.lo.s32 	%r333, %r7, 65, %r332;
	or.b32  	%r334, %r54, 2;
	mul.lo.s32 	%r335, %r334, 65;
	add.s32 	%r336, %r335, %r310;
	add.s32 	%r337, %r336, %r314;
	mul.wide.u32 	%rd60, %r337, 4;
	add.s64 	%rd13, %rd53, %rd60;
	cvt.u64.u32 	%rd61, %r335;
	add.s64 	%rd62, %rd56, %rd61;
	add.s64 	%rd63, %rd62, %rd54;
	shl.b64 	%rd64, %rd63, 2;
	add.s64 	%rd14, %rd53, %rd64;
	or.b32  	%r338, %r54, 4;
	mul.lo.s32 	%r339, %r338, 65;
	add.s32 	%r340, %r339, %r310;
	add.s32 	%r341, %r340, %r314;
	mul.wide.u32 	%rd65, %r341, 4;
	add.s64 	%rd15, %rd53, %rd65;
	cvt.u64.u32 	%rd66, %r339;
	add.s64 	%rd67, %rd56, %rd66;
	add.s64 	%rd68, %rd67, %rd54;
	shl.b64 	%rd69, %rd68, 2;
	add.s64 	%rd16, %rd53, %rd69;
	or.b32  	%r342, %r54, 6;
	mul.lo.s32 	%r343, %r342, 65;
	add.s32 	%r344, %r343, %r310;
	add.s32 	%r345, %r344, %r314;
	mul.wide.u32 	%rd70, %r345, 4;
	add.s64 	%rd17, %rd53, %rd70;
	cvt.u64.u32 	%rd71, %r343;
	add.s64 	%rd72, %rd56, %rd71;
	add.s64 	%rd73, %rd72, %rd54;
	shl.b64 	%rd74, %rd73, 2;
	add.s64 	%rd18, %rd53, %rd74;
	shl.b32 	%r346, %r3, 1;
	and.b32  	%r347, %r346, 240;
	shr.u32 	%r348, %r1, 3;
	or.b32  	%r349, %r347, %r348;
	shl.b32 	%r350, %r349, 7;
	shl.b32 	%r351, %r3, 13;
	and.b32  	%r352, %r351, 32768;
	or.b32  	%r353, %r301, %r303;
	or.b32  	%r354, %r350, %r352;
	or.b32  	%r112, %r354, %r353;
	or.b32  	%r113, %r112, 512;
	or.b32  	%r114, %r112, 1024;
	or.b32  	%r115, %r112, 1536;
	mul.wide.u32 	%rd75, %r333, 4;
	add.s64 	%rd19, %rd53, %rd75;
	mul.wide.u32 	%rd76, %r331, 4;
	add.s64 	%rd20, %rd53, %rd76;
	mov.u32 	%r1028, 0;
	setp.eq.s32 	%p163, %r108, 0;
	mov.u16 	%rs84, 25600;
	mov.u16 	%rs58, 21504;
	mov.u16 	%rs92, 18432;
	mov.u16 	%rs80, -14592;
	mov.u32 	%r1029, %r1028;
	mov.u32 	%r1030, %r1028;
	mov.u32 	%r1026, %r1028;
LBB0_62:                                // %L906
                                        // =>This Loop Header: Depth=1
                                        //     Child Loop BB0_63 Depth 2
	or.b32  	%r420, %r108, %r1026;
	or.b32  	%r421, %r420, %r87;
	shl.b32 	%r422, %r421, 12;
	or.b32  	%r423, %r110, %r422;
	mul.wide.s32 	%rd77, %r423, 4;
	add.s64 	%rd78, %rd1, %rd77;
	ld.global.v4.u32 	{%r424, %r425, %r426, %r427}, [%rd78];
	or.b32  	%r428, %r423, 4096;
	mul.wide.s32 	%rd79, %r428, 4;
	add.s64 	%rd80, %rd1, %rd79;
	ld.global.v4.u32 	{%r429, %r430, %r431, %r432}, [%rd80];
	or.b32  	%r433, %r423, 8192;
	mul.wide.s32 	%rd81, %r433, 4;
	add.s64 	%rd82, %rd1, %rd81;
	ld.global.v4.u32 	{%r434, %r435, %r436, %r437}, [%rd82];
	or.b32  	%r438, %r111, %r1026;
	shl.b32 	%r439, %r438, 12;
	or.b32  	%r440, %r110, %r439;
	or.b32  	%r441, %r440, 12288;
	mul.wide.s32 	%rd83, %r441, 4;
	add.s64 	%rd84, %rd1, %rd83;
	ld.global.v4.u32 	{%r442, %r443, %r444, %r445}, [%rd84];
	selp.b32 	%r446, %r426, %r424, %p163;
	shfl.sync.bfly.b32	%r447, %r446, 8, 31, -1;
	selp.b32 	%r356, %r424, %r447, %p163;
	selp.b32 	%r357, %r447, %r426, %p163;
	selp.b32 	%r448, %r427, %r425, %p163;
	shfl.sync.bfly.b32	%r449, %r448, 8, 31, -1;
	selp.b32 	%r364, %r425, %r449, %p163;
	selp.b32 	%r365, %r449, %r427, %p163;
	selp.b32 	%r450, %r431, %r429, %p163;
	shfl.sync.bfly.b32	%r451, %r450, 8, 31, -1;
	selp.b32 	%r372, %r429, %r451, %p163;
	selp.b32 	%r373, %r451, %r431, %p163;
	selp.b32 	%r452, %r432, %r430, %p163;
	shfl.sync.bfly.b32	%r453, %r452, 8, 31, -1;
	selp.b32 	%r380, %r430, %r453, %p163;
	selp.b32 	%r381, %r453, %r432, %p163;
	selp.b32 	%r454, %r436, %r434, %p163;
	shfl.sync.bfly.b32	%r455, %r454, 8, 31, -1;
	selp.b32 	%r388, %r434, %r455, %p163;
	selp.b32 	%r389, %r455, %r436, %p163;
	selp.b32 	%r456, %r437, %r435, %p163;
	shfl.sync.bfly.b32	%r457, %r456, 8, 31, -1;
	selp.b32 	%r396, %r435, %r457, %p163;
	selp.b32 	%r397, %r457, %r437, %p163;
	selp.b32 	%r458, %r444, %r442, %p163;
	shfl.sync.bfly.b32	%r459, %r458, 8, 31, -1;
	selp.b32 	%r404, %r442, %r459, %p163;
	selp.b32 	%r405, %r459, %r444, %p163;
	selp.b32 	%r460, %r445, %r443, %p163;
	shfl.sync.bfly.b32	%r461, %r460, 8, 31, -1;
	selp.b32 	%r412, %r443, %r461, %p163;
	selp.b32 	%r413, %r461, %r445, %p163;
	mov.u32 	%r414, 21520;
	// begin inline asm
	prmt.b32 %r355, %r356, %r357, %r414;
	// end inline asm
	mov.u32 	%r418, 30258;
	// begin inline asm
	prmt.b32 %r359, %r356, %r357, %r418;
	// end inline asm
	// begin inline asm
	prmt.b32 %r363, %r364, %r365, %r414;
	// end inline asm
	// begin inline asm
	prmt.b32 %r367, %r364, %r365, %r418;
	// end inline asm
	// begin inline asm
	prmt.b32 %r371, %r372, %r373, %r414;
	// end inline asm
	// begin inline asm
	prmt.b32 %r375, %r372, %r373, %r418;
	// end inline asm
	// begin inline asm
	prmt.b32 %r379, %r380, %r381, %r414;
	// end inline asm
	// begin inline asm
	prmt.b32 %r383, %r380, %r381, %r418;
	// end inline asm
	// begin inline asm
	prmt.b32 %r387, %r388, %r389, %r414;
	// end inline asm
	// begin inline asm
	prmt.b32 %r391, %r388, %r389, %r418;
	// end inline asm
	// begin inline asm
	prmt.b32 %r395, %r396, %r397, %r414;
	// end inline asm
	// begin inline asm
	prmt.b32 %r399, %r396, %r397, %r418;
	// end inline asm
	// begin inline asm
	prmt.b32 %r403, %r404, %r405, %r414;
	// end inline asm
	// begin inline asm
	prmt.b32 %r407, %r404, %r405, %r418;
	// end inline asm
	// begin inline asm
	prmt.b32 %r411, %r412, %r413, %r414;
	// end inline asm
	// begin inline asm
	prmt.b32 %r415, %r412, %r413, %r418;
	// end inline asm
	st.shared.u32 	[%rd11], %r355;
	st.shared.u32 	[%rd12+128], %r359;
	st.shared.u32 	[%rd12+4], %r363;
	st.shared.u32 	[%rd12+132], %r367;
	st.shared.u32 	[%rd12+1040], %r371;
	st.shared.u32 	[%rd12+1168], %r375;
	st.shared.u32 	[%rd12+1044], %r379;
	st.shared.u32 	[%rd12+1172], %r383;
	st.shared.u32 	[%rd12+520], %r387;
	st.shared.u32 	[%rd12+648], %r391;
	st.shared.u32 	[%rd12+524], %r395;
	st.shared.u32 	[%rd12+652], %r399;
	st.shared.u32 	[%rd12+1560], %r403;
	st.shared.u32 	[%rd12+1688], %r407;
	st.shared.u32 	[%rd12+1564], %r411;
	st.shared.u32 	[%rd12+1692], %r415;
	bar.sync 	0;
	mov.u32 	%r1027, 256;
	mov.u64 	%rd93, %rd20;
	mov.u64 	%rd94, %rd19;
LBB0_63:                                // %L8927
                                        //   Parent Loop BB0_62 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	mov.u32 	%r64, %r1030;
	mov.u32 	%r63, %r1029;
	ld.shared.u32 	%r1030, [%rd93];
	// begin inline asm
	mov.b32 %r467, {%rs84, %rs84};
	// end inline asm
	// begin inline asm
	mov.b32 %r478, {%rs58, %rs58};
	// end inline asm
	xor.b32  	%r466, %r1030, -2004318072;
	mov.u32 	%r465, 983055;
	// begin inline asm
	lop3.b32 %r464, %r465, %r466, %r467, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r468, {%rs92, %rs92};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r469, %r467, %r468;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r472, %r464, %r469;
	// end inline asm
	mov.u32 	%r476, 15728880;
	// begin inline asm
	lop3.b32 %r475, %r476, %r466, %r478, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r479, {%rs92, %rs92};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r480, %r478, %r479;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r483, %r475, %r480;
	// end inline asm
	shr.u32 	%r488, %r466, 8;
	// begin inline asm
	lop3.b32 %r486, %r465, %r488, %r467, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r490, {%rs92, %rs92};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r491, %r467, %r490;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r494, %r486, %r491;
	// end inline asm
	// begin inline asm
	lop3.b32 %r497, %r476, %r488, %r478, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r501, {%rs92, %rs92};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r502, %r478, %r501;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r505, %r497, %r502;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r508, %r14;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r510, %r508, %r472;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r513, %r14;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r515, %r513, %r483;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r518, %r14;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r520, %r518, %r494;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r523, %r14;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r525, %r523, %r505;
	// end inline asm
	// begin inline asm
	mov.b32 %r533, {%rs84, %rs84};
	// end inline asm
	// begin inline asm
	mov.b32 %r544, {%rs58, %rs58};
	// end inline asm
	xor.b32  	%r532, %r1028, -2004318072;
	// begin inline asm
	lop3.b32 %r530, %r465, %r532, %r533, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r534, {%rs92, %rs92};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r535, %r533, %r534;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r538, %r530, %r535;
	// end inline asm
	// begin inline asm
	lop3.b32 %r541, %r476, %r532, %r544, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r545, {%rs92, %rs92};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r546, %r544, %r545;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r549, %r541, %r546;
	// end inline asm
	shr.u32 	%r554, %r532, 8;
	// begin inline asm
	lop3.b32 %r552, %r465, %r554, %r533, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r556, {%rs92, %rs92};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r557, %r533, %r556;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r560, %r552, %r557;
	// end inline asm
	// begin inline asm
	lop3.b32 %r563, %r476, %r554, %r544, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r567, {%rs92, %rs92};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r568, %r544, %r567;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r571, %r563, %r568;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r574, %r11, %r538, %r510;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r578, %r11, %r549, %r515;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r582, %r11, %r560, %r520;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r586, %r11, %r571, %r525;
	// end inline asm
	// begin inline asm
	mov.b32 %r595, {%rs84, %rs84};
	// end inline asm
	// begin inline asm
	mov.b32 %r606, {%rs58, %rs58};
	// end inline asm
	xor.b32  	%r594, %r63, -2004318072;
	// begin inline asm
	lop3.b32 %r592, %r465, %r594, %r595, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r596, {%rs92, %rs92};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r597, %r595, %r596;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r600, %r592, %r597;
	// end inline asm
	// begin inline asm
	lop3.b32 %r603, %r476, %r594, %r606, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r607, {%rs92, %rs92};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r608, %r606, %r607;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r611, %r603, %r608;
	// end inline asm
	shr.u32 	%r616, %r594, 8;
	// begin inline asm
	lop3.b32 %r614, %r465, %r616, %r595, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r618, {%rs92, %rs92};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r619, %r595, %r618;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r622, %r614, %r619;
	// end inline asm
	// begin inline asm
	lop3.b32 %r625, %r476, %r616, %r606, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r629, {%rs92, %rs92};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r630, %r606, %r629;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r633, %r625, %r630;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r636, %r12;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r638, %r636, %r600, %r574;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r642, %r12;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r644, %r642, %r611, %r578;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r648, %r12;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r650, %r648, %r622, %r582;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r654, %r12;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r656, %r654, %r633, %r586;
	// end inline asm
	// begin inline asm
	mov.b32 %r665, {%rs84, %rs84};
	// end inline asm
	// begin inline asm
	mov.b32 %r676, {%rs58, %rs58};
	// end inline asm
	xor.b32  	%r664, %r64, -2004318072;
	// begin inline asm
	lop3.b32 %r662, %r465, %r664, %r665, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r666, {%rs92, %rs92};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r667, %r665, %r666;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r670, %r662, %r667;
	// end inline asm
	// begin inline asm
	lop3.b32 %r673, %r476, %r664, %r676, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r677, {%rs92, %rs92};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r678, %r676, %r677;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r681, %r673, %r678;
	// end inline asm
	shr.u32 	%r686, %r664, 8;
	// begin inline asm
	lop3.b32 %r684, %r465, %r686, %r665, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r688, {%rs92, %rs92};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r689, %r665, %r688;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r692, %r684, %r689;
	// end inline asm
	// begin inline asm
	lop3.b32 %r695, %r476, %r686, %r676, 202;
	// end inline asm
	// begin inline asm
	mov.b32 %r699, {%rs92, %rs92};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r700, %r676, %r699;
	// end inline asm
	// begin inline asm
	sub.rn.f16x2 %r703, %r695, %r700;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r729, %r13, %r670, %r638;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r726, %r13, %r681, %r644;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r738, %r13, %r692, %r650;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r735, %r13, %r703, %r656;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r722, %r161;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r724, %r722, %r726;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r727, %r158, %r729, %r724;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r731, %r161;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r733, %r731, %r735;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r736, %r158, %r738, %r733;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r740, %r161, %r729;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r743, %r158, %r726, %r740;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r747, %r161, %r738;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r750, %r158, %r735, %r747;
	// end inline asm
	mov.u32 	%r825, 0;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r781, %r778}, {%r197, %r203, %r200, %r206}, {%r727, %r743}, {%r825, %r825};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r790, %r787}, {%r197, %r203, %r200, %r206}, {%r736, %r750}, {%r825, %r825};
	// end inline asm
	// begin inline asm
	neg.f16x2 %r774, %r244;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r776, %r774, %r778;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r779, %r241, %r781, %r776;
	// end inline asm
	// begin inline asm
	neg.f16x2 %r783, %r244;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r785, %r783, %r787;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r788, %r241, %r790, %r785;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r792, %r244, %r781;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r795, %r241, %r778, %r792;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r799, %r244, %r790;
	// end inline asm
	// begin inline asm
	fma.rn.f16x2 %r802, %r241, %r787, %r799;
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r806, %r807}, {%r104, %r106, %r105, %r107}, {%r779, %r795}, {%r825, %r825};
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%r816, %r817}, {%r104, %r106, %r105, %r107}, {%r788, %r802}, {%r825, %r825};
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r826, %r8, %r806;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r829, %r8, %r807;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r832, %r8, %r816;
	// end inline asm
	// begin inline asm
	mul.rn.f16x2 %r835, %r8, %r817;
	// end inline asm
	// begin inline asm
	mov.b32 %r838, {%rs80, %rs80};
	// end inline asm
	mov.u16 	%rs69, 18176;
	// begin inline asm
	mov.b32 %r839, {%rs69, %rs69};
	// end inline asm
	// begin inline asm
	max.f16x2 %r840, %r826, %r838;
	// end inline asm
	// begin inline asm
	min.f16x2 %r843, %r840, %r839;
	// end inline asm
	// begin inline asm
	mov.b32 %r846, {%rs80, %rs80};
	// end inline asm
	// begin inline asm
	mov.b32 %r847, {%rs69, %rs69};
	// end inline asm
	// begin inline asm
	max.f16x2 %r848, %r829, %r846;
	// end inline asm
	// begin inline asm
	min.f16x2 %r851, %r848, %r847;
	// end inline asm
	// begin inline asm
	mov.b32 %r854, {%rs80, %rs80};
	// end inline asm
	// begin inline asm
	mov.b32 %r855, {%rs69, %rs69};
	// end inline asm
	// begin inline asm
	max.f16x2 %r856, %r832, %r854;
	// end inline asm
	// begin inline asm
	min.f16x2 %r859, %r856, %r855;
	// end inline asm
	// begin inline asm
	mov.b32 %r862, {%rs80, %rs80};
	// end inline asm
	// begin inline asm
	mov.b32 %r863, {%rs69, %rs69};
	// end inline asm
	// begin inline asm
	max.f16x2 %r864, %r835, %r862;
	// end inline asm
	// begin inline asm
	min.f16x2 %r867, %r864, %r863;
	// end inline asm
	// begin inline asm
	mov.b32 %r873, {%rs84, %rs84};
	// end inline asm
	// begin inline asm
	mov.b32 %r871, {%rs92, %rs92};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r872, %r873, %r871;
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r875, %r843, %r872;
	// end inline asm
	// begin inline asm
	mov.b32 %r878, {%rs92, %rs92};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r879, %r873, %r878;
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r882, %r851, %r879;
	// end inline asm
	// begin inline asm
	mov.b32 %r885, {%rs92, %rs92};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r886, %r873, %r885;
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r889, %r859, %r886;
	// end inline asm
	// begin inline asm
	mov.b32 %r892, {%rs92, %rs92};
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r893, %r873, %r892;
	// end inline asm
	// begin inline asm
	add.rn.f16x2 %r896, %r867, %r893;
	// end inline asm
	mov.u32 	%r902, 25152;
	// begin inline asm
	prmt.b32 %r899, %r875, %r889, %r902;
	// end inline asm
	// begin inline asm
	prmt.b32 %r903, %r882, %r896, %r902;
	// end inline asm
	shl.b32 	%r910, %r903, 4;
	mov.u32 	%r908, 252645135;
	// begin inline asm
	lop3.b32 %r907, %r908, %r899, %r910, 202;
	// end inline asm
	xor.b32  	%r911, %r907, -2004318072;
	st.shared.u32 	[%rd94], %r911;
	add.s32 	%r1027, %r1027, -16;
	add.s64 	%rd94, %rd94, 2180;
	add.s64 	%rd93, %rd93, 2180;
	setp.eq.s32 	%p164, %r1027, 0;
	mov.u32 	%r1028, %r63;
	mov.u32 	%r1029, %r64;
	@%p164 bra 	LBB0_117;
	bra.uni 	LBB0_63;
LBB0_117:                               // %guard_pass6324
                                        //   in Loop: Header=BB0_62 Depth=1
	bar.sync 	0;
	ld.shared.u32 	%r917, [%rd11];
	ld.shared.u32 	%r918, [%rd12+128];
	ld.shared.u32 	%r925, [%rd12+4];
	ld.shared.u32 	%r926, [%rd12+132];
	ld.shared.u32 	%r933, [%rd13];
	ld.shared.u32 	%r934, [%rd14+128];
	ld.shared.u32 	%r941, [%rd14+4];
	ld.shared.u32 	%r942, [%rd14+132];
	ld.shared.u32 	%r949, [%rd15];
	ld.shared.u32 	%r950, [%rd16+128];
	ld.shared.u32 	%r957, [%rd16+4];
	ld.shared.u32 	%r958, [%rd16+132];
	ld.shared.u32 	%r965, [%rd17];
	ld.shared.u32 	%r966, [%rd18+128];
	ld.shared.u32 	%r973, [%rd18+4];
	ld.shared.u32 	%r974, [%rd18+132];
	// begin inline asm
	prmt.b32 %r912, %r917, %r918, %r414;
	// end inline asm
	// begin inline asm
	prmt.b32 %r916, %r917, %r918, %r418;
	// end inline asm
	// begin inline asm
	prmt.b32 %r920, %r925, %r926, %r414;
	// end inline asm
	// begin inline asm
	prmt.b32 %r924, %r925, %r926, %r418;
	// end inline asm
	// begin inline asm
	prmt.b32 %r928, %r933, %r934, %r414;
	// end inline asm
	// begin inline asm
	prmt.b32 %r932, %r933, %r934, %r418;
	// end inline asm
	// begin inline asm
	prmt.b32 %r936, %r941, %r942, %r414;
	// end inline asm
	// begin inline asm
	prmt.b32 %r940, %r941, %r942, %r418;
	// end inline asm
	// begin inline asm
	prmt.b32 %r944, %r949, %r950, %r414;
	// end inline asm
	// begin inline asm
	prmt.b32 %r948, %r949, %r950, %r418;
	// end inline asm
	// begin inline asm
	prmt.b32 %r952, %r957, %r958, %r414;
	// end inline asm
	// begin inline asm
	prmt.b32 %r956, %r957, %r958, %r418;
	// end inline asm
	// begin inline asm
	prmt.b32 %r960, %r965, %r966, %r414;
	// end inline asm
	// begin inline asm
	prmt.b32 %r964, %r965, %r966, %r418;
	// end inline asm
	// begin inline asm
	prmt.b32 %r968, %r973, %r974, %r414;
	// end inline asm
	// begin inline asm
	prmt.b32 %r972, %r973, %r974, %r418;
	// end inline asm
	selp.b32 	%r976, %r916, %r912, %p163;
	shfl.sync.bfly.b32	%r977, %r976, 8, 31, -1;
	selp.b32 	%r978, %r912, %r977, %p163;
	selp.b32 	%r979, %r977, %r916, %p163;
	selp.b32 	%r980, %r924, %r920, %p163;
	shfl.sync.bfly.b32	%r981, %r980, 8, 31, -1;
	selp.b32 	%r982, %r920, %r981, %p163;
	selp.b32 	%r983, %r981, %r924, %p163;
	selp.b32 	%r984, %r932, %r928, %p163;
	shfl.sync.bfly.b32	%r985, %r984, 8, 31, -1;
	selp.b32 	%r986, %r928, %r985, %p163;
	selp.b32 	%r987, %r985, %r932, %p163;
	selp.b32 	%r988, %r940, %r936, %p163;
	shfl.sync.bfly.b32	%r989, %r988, 8, 31, -1;
	selp.b32 	%r990, %r936, %r989, %p163;
	selp.b32 	%r991, %r989, %r940, %p163;
	selp.b32 	%r992, %r948, %r944, %p163;
	shfl.sync.bfly.b32	%r993, %r992, 8, 31, -1;
	selp.b32 	%r994, %r944, %r993, %p163;
	selp.b32 	%r995, %r993, %r948, %p163;
	selp.b32 	%r996, %r956, %r952, %p163;
	shfl.sync.bfly.b32	%r997, %r996, 8, 31, -1;
	selp.b32 	%r998, %r952, %r997, %p163;
	selp.b32 	%r999, %r997, %r956, %p163;
	selp.b32 	%r1000, %r964, %r960, %p163;
	shfl.sync.bfly.b32	%r1001, %r1000, 8, 31, -1;
	selp.b32 	%r1002, %r960, %r1001, %p163;
	selp.b32 	%r1003, %r1001, %r964, %p163;
	selp.b32 	%r1004, %r972, %r968, %p163;
	shfl.sync.bfly.b32	%r1005, %r1004, 8, 31, -1;
	selp.b32 	%r1006, %r968, %r1005, %p163;
	selp.b32 	%r1007, %r1005, %r972, %p163;
	shl.b32 	%r1008, %r1026, 12;
	or.b32  	%r1009, %r109, %r1008;
	or.b32  	%r1010, %r1009, %r112;
	mul.wide.u32 	%rd85, %r1010, 4;
	add.s64 	%rd86, %rd2, %rd85;
	st.global.v4.u32 	[%rd86], {%r978, %r982, %r979, %r983};
	add.s32 	%r1011, %r1009, %r113;
	mul.wide.s32 	%rd87, %r1011, 4;
	add.s64 	%rd88, %rd2, %rd87;
	st.global.v4.u32 	[%rd88], {%r986, %r990, %r987, %r991};
	add.s32 	%r1012, %r1009, %r114;
	mul.wide.s32 	%rd89, %r1012, 4;
	add.s64 	%rd90, %rd2, %rd89;
	st.global.v4.u32 	[%rd90], {%r994, %r998, %r995, %r999};
	add.s32 	%r1013, %r1009, %r115;
	mul.wide.s32 	%rd91, %r1013, 4;
	add.s64 	%rd92, %rd2, %rd91;
	st.global.v4.u32 	[%rd92], {%r1002, %r1006, %r1003, %r1007};
	add.s32 	%r116, %r1026, 256;
	setp.eq.s32 	%p166, %r1026, 32512;
	mov.u32 	%r1028, %r63;
	mov.u32 	%r1029, %r64;
	mov.u32 	%r1026, %r116;
	@%p166 bra 	LBB0_118;
	bra.uni 	LBB0_62;
LBB0_118:                               // %L15317
	st.global.u32 	[%rd3], %r825;
	ret;
LBB0_1:                                 // %L8
	ld.param.u64 	%rd21, [_Z17julia_upchan_373313CuDeviceArrayI9Float16x2Li1ELi1EES_IS0_Li1ELi1EES_I6Int4x8Li1ELi1EES_IS1_Li1ELi1EES_I5Int32Li1ELi1EE_param_0];
	mov.u64 	%rd34, exception11410;
	cvta.global.u64 	%rd35, %rd34;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd35;
	call.uni 
	gpu_report_exception, 
	(
	param0
	);
	} // callseq 0
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .align 8 .b8 param0[8];
	st.param.b64 	[param0+0], %rd21;
	call.uni 
	gpu_signal_exception, 
	(
	param0
	);
	} // callseq 1
	// begin inline asm
	exit;
	// end inline asm
                                        // -- End function
}
